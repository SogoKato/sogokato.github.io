{"pageProps":{"posts":[{"title":"リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半","date":"2023-02-04T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n今回は第2部「単体テストとその価値」の","draft":false,"content":"\n[『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）](https://book.mynavi.jp/ec/products/detail/id=134252)を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n今回は第2部「単体テストとその価値」の前半についてのまとめになります。第2部は以下の4章で構成されています。今回は前半の第4章と第5章について扱います。\n\n* **第4章：良い単体テストを構成する4本の柱**\n* **第5章：モックの利用とテストの壊れやすさ**\n* 第6章：単体テストの3つの手法\n* 第7章：単体テストの価値を高めるリファクタリング\n\nまず、各章の内容の要約（切り抜き）を書き、その後に考察してみたいと思います。\n\n---\n\n## 第4章：良い単体テストを構成する4本の柱\n\n* 4本の柱（p.96）\n  * **退行（regression）に対する保護**\n  * **リファクタリングへの耐性**\n  * **迅速なフィードバック**\n  * **保守のしやすさ**\n* 1本目の柱：退行（regression）に対する保護（pp.96-98）\n  * ソフトウェアで発生する退行とはバグのこと\n  * 退行に対する保護がテストにどのくらい備わっているかを把握するには、次のことに目を向けるようにします\n    * テスト時に実行されるプロダクション・コードの量\n      * 量が増えると、退行が見つかる可能性は高くなります\n    * そのコードの複雑さ・そのコードが扱っているドメインの重要性\n      * **複雑なビジネス・ロジックが記述されたコードはボイラープレート・コードよりもはるかに重要**\n      * ビジネス的に重要な機能になるほど、持ち込まれたバグによって生じる被害もおおきくなる\n  * さらに、退行が発生することを回避するには……**ライブラリやフレームワークなどの外部から持ち込んだコード**のことも考慮しなくてはなりません\n    * アプリケーションのために書かれたコードと同じくらい、機能に影響を与える\n    * **テストの際にできるだけ多くのプロダクション・コードを実行させるようにします**\n* 2本目の柱：リファクタリングへの耐性（pp.98-99）\n  * リファクタリングとは、既存のコードの観測可能な振る舞い（observable behavior）を変えることなく、そのコードを変更すること\n  * **リファクタリングを行った結果**……**テストが失敗するようになった**……このテストはテスト対象の機能が正しく振る舞っていることを検証していたわけではなかったのです。**このようなテストの失敗のことを偽陽性（false positive）と呼びます**\n  * （リファクタリングへの耐性が備わっていれば）次の2つの効果が得られるようになります\n    * 既存の機能に何らかの問題を持ち込んでしまった場合、テストによってそのことが早い段階で警告されるようになる\n    * プロダクション・コードを変更しても退行が起こらないことに自信を持てるようになる\n* 何が偽陽性（false positive）を引き起こすのか？（p.101）\n  * テスト・コードがプロダクション・コードとより密接に結びついてしまうと、より多くの嘘の警告が発せられることになる\n    * **検証する対象を観察可能な振る舞いとし、その結果を得るための細かい手順である実装の詳細には目を向けない**\n  * もっとも意識すべきことは、作成するテスト・ケースが問題領域に関する物語（story）を伝えているのか、ということ\n    * そのような意識でテスト・ケースが作成されていれば……テスト・ケースで語られれている物語と実際のアプリケーションの振る舞いとのあいだに違いがあることが明らかになります\n* **観測可能な振る舞いを検証するようなテスト・ケースは偽陽性を生み出すことは**（仮にあったとしても）**滅多にありません**（pp.107-108）\n  * なぜ……「まったくない」のではなく「滅多にない」なのか……その理由は……テスト・ケースが壊れてしまう可能性はまだあるからです\n  * たとえば……新たな引数を追加した場合、コンパイル・エラーが発生します\n  * とはいえ、この種の偽陽性は簡単に修正できます……エラー・メッセージに従って……新たな引数を追加するだけ\n  * 一方、コンパイル・エラーが発生しない偽陽性の対処は簡単ではありません……本当のバグとの区別がつけにくく、調査をするのにより多くの時間を要することになる\n* **最初の2本の柱**……を備えることはテスト・スイートの正確性を最大限に引き上げることになる（p.110）\n  * **テストをすることでどのくらいのバグを検出できるのか？**\n    * 偽陰性（見つけられないバグ）の発生を抑える……大綱に対する保護がこの性質に該当\n  * **テストをすることでバグがないことをどのくらい示せるのか？**\n    * 偽陽性（嘘の警告）の発生を抑えることに関係し、リファクタリングへの耐性がこの性質に該当\n* 3本目の柱：迅速なフィードバック（p.113）\n  * **テストを速やかに行えるようになると、フィードバックを得てから改善するまでの時間も劇的に短くなり**……**バグがすぐに検出されるようになります**\n  * テストが遅くなると、テストを実施する回数が減ってしまい、開発が間違った方向に進んでしまっても気づくまでに時間がかかる\n* 4本目の柱：保守のしやすさ（p.113）\n  * **保守コストの評価**となる性質\n  * 次の2つの観点から把握できます\n    * **テスト・ケースを理解することがどのくらい難しいのか？**\n    * **テストを行うことがどのくらい難しいのか？**\n* 退行に対する保護、リファクタリングへの耐性、迅速なフィードバックの3本の柱は互いに背反する性質（p.115）\n  * **4本の柱のうち1本でもテスト・ケースに備わっていなければ……そのテスト・ケースの価値はなくなってしまう**\n  * すべての柱を可能な限り備えるように努めなくてはなりません\n* 極端な例 #1: **E2E（End-to-End）テスト**（pp.115-116）\n  * E2Eテストでは、多くのプロダクション・コードが実行されることになるため、退行に対する保護を十分に備えている\n  * 加えて、E2Eテストは嘘の警告を発する偽陽性（false positive）も持ち込まれにくいため、リファクタリングへの耐性が最も備わった種類のテストである\n  * 大きな欠点……**テストを実行し終えるまでに時間がかかってしまう**こと\n  * E2Eテストだけでコードベースを管理することが現実的でないことの理由\n* 極端な例: #2: 取るに足らないテスト（p.117）\n  * プロダクション・コードと同じことを別の書き方で表現しているだけであり、常に成功する\n  * 退行に対する保護は全く備わっていない\n* 極端な例: #3: 壊れやすいテスト（pp.118-119）\n  * 何（what）ではなくどのように（how）ということに目を向けているため……リファクタリングを妨げるものとなってしまった\n* どのようなトレード・オフを図ればよいのでしょうか？（p.121）\n  * 現実において、リファクタリングへの耐性を犠牲にすることはできません\n  * **退行に対する保護を優先するのか、それとも、迅速なフィードバックを優先するのか、ということを選択することを要求されるようになる**\n* E2Eテストだと退行に対する保護のほうが重要になり、単体テストだと迅速なフィードバックのほうが重要になる。一方、統合テストはそれらの真ん中くらいの割合が最善のバランスになる（p.125）\n  * ここで注目してほしいのが、どの層もリファクタリングへの耐性を必ず備えるようにしている点です\n  * ![fig 4.12](//www.plantuml.com/plantuml/png/LP3DIiD058NtUOfPraKsNOjqqwSmBiRajWRh59BfVdvGKbG8Y611aQ9Gg6WL4HMYUPZRr6JLLt2Q22QB6MQutptdS3eXfm4V7Gsi5kevwajKKrGBL6dvVKNrZF83vLCkufMOEMoTHAjhaTtFYacCyW7b1DNfEXbl4HgI07hKvSF0QXL2vDCp0pWiMtnNr3AzoH_V_y1-067e3vdLojFZGjoYd3kizBz3dQ0UeuvHQvEbNEW1UFlKFRG2S3bb_G6GRhkB-WJL9-feWq0RQjEVjvSiZXg0pxYnfTouri3i_6hvTT40Hypdrdz4icsNukOGkw5IUnExMjjSnDwf1wuw8VRkWUzvmFQQ6XrWdkd_5m00)\n\n---\n\n## 第5章：モックの利用とテストの壊れやすさ\n\n* テスト・ダブルには……5種類があります……モックとスタブの2つに大きく分けることができます（pp.132-134）\n  * **モック**：モック、スパイ\n    * テスト対象システムからその依存に向かって行われる**外部に向かうコミュニケーション（出力）を模倣**し、そして、**検証する**\n    * スパイはモックと同じ役割を担う\n      * モックはモック・フレームワークの助けを借りて生成される\n      * スパイは開発者自身の手で実装される\n  * **スタブ**：スタブ、ダミー、フェイク\n    * 依存からテスト対象システムに向かって行われる**内部に向かうコミュニケーション（入力）を模倣**\n    * ダミーとは、null値や一時しのぎで使われる文字列などのシンプルなハード・コーディングされた値のこと\n    * スタブはもっと洗練されており、設定によって返す結果を異なるシナリオごとに変えられる完全に自立した依存として振る舞うもの\n    * フェイクと使う目的はスタブの場合とほぼ同じである一方、通常、フェイクはまだ存在しない依存を置き換えるために作成される\n* **スタブとのやりとりを決して検証してはならない**（pp.135-137）\n  * スタブが行っていることは、テスト対象システムが最終的な結果を生成するのに必要なデータを提供する、ということだけ\n  * **最終的な結果の一部とはならないものを検証することを過剰検証（over-specification）と呼びます**\n* すべてのプロダクション・コードは次の2つの観点で分類できます（pp.140-141）\n  * 公開されたAPIなのか、それとも、プライベートなAPIなのか？\n  * **観測可能な振る舞いなのか、それとも、実装の詳細なのか？**\n    * 観測可能な振る舞い（observable behavior）の一部になるには、そのコードは次に挙げるもののどちらかでなくてはなりません\n      * クライアントが目標を達成するために使う公開された操作\n      * クライアントが目標を達成するために使う公開された状態\n* クライアントが1つの目標を達成するのにテスト対象となるクラスが提供する複数のメソッドを呼び出す必要があるのであれば、そのクラスは実装の詳細を漏洩していると見た方がよいでしょう。理想とすべきAPIの設計は、いかなる目標であれ、1つの操作で目標を達成できるようにすることです（p.146）\n* **アプリケーション・サービスに対するテスト・ケースはビジネスにおける全体的なユースケースがいかに実行されるのかを検証する**のに対し、**ドメイン・クラスに対するテスト・ケースは同じユース・ケースが完了に至るまでの一部を検証する**ことになる（p.153）\n  * ![fig 5.10](//www.plantuml.com/plantuml/png/SoWkIImgAStDuIfAJIv9p4lFILLGUhfasilc5O-RrZzkNlcuQSdZfaMFcpS_RkvGKaWiLaZEoKpDAq5M3fQV_hXvrUEcZO-RzpnkslwuUJbOn-x7JLj18isJ7pVj1EikJYqgoqnEHT7UtFcuUI7G7eWMcBKx3S4QKl9p4pFp38dHO8IamOWBuau5tPJyyZnTEvZ52bOAIizdhtksOkRxFHsFcvU1tRiJRCf62FlzdaubBfXgtT82e5weKJ1Hc9amjo7CVDouxicE1c3OAN51vQ0cG7NYCC48Zmb6Q2OufEQb0ACB0000)\n* システム内コミュニケーションとシステム間コミュニケーション（pp.155-156）\n  * **システム内コミュニケーションは実装の詳細になります**。その理由は、クライアントからのリクエストを処理する際、ドメイン・クラス間で行われるやり取りは観測可能な振る舞いの一部にはならないからです\n  * システム間コミュニケーションの場合は違います。なぜなら、テスト対象のアプリケーションがどのように外部とのコミュニケーションを取るのか、ということはそのシステムの観測可能な振る舞い全体を形成するものだからです\n* **外部から観察できないプロセス外依存とのコミュニケーションは実装の詳細になる**（pp.163-164）\n  * もし、データベースに対してテスト対象のアプリケーションを除くすべてのアプリケーションからアクセスされることが決してないのであれば、テスト対象のアプリケーションとデータベースのコミュニケーションに関する仕様を（既存の機能を破綻させない限り）好きなように変えられることになります\n  * **しかしながら、このことは明らかに課題を抱えることになります**……迅速なフィードバックを得られなくなってしまうからです（→6・7章）\n\n---\n\n## 感想と考察\n\nここからは本を読みながら、私が思ったことや考えたことを書きます。\n\n### リファクタリングへの耐性を持つことが常に必要\n\n今回読んだ範囲では「良い単体テストを構成する4本の柱」について説明されていましたが、その中でも一貫して重要視されていたのが2本目の柱「リファクタリングへの耐性」です。\n\nリファクタリングへの耐性を持たせるためのコツは「観測可能な振る舞い」のみをテストし、それを得るまでの過程は見ないということです（how ではなく what をみる）。そのため E2E テストは退行に対する保護を最大限に備えていると言えます。私が所属するチームでも E2E テストのことを普段「リグレッション・テスト」と呼んでおり、その通りだなと思いました。\n\n一方で E2E テストには実行時間が長くかかってしまうので、E2E テストだけで開発を行うのは厳しいです。しかしながら、筆者は第5章で「システム内コミュニケーションは実装の詳細になります」と言い、観測可能な振る舞いではない（テストで見るべき最終的な結果ではない）としています。そうなるとほとんどやっていることは E2E テストと同じなので単体テストの範疇ではない気がします。これは明らかな矛盾ですが、ここについては第6・7章で説明してくれるようなので続きを楽しみにしたいと思います。\n\nまた、単体テストがカバーする範囲を広くしすぎると p-r をレビューする時に、対象のコードが問題ないかの判断をするのが難しくなるのではないかな？という疑問点が浮かんできました。テスト粒度のバランスについても以降の章で説明があるのを期待しています。\n\n### モックとスタブ\n\nモックに関連して5つの用語が出てきました。モック・スパイ・スタブ・ダミー・フェイクです。正直、これらの役割のものは全部モックだと思っていました。言葉の意味を知ったからには意識して使い分けていこうと思います。\n\nここで重要だと思ったのは「スタブとのやりとりを決して検証してはならない」という点です。\n\nリファクタリングへの耐性の話でも出てきたように、観測可能な振る舞いのみをテストするべきとうことと一貫して、テスト対象システムが持ってくる値を検証することは、テスト対象システムの実装の詳細（how）を調べることになり、過剰検証となります。\n\n今まで実装してきた単体テストを思い返してみて、これをやってしまっていることはあまりないとは思いますが、うっかりするとやってしまいそうなので意識していきたいです。\n\n## まとめ\n\n以上、第2部「単体テストとその価値」の前半についてのまとめと所感を拙文ながら書きました。気づきが多いので、自分が携わるコードでもこの本で得た知識を導入しようと試みています。早く全部読み切らなきゃ。ではでは。\n","tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}]},{"title":"単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部","date":"2023-01-17T00:00:00.000Z","ref":"/posts/2023/01/unit-testing-principles-practices-and-patterns-part1","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n今回は第1部「単体（unit）テストと","draft":false,"content":"\n[『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）](https://book.mynavi.jp/ec/products/detail/id=134252)を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n今回は第1部「単体（unit）テストとは」についてのまとめになります。第1部は以下の3章で構成されています。\n\n* 第1章：なぜ、単体（unit）テストを行うのか？\n* 第2章：単体テストとは何か？\n* 第3章：単体テストの構造的解析\n\nまず、各章の内容の要約（切り抜き）を書き、その後に考察してみたいと思います。\n\n---\n\n## 第1章：なぜ、単体（unit）テストを行うのか？\n\n* テストの質が悪ければ、テストをまったくしない場合と同じ結果になる（p.8）\n* **テスト・ケースは多いほど良い……は間違いです。なぜなら、コードは資産ではなく負債だからです**（p.10）\n* 質の良いテスト・ケースだけを集めることに意識を向けなくてはなりません（p.10）\n* **網羅率はテスト・スイートの質が悪いことを示せても、テスト・スイートの質が良いことを証明することはできない**（p.11）\n* 部分的にしか検証されないテストを極端にしたものが確認不在のテスト（p.16）\n  * テスト対象のコードを単に実行するだけで、何も確認していないテストのこと\n* **優れたテスト・スイート**（pp.20-21）\n  * テストすることが開発サイクルの中に組み込まれている\n  * コードベースの特に重要な部分のみがテスト対象となっている\n    * 核となる部分は……ドメイン・モデル\n    * ドメイン・モデルをコードベースの本質ではない部分から隔離しておかなくてはならない\n  * 最小限の保守コストで最大限の価値を生み出すようになっている\n\n---\n\n## 第2章：単体テストとは何か？\n\n* 単体テストの定義（p.28）\n  * 「単体（unit）」と呼ばれる少量のコードを検証する\n  * 実行時間が短い\n  * 隔離された状態で実行される\n* **ロンドン学派が考える隔離**（p.29）\n  * テスト対象となるクラスが他のクラスに依存しているのであれば、その依存をすべてテスト・ダブルに置き換えなくてはならない\n* **古典学派が考える隔離**（pp.37-38）\n  * 隔離する必要があるのはコードではなくテスト・ケースであり、各テスト・ケースをお互いに影響を与えることなく個別に実行できるようにしなくてはならない\n  * 共有依存、プライベート依存、プロセス外依存\n  * テスト・ダブルが使われるのはテスト・ケース間で共有される状態を持つ依存に対してのみです\n* ロンドン学派は……依存の種類によってはテスト・ダブルに置き換えずにそのまま使うことを許す場合がある……もし依存が不変（immutable）であれば、その依存はテスト・ダブルに置き換える必要はありません……このような不変オブジェクトは値オブジェクト、もしくは、単に値と呼ばれます（pp.41-42）\n* **私個人は古典学派のスタイルのほうを好んでいます**。その理由は、**古典学派のほうがより良質な単体テストを作成でき、単体テストの究極的な目標である、プロジェクトの持続的な成長を促す、ということを達成するのに向いているからです**。このようになるのは、ロンドン学派のスタイルで作成するモックを用いた単体テストは古典学派のスタイルで作成する単体テストよりも壊れやすくなるからです（p.46）\n* ロンドン学派の主張に対する反論\n  * 細かな粒度による検証（p.47）\n    * 単体テストでは、1単位のコード（a unit of code）を検証するのではなく、1単位の振る舞い（a unit of behavior）を検証するようにします……コードの粒度を細かくしようとすることは単体テストにおいてあまり有用ではありません\n  * 複雑な依存関係を持つものに対する単体テスト（pp.48-49）\n    * 本来考えるべきことは……複雑な依存関係を構築しなくても済むようにするための方法\n  * テストが失敗した際、どこに問題があったのかが正確に分かる（p.49）\n    * 単体テストを頻繁に実施していれば……どこでバグが発生したのかをすぐに見つけ出せる\n* 古典学派の観点で再定義（p.52）\n  * **1単位の振る舞い（a unit of behavior）を検証すること**\n  * 実行時間が短いこと\n  * **他のテスト・ケースから隔離された状態で実行されること**\n* E2E（End-to-End）テスト（pp.53-54）\n  * 一種の統合テストとして見ることができる\n  * UI（User Interface）テスト、GUI（Graphical User Interface）テスト、機能（functional）テストなどと呼ばれることもあります\n\n---\n\n## 第3章：単体テストの構造的解析\n\n* AAAパターン（3Aパターンとも呼ばれる）……では、**テスト・ケースを準備（Arrange）、実行（Act）、確認（Assert）の3つのフェーズで構成します**（p.58）\n* 確認（Assert）フェーズで確認する項目はどのくらいあればよいのか？（pp.65-66）\n  * 1単位の振る舞いによって複数の結果が生じることはあり得ること\n  * とは言え、確認フェーズが大きくなりすぎるのであれば、開発者は危機感を持たなくてはなりません\n  * オブジェクトの全フィールドの値を確認しているのであれば、そのようなことをするのではなく、そのオブジェクトが同等であることを確認できる手段を用意するようにします\n* **テスト・フィクスチャの準備をテスト・クラスのコンストラクタで行えば……記述するコードの量は劇的に減ることになります**。しかしながら、この方法には、次にあげる**2つの重大な欠点**があります（p.72）\n  * テスト・ケース間の結び付きが強くなってしまう\n  * テスト・ケースが読みづらくなってしまう\n* **共通的に利用するテスト・フィクスチャの準備に関するコードをプライベートなファクトリ・メソッドに定義する**ことで、テスト・コードの量を減らすのと同時に各テスト・ケースで何が行われるかを完全に理解できるようになります（p.75）\n* しかしながら、テスト・フィクスチャの準備をコンストラクタで行うことに関して、1つ例外があります。それは、すべてのテスト・ケース（もしくは、ほぼすべてのテスト・ケース）で同じテスト・フィクスチャを使うようになっているのであれば、コンストラクタを使ってもよい、ということです（p.76）\n* **単体テストでの名前の付け方**\n  * 非常に有名で、おそらく、もっとも役に立たないのが次のような命名規則です（pp.77-78）\n    * `{テスト対象メソッド}_{事前条件}_{想定する結果}`\n    * 実用性がない理由は、目を向けている部分が振る舞いではなく実装の詳細だからです\n    * このようなことをするよりも、簡潔な普通の言い回しにしたほうが何を検証しているのかがより明確になる\n    * 非開発者がこのテスト・メソッド名を見ても、このテスト・メソッドが何を検証するものなのかが全く伝わらないはずです\n  * テスト・メソッドに名前を付けるときの指針（p.79）\n    * **厳格な命名規則に縛られないようにする**\n    * **問題領域のことに精通している非開発者に対して、どのような検証をするのかが伝わるような名前を付ける**\n    * （英語の場合は）アンダースコア（「_」）を使って単語を区切るようにする\n  * 指針に従った名前に変えた場合の例（pp.80-82）\n    * `IsDeliveryValid_InvalidDate_ReturnsFalse` → `Delivery_with_invalid_date_should_be_considered_invalid`\n    * さらなる改善が可能\n      1. `Delivery_with_past_date_should_be_considered_invalid`\n      2. `Delivery_with_past_date_should_be_invalid`\n      3. `Delivery_with_past_date_is_invalid`\n      4. `Delivery_with_a_past_date_is_invalid`\n* パラメータ化テストを使うことで、テスト・コードの量を劇的に減らせるようになります。しかしながら、この利点と引き換えに課せられる負担……とは、このテスト・メソッドが何の事実を表現しているのかが分かりづらくなる、ということです。この対応策として、正常系のテスト・ケースのみを独自のテスト・グループとして抜き出す（p.85）\n\n---\n\n## 感想と考察\n\nここからは本を読みながら、私が思ったことや考えたことを書きます。\n\n### 本を読む前のテストに対する認識\n\nまず前提として、本を読む前の私のテストに対する認識をまとめます。\n\n* 単体テストは普段から書いている\n  * Python と [pytest](https://docs.pytest.org/en/7.2.x/) を使用\n  * カバレッジは100%にしようというチームのルールがある\n  * CI パイプラインに組み込まれている\n* モックの使い方にいまいち自信がない\n  * 自作自演になっている気がする時がある\n* データベースのテストはやるべきか迷う\n* ラージテスト・スモールテスト、統合テスト、退行テストなどの用語の正確な意味や使い分けを知らない\n* TDD について勉強したことはない\n\n上記のような感じで、あらためて振り返るとテストに関して自分がなんとなくやってきたことがさらけ出されてしまいました。今回の本では、私のようなレベルの読者でも引っかかることなく親切に解説されています。\n\n### 古典学派 vs ロンドン学派\n\n学びは色々とあるのですが、まず知ったのは「古典学派」と「ロンドン学派」がある、ということです。古典学派は[『テスト駆動開発』（Kent Beck 著、和田卓人訳）](https://www.ohmsha.co.jp/book/9784274217883/)を原点としています。ロンドン学派はロンドンのプログラミング・コミュニティで生まれたことに由来しています。ロンドン学派は1単位のコードをテストするために、テスト対象以外の依存はモックを使うようにするべきと考えていて、古典学派は1単位の振る舞いをテストするために、単体テスト同士が状態を共有する依存に対してのみモックを使うべきと考えています。\n\n私の所属するチームでは明確にどちらの学派の主張を採用しているわけではありませんが、どちらかというとロンドン学派に近いように感じました。各メソッドを「1単位のコード」と見て、単体テストを書いています。モックに関してはロンドン学派ほど厳格ではないですが、例えば lib は lib で単体テストを行っているという理由で、lib の呼び出し側に対する単体テストでは lib をモックするというようなケースはしばしばあります。\n\n筆者が指摘する通り、私のコードベースでは1つをリファクタするとそのテストや周辺のテストも直さないといけないので、これは維持コストのかかる良くないテストコードなのかも、ということに気づきました。\n\n### テスト・フィクスチャ\n\n第3章の「テスト・フィクスチャの準備」についての議論も興味深かったです。本の中ではコンストラクタを使って繰り返し同じ記述を書くことを避けることに関して、「テスト・ケースが読みづらくなってしまう」ことに言及しています。\n\n私はテストクラスでコンストラクタを使うことはあまり多くないですが、[pytest.fixture を autouse=True にする](https://docs.pytest.org/en/7.2.x/how-to/fixtures.html#autouse-fixtures-fixtures-you-don-t-have-to-request)ことは多いです。コードの量を削減できる一方で、これも多用しすぎるとテストコードが読みにくくなってしまうので気を付けたいと思いました。\n\n### 命名規則\n\n命名規則に関しては以下のようなルールを設けています。前提として、テスト対象のメソッドに対して、テストクラスを1つ作るルールになっています。下記の命名はそのテストクラスのメソッド名に対するものです。\n\n* 正常系\n  * `test_success` もしくは `test_success_{事前条件}`\n    * e.g. `test_success_when_hoge_is_fuga`\n* 異常系\n  * `test_failure_{事前条件}`\n    * e.g. `test_failure_when_hoge_is_invalid`\n\n本ではよくある（そして役に立たない）命名規則の例として `{テスト対象メソッド}_{事前条件}_{想定する結果}` というものが挙げられていますが、私のチームでもテスト対象メソッドごとにテストクラスを作っている時点で、想定する結果（success/failure）や事前条件（when～）もあるので、これに該当してしまっていると思いました。\n\nただ、これに関しては私自身そこまで悪いとは思っていません。ルールがあるといっても、頭に `test_success` `test_failure` をつけているだけですし、この程度ならむしろ見やすくて良いと思います。しかしながら、そもそもこのテストクラスの作り方の枠組み自体が、振る舞いよりもコードの実装に目が行くものなのは確かなので、この点に関しては本の続きを読みながらより良くしていくためにどうするべきかを考えていきたいと思っています。\n\n## まとめ\n\n以上、第1部「単体（unit）テストとは」についてのまとめと所感を拙文ながら書きました。\n\nまだ途中ですが、読みやすく面白い予感なので、気になった方は是非本を手に取って読んでみてください！\n","tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}]},{"title":"SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ","date":"2023-01-12T00:00:00.000Z","ref":"/posts/2023/01/sqlalchemy-dealing-with-disconnects","desc":" FastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2","draft":false,"content":"\nFastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2.1.1\n\n## 問題\n\n```\nMySQLdb.OperationalError: (2006, 'MySQL server has gone away')\n```\n\n最後に MySQL サーバーに接続してから一定時間（デフォルトで8時間）が経過すると上記のエラーにより DB へのアクセスに失敗します。\n\n## 原因\n\nSQLAlchemy には Connection Pooling という、DB サーバーとのコネクションを内部的に保持する機能が存在します。また、MySQL には一定時間（デフォルトで8時間）が経過するとコネクションを破棄する機能が存在します。\n\nその結果、SQLAlchemy 側で保持しているコネクションを使ってクエリを投げたりしても、MySQL 側でコネクションが破棄されている場合には `MySQL server has gone away` のエラーが出てしまうことになります。\n\n`show global variables like 'wait_timeout';` によって、現在設定されている `wait_timeout` の秒数を知ることができます。\n\n```\nmysql> show global variables like 'wait_timeout';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| wait_timeout  | 28800 |\n+---------------+-------+\n1 row in set (0.00 sec)\n```\n\n生きているコネクションは `show processlist` で知ることができます。`Time` が経過時間（秒）です。\n\n```\nmysql> show processlist;\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n| Id      | User  | Host            | db   | Command | Time  | State    | Info             |\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n| 1200000 | scott | localhost:47000 | test | Query   |     0 | starting | show processlist |\n| 1200001 | scott | localhost:47001 | test | Sleep   |  3600 |          | NULL             |\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n2 rows in set (0.00 sec)\n```\n\n## 解決方法\n\n[SQLAlchemy の公式ドキュメント](https://docs.sqlalchemy.org/en/20/core/pooling.html#dealing-with-disconnects)に書かれているように、大きく「悲観的」「楽観的」2つのアプローチがあります。\n\nどちらを採用するかは要件や好みによると思います。どちらの方法にしても、コネクションプールからチェックアウトした後に MySQL 側で破棄されてしまうようなケースでは無効なのでご注意ください（一度の処理でそんなに長く扱うことは少ないとは思いますが）。\n\n### 悲観的アプローチ\n\nコネクションプールから取り出すときに、そのコネクションがまだ生きているかどうかをテストする方法です。私は今回こちらを採用しました。\n\nコネクションのチェックアウト時に若干のオーバーヘッドができてしまいますが、最もシンプルで信頼できるアプローチとされています。\n\n```py\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+mysqldb://scott:tiger@localhost/test\", pool_pre_ping=True)\n```\n\n### 楽観的アプローチ\n\n一定時間ごとにコネクションを張り直す方法です。例えば、DB サーバー側で28800秒に設定されているのならば、それよりも短く設定すればよいです。\n\n使っていても使っていなくても一定時間おきに DB へのリクエストが飛んでしまいますが、コネクションのチェックアウト時にオーバーヘッドが発生しないのが利点です。\n\n```py\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+mysqldb://scott:tiger@localhost/test\", pool_recycle=3600)\n```\n\n## 参考文献\n\n* [Connection Pooling](https://docs.sqlalchemy.org/en/20/core/pooling.html)\n* [Python: SQLAlchemy で 'MySQL server has gone away' になる問題を解決する](https://blog.amedama.jp/entry/2015/08/15/133322)\n* [full-stack-fastapi-postgresql/session.py at master · tiangolo/full-stack-fastapi-postgresql](https://github.com/tiangolo/full-stack-fastapi-postgresql/blob/master/%7B%7Bcookiecutter.project_slug%7D%7D/backend/app/app/db/session.py)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"}]},{"title":"2023年版 キーボードマッピングの個人的メモ","date":"2023-01-08T00:00:00.000Z","ref":"/posts/2023/01/keyboard-remap","desc":" 不定期的に「あーでもない、こーでもない」と言ってキーボードのマッピングをいじりだしてしまうことってありますよね。私はあります。限りあるキーの中から自分にとっての最適解を見つける作業はなんだかんだ楽しいです。\n\n今回は 2023 年版、私のキーボードのマッピングを書きとめておこうと思います。\n\n過去","draft":false,"content":"\n不定期的に「あーでもない、こーでもない」と言ってキーボードのマッピングをいじりだしてしまうことってありますよね。私はあります。限りあるキーの中から自分にとっての最適解を見つける作業はなんだかんだ楽しいです。\n\n今回は 2023 年版、私のキーボードのマッピングを書きとめておこうと思います。\n\n過去の記事: [Windows10 と PowerToys で US キーボードでも無変換・変換キーを使って IME を一発で切り替える](https://qiita.com/SogoK/items/7e0ea37c3e958c39608c)\n\n## 環境\n\n* 使うパソコン\n  * Windows デスクトップ\n  * Windows ラップトップ\n  * MacBook Air (2022)\n* 使うキーボード\n  * HHKB（US 配列）\n  * MacBook Air 内蔵キーボード（US 配列）\n\n仕事は Windows ラップトップ + HHKB なので、この組み合わせで作業する時間が一番長いです。MacBook Air で作業する時は基本的には内蔵キーボードを使いますが、HHKB を接続することもしばしばあります。\n\n## 結論\n\n結局仕事でパソコンを触る時間の方が長いので、Windows + HHKB の組み合わせで使う状況を優先しました。\n\n- HHKB なので、`Control` は `Caps Lock` の位置\n- スペースキーの左右はそれぞれ Mac の `英数` `かな` キーにする\n  - Windows でも Mac の `英数` `かな` キーをちゃんと認識して IME の切り替えをやってくれる\n  - なので過去記事で紹介した PowerToys を使用したハックは不要\n- 上記によってスペースキー左右の `Windows/Command` キーが消えてしまうので、`左 Alt/Option` を `Windows/Command` にする\n- Mac では Karabiner Elements を使用して Windows での操作感に寄せていく\n  - Mac の `Command` と Windows の `Control` が同じ位置に来るようにする\n\n## 実現方法\n\n使うツールは以下の 2 つです。\n\n- [Happy Hacking Keyboard キーマップ変更ツール](https://happyhackingkb.com/jp/download/)\n- [Karabiner Elements](https://karabiner-elements.pqrs.org/)\n\n### Happy Hacking Keyboard キーマップ変更ツール\n\n![HHKB](/images/posts/2023/01/keyboard_hhkb_remap.png)\n\n変更点としては\n\n- `左♢` を `英数` に\n- `右♢` を `かな` に\n- `左 Alt/Option` を `Control` に\n\nこれによって Windows でも Mac でもスペースキーの左を押せば英字入力、スペースキーの右を押せばかな入力にモードを切り替えられます。今となってはこれ以外の IME 切り替え方法は面倒すぎて耐えられません。\n\nそして、この変更によって `♢` が消滅したので `Windows/Command` キーが使えなくなってしまいます。そのため `左 Alt/Option` を `♢` に変更します。`Alt/Option` は左右にあるのでどちらを変更してもいいのですが、個人的には `Windows + Shift + S`（スクリーンショット）や、（Mac では `Command` と `Control` を入れ替えるため）`Control + C` の組み合わせなどが左手だけで押せた方が便利なので、左側を `♢` にしました。  \n本当は左側の `Alt/Option` もあるのが理想なのですが、`Alt/Option` を使うのは VS Code で複数行選択するときがほとんどなので、マウスとの組み合わせですしまだなんとかなると判断しました。\n\nWindows でも Mac でも DIP スイッチは変更せずに、常に同じモードで使います。DIP スイッチについては[公式ページ](https://happyhackingkb.com/jp/products/discontinued/hhkb_backview.html)を参照ください。\n\n| キー | ON/OFF |\n| ---- | ------ |\n| SW1  | OFF    |\n| SW2  | OFF    |\n| SW3  | ON     |\n| SW4  | OFF    |\n| SW5  | OFF    |\n\n参考: HHKB のデフォルトのキー配列\n\n![HHKB のデフォルトのキー配列](https://happyhackingkb.com/jp/products/image/leaflet/pro_keytop_a_l.jpg)\n\n### Karabiner Elements（基本的な設定）\n\nWindows では OS 側での設定は特に行わず、HHKB に書き込んだ設定のみで使用します。  \nここから、Mac で Windows での操作感に寄せていくための調整をやっていきます。\n\n#### 修飾キーを入れ替える\n\nまず、修飾キーを入れ替えていきます。修飾キーの入れ替えは Mac の標準機能で実現できるのですが、ツール統一の観点から Karabiner Elements で実施します。\n\nMac の内蔵キーボード（US 配列）の `Caps Lock` を HHKB 風に Windows での `Control` 相当である `Command` にします。\n\n![内蔵キーボード](/images/posts/2023/01/keyboard_ke_internal.png)\n\nHHKB の `左 Command` と `左 Control` を入れ替えます。これにより、一般的に `Caps Lock` の位置のキーが `Command` になります。一番手前の列の左端が `Control` です。\n\n![HHKB](/images/posts/2023/01/keyboard_ke_hhkb.png)\n\n#### Mac 内蔵キーボードの左右 `Command` を `英数` `かな` にする\n\nKarabiner Elements の `Complex Modifications` → `Add rule` → `Import more rules from the Internet (Open a web browser)` と進みます。\n\n[https://ke-complex-modifications.pqrs.org/](https://ke-complex-modifications.pqrs.org/) が開くので、`RDP for Japanese, US Keyboard （リモートデスクトップとUSキーボード、日本語環境の設定）` を import します。リモートデスクトップを使わなければ `For Japanese （日本語環境向けの設定） (rev 6)` でも OK です。\n\n`[RDP] RDPアプリ以外では、コマンドキーを単体で押したときに、英数・かなキーを送信する。（左コマンドキーは英数、右コマンドキーはかな） (rev 3)`（`コマンドキーを単体で押したときに、英数・かなキーを送信する。（左コマンドキーは英数、右コマンドキーはかな） (rev 3)`）のルールを追加します。\n\nこれにより、HHKB での `英数` `かな` と同じ機能が実現します。本来の位置の左右 `Command` も単押しでなければ引き続き利用可能です。\n\n### Karabiner Elements（細かい設定）\n\n上記の設定で基本的には OK ですが、まだ細かいところで違いがあるので合わせていきます。\n\n#### `Home` `End` キーで行端に移動する\n\n先ほどと同じように、今度は `PC-Style Shortcuts` を探して import します。\n\n`Home key to the beginning of the line (Control + a)` および `End key to the end of the line (Control + e)` のルールを追加します。\n\n#### 日本語入力時の `Control + T/U/I/O/P` を復活させる\n\nHHKB で日本語を入力している方なら使っていることも多いと思われる `Control + T/U/I/O/P` というショートカットがあります。Windows で使えるショートカットですが、Mac でも `Windows 風のキー操作` を有効にすることで使えます。\n\n![Mac IME](/images/posts/2023/01/keyboard_mac_ime.png)\n\n| Windows ショートカット | Mac ショートカット         | 変換先   | F キー |\n| ---------------------- | -------------------------- | -------- | ------ |\n| Control + T            | Control + T                | 半角英数 | F10    |\n| Control + U            | Control + U                | 全角かな | F6     |\n| Control + I            | Control + I                | 全角カナ | F7     |\n| Control + O            | 不明 (Option + A は使えた) | 半角ｶﾅ   | F10    |\n| Control + P            | Control + P                | 全角英数 | F9     |\n\nこれらに関しては、半角ｶﾅを除いて、どちらも `Control` なので、`Caps Lock` 位置に Windows では `Control` を、Mac では `Command` を置く運用だと位置がずれてしまいます。\n\nなので、`Command + T/U/I/O/P` で、Windows と同じような動作をするように変更します。なぜか `Control + O` だけ Windows と互換性がない（半角英数になってしまう）ので、`Option + A` にします。\n\n試してみたい方は [japanese_cmd_tuiop.json](https://raw.githubusercontent.com/SogoKato/KE-complex_modifications/feature/cmd-tuiop/public/json/japanese_cmd_tuiop.json) をダウンロードして `~/.config/karabiner/assets/complex_modifications` ディレクトリ内に保存してください。\n\n（使ってみて安定していたらプルリクを出そうと思います）\n\n上記をすべて設定するとこんな感じです。\n\n![complex modifications](/images/posts/2023/01/keyboard_ke_complex.png)\n\n## 最後に\n\n以上が、2023年版 私のキーボードマッピングでした。多分向こう半年くらいはこの設定で行くと思います。ではでは。\n","tags":[{"name":"キーボード","ref":"/tags/キーボード"}]},{"title":"プロキシ環境でKubernetes構築（Containerd+Calico）","date":"2022-12-27T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-behind-proxy","desc":" 同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4","draft":false,"content":"\n同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4GB）\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.14\n* Calico v3.24.5\n\nコントロールプレーン、ノード1台ずつの構成とします。プロキシを経由しなければインターネットに出られないようになっています。\n\n![network](//www.plantuml.com/plantuml/png/SoWkIImgAStDuSehJybCJ5Uevb9Go4ijASylobP8pybFIim12O51KNvfIMgHDP1NYwIee2YpBB4a5QugCIMbABMuMC5MGSdGt4ZFs53FGCz0tz1CoPeBnHo5Q6mg3PLYhQ7AalFpIehoSmfo4lDIOM9v-Icf40VKSZcavgK07Gu0)\n\nプライベートネットワークの CIDR は `172.31.0.0/16`、プロキシは `http://172.31.0.1:3128` として進めます。\n\nService CIDR はデフォルトの `10.96.0.0/12` を、Pod Network CIDR は Calico のデフォルトである `192.168.0.0/16` を使います。\n\n💡 筆者の環境ではこの記事で紹介する内容で構築できましたが、環境によって状況が異なる可能性があります。プロキシ配下での構築に挑戦する前に、**まずは似た環境のインターネット接続があるサーバーで試すことをおすすめします**。\n\n## プロキシの設定が必要な箇所\n\n### 環境変数（`~/.bashrc`）\n\n#### コントロールプレーン\n\n```sh\nexport HTTP_PROXY=http://172.31.0.1:3128\nexport HTTPS_PROXY=http://172.31.0.1:3128\nexport NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12,192.168.0.0/16\n```\n\nコントロールプレーンでは `NO_PROXY` に Sercice CIDR の IP レンジ（デフォルトは `10.96.0.0/12`）と Pod Network CIDR の IP レンジを設定しておくことで `kubeadm init` 時の preflight check の WARNING を抑えることができます[^1]。\n\n反映するには `source ~/.bashrc` します。\n\n[^1]: 以前は IP レンジを指定できなかったようですが、今は問題なく使えます。https://github.com/kubernetes/kubeadm/issues/324#issuecomment-331483277\n\n#### ノード\n\n```sh\nexport HTTP_PROXY=http://172.31.0.1:3128\nexport HTTPS_PROXY=http://172.31.0.1:3128\nexport NO_PROXY=localhost,127.0.0.1,172.31.0.0/16\n```\n\nノードでは `kubeadm init` を実行しないのでこれだけで OK。\n\n### `/etc/apt/apt.conf`\n\n各種ライブラリのインストールのために必要です。\n\n```\nAcquire::http::proxy \"http://172.31.0.1:3128\";\nAcquire::https::proxy \"http://172.31.0.1:3128\";\n```\n\n### `/etc/systemd/system/containerd.service.d/http-proxy.conf`\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12\"\n```\n\n`NO_PROXY` に Pod Network CIDR の IP レンジも追加しようかと思ったのですが、ノードを跨いだ Pod 間の通信など試した範囲では追加しなくても異常がなかったので追加していません。  \n筆者の Kubernetes の知識が浅いだけかもしれないので、検証不足でしたら教えていただけるとありがたいです。🙇\n\nこのファイルを変更したら Containerd の再起動が必要です。\n\n```sh\nsystemctl daemon-reload\nsystemctl restart containerd\n```\n\n## 構築手順\n\n上記のプロキシ設定以外は通常の手順と同じです。\n\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n\nUbuntu 22.04 で構築する際の注意点については [Ubuntu 22.04でのKubernetesクラスター構築（ContainerdとSystemdCgroup）](/posts/2022/12/kubernetes-ubuntu22.04-cgroup-systemd) をご参照ください。\n\n```sh\nkubeadm init --pod-network-cidr 192.168.0.0/16\n```\n\n### ネットワークプラグインの適用\n\n構築が完了したらネットワークプラグインを適用します。以下は Calico を使う場合のコマンドです。\n\n```sh\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/calico.yaml -O\nkubectl apply -f calico.yaml\n```\n\n`kubectl -n kube-system get po -w` して、1つの `calico-kube-controllers` とノード数分の `calico-node` Pod が Running なら問題ありません。CoreDNS がクラッシュするバグを踏んだら [KubernetesでCoreDNSがループしてしまう問題への対処](/posts/2022/12/kubernetes-coredns-loop) の記事を参考にしてみてください。\n\n## 動作確認\n\n簡単な動作確認をしてみます。\n\n```sh\nkubectl create deployment nginx --image=nginx\n```\n\n```sh\nPOD_NAME=$(kubectl get pods -l app=nginx -o jsonpath=\"{.items[0].metadata.name}\")\n```\n\n別のシェルを開き、`curl localhost:8080` を試してみます。\n\n```sh\nkubectl port-forward $POD_NAME 8080:80\n```\n\nログを見てみます。\n\n```sh\nkubectl logs $POD_NAME\n```\n\nexec を試します。\n\n```sh\nkubectl exec -ti $POD_NAME -- nginx -v\n```\n\nNodePort Service を試します。\n\n```sh\nkubectl expose deployment nginx --port 80 --type NodePort\n```\n\n```sh\nNODE_PORT=$(kubectl get svc nginx \\\n  --output=jsonpath='{range .spec.ports[0]}{.nodePort}')\n```\n\n```sh\ncurl 127.0.0.1:$NODE_PORT\n```\n\n```sh\nkubectl delete svc nginx\n```\n\n次に Cluster IP Service を試します。\n\n```sh\nkubectl expose deployment nginx --port 80 --type ClusterIP\n```\n\nクライアントを想定した Pod を建てます（nginx ですが）。\n\n```sh\nkubectl create deployment client --image=nginx\n```\n\n```sh\nPOD_NAME_CLIENT=$(kubectl get pods -l app=client -o jsonpath=\"{.items[0].metadata.name}\")\n```\n\nPod 内で `curl nginx` を実行します。\n\n```sh\nkubectl exec -ti $POD_NAME_CLIENT -- curl nginx\n```\n\n`>Welcome to nginx!` の HTML が返ってこれば OK！\n\n## トラブルシューティング集\n\n### `FailedCreatePodSandBox` - ホストのプライベート IP にアクセス不可\n\n`calico-kube-controllers` が ContainerCreating で止まってしまう問題が発生しました。\n\n```\nEvents:\n  Type     Reason                  Age                 From               Message\n  ----     ------                  ----                ----               -------\n  Warning  FailedScheduling        115s                default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..\n  Normal   Scheduled               104s                default-scheduler  Successfully assigned kube-system/calico-kube-controllers-7bdbfc669-97wdp to controlplane\n  Warning  FailedCreatePodSandBox  103s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox \"6a029253befac6840d358f8f78b865510bb3874b971fc7241d4ded6b1e92ce2d\": plugin type=\"calico\" failed (add): stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/\n  Normal   SandboxChanged          16s (x3 over 103s)  kubelet            Pod sandbox changed, it will be killed and re-created.\n```\n\n`stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/` のエラーメッセージが出ていますが、実際にはマウントはできていました。\n\n「マウントはできて nodename（ホスト名）は取得できているが、プロキシに阻まれて通信できていないのでは？」と考え、Containerd の NO_PROXY の設定にホストのプライベートネットワークの CIDR を追記したら `172.31.0.0/16` たらこの問題は解決しました。\n\n```\n# vim /etc/systemd/system/containerd.service.d/http-proxy.conf\n```\n\n`172.31.0.0/16` を追記。\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16\"\n```\n\n```\n# systemctl daemon-reload\n# systemctl restart containerd\n# kubectl -n kube-system delete po calico-kube-controllers-7bdbfc669-97wdp --force\nWarning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\npod \"calico-kube-controllers-7bdbfc669-97wdp\" force deleted\n```\n\n### `FailedCreatePodSandBox` - Service の IP にアクセス不可\n\n状況は変わったものの、こちらも `calico-kube-controllers` が ContainerCreating で止まってしまう問題です。\n\n```\nEvents:\n  Type     Reason                  Age                From               Message\n  ----     ------                  ----               ----               -------\n  Normal   Scheduled               3m12s              default-scheduler  Successfully assigned kube-system/calico-kube-controllers-7bdbfc669-9gltp to controlplane\n  Warning  FailedCreatePodSandBox  72s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox \"68070146a6bd3c3a3044cbe84495c39ef3abafd069f171db2a185c8925aee2d1\": plugin type=\"calico\" failed (add): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": Service Unavailable\n  Normal   SandboxChanged          12s (x2 over 72s)  kubelet            Pod sandbox changed, it will be killed and re-created.\n```\n\nこちらはエラーメッセージの通りなので、Service CIDR を Containerd の NO_PROXY に追加します。\n\n```\n# vim /etc/systemd/system/containerd.service.d/http-proxy.conf\n```\n\n`10.96.0.0/12` を追記。\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12\"\n```\n\n先ほどと同じように daemon-reload, restart containerd, Pod の強制削除をします。\n\n## まとめ\n\n最後までお読みいただきありがとうございます。\n\nプロキシ環境での Kubernetes クラスター構築は、通常のクラスター構築よりも Kubernetes のネットワーク周りの知識が要求されるので少しハードルが上がります。\n\n冒頭にも書きましたが、まずはインターネットに直接繋がる環境で構築を試してみて、その後にプロキシ環境での構築を実施すると原因の切り分けがスムーズになると思います。\n\n## 参考文献\n\n* [Installing kubernetes behind a corporate proxy](https://medium.com/@vivekanand.poojari/installing-kubernetes-behind-a-corporate-proxy-bc5582e43fb8)\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n* [Install Calico networking and network policy for on-premises deployments](https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises)\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}]},{"title":"Ubuntu 22.04でのKubernetesクラスター構築（ContainerdとSystemdCgroup）","date":"2022-12-26T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-ubuntu22.04-cgroup-systemd","desc":" 公式ドキュメントのコマンドを手順通り流し込めば割と簡単に構築できる Kubernetes クラスターですが、Ubuntu 22.04 になってから少し手を入れる必要が出てきたので差分を紹介しておきます。\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* k","draft":false,"content":"\n公式ドキュメントのコマンドを手順通り流し込めば割と簡単に構築できる Kubernetes クラスターですが、Ubuntu 22.04 になってから少し手を入れる必要が出てきたので差分を紹介しておきます。\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.14\n\n## 何が変わった？\n\nUbuntu 21.10 以降、Cgroup v2 がデフォルトになりました[^1]。  \nCgroup について詳しく知りたい方は [第37回 Linuxカーネルのコンテナ機能 ― cgroupの改良版cgroup v2［1］](https://gihyo.jp/admin/serial/01/linux_containers/0037)の記事がわかりやすいので読んでみてください。\n\nKubernetes においては「cgroupドライバー」を kubelet の設定で選択します。`cgroupfs` ドライバーが v1 に、`systemd` ドライバーが v2 に対応していると考えれば問題ないと思います。\n\n[^1]: https://wiki.ubuntu.com/UbuntuWeeklyNewsletter/Issue697\n\n## 何もしないとどうなる？\n\nコンテナは起動しますが、使い物にならないくらい不安定になり再作成を繰り返します。システムコンポーネントのコンテナ（kube-apiserver）も例外でないので、kubectl を叩いてもレスポンスが返ってこなかったり。。\n\n## 解決方法\n\nCgroup v1 に戻す、というやり方もあるとは思うのですが、systemd を Cgroup ドライバーとして設定すれば Cgroup v2 のままで使えるようになるので、新しくクラスターを構築するのであればそうするのがおすすめです。\n\nkubelet に関しては kubeadm v1.22 以降デフォルトで `systemd` を選択するようになったので[^2]、特に気にする必要はないです。\n\n[^2]: 備考: v1.22では、ユーザーがKubeletConfigurationのcgroupDriverフィールドを設定していない場合、kubeadmはデフォルトでsystemdを設定するようになりました。  \nhttps://kubernetes.io/ja/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/#kubelet-cgroup%E3%83%89%E3%83%A9%E3%82%A4%E3%83%90%E3%83%BC%E3%81%AE%E8%A8%AD%E5%AE%9A\n\n**Containerd を CRI として使用する場合、Containerd 側でも Cgroup ドライバーを選択する必要があります（今回の記事のミソ）。**\n\n[Containerd のインストール手順](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/#containerd%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB)に下記のコマンドがありますが、その下にさらに大事なことが書かれています[^3]。\n\n```sh\n# containerdの設定\nmkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n# containerdの再起動\nsystemctl restart containerd\n```\n\n> `systemd`のcgroupドライバーを使うには、`/etc/containerd/config.toml`内で`plugins.cri.systemd_cgroup = true`を設定してください。\n\n[^3]: 引用で省略した _kubeadmを使う場合は[kubeletのためのcgroupドライバー](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#%E3%82%B3%E3%83%B3%E3%83%88%E3%83%AD%E3%83%BC%E3%83%AB%E3%83%97%E3%83%AC%E3%83%BC%E3%83%B3%E3%83%8E%E3%83%BC%E3%83%89%E3%81%AEkubelet%E3%81%AB%E3%82%88%E3%81%A3%E3%81%A6%E4%BD%BF%E7%94%A8%E3%81%95%E3%82%8C%E3%82%8Bcgroup%E3%83%89%E3%83%A9%E3%82%A4%E3%83%90%E3%83%BC%E3%81%AE%E8%A8%AD%E5%AE%9A)を手動で設定してください。_ の部分に関してはリンク先で Docker を CRI に使う場合のことにしか実質触れていないので気にしなくていいです。\n\nなので、言われた通り `plugins.cri.systemd_cgroup = true` を設定してから restart をかけるようにしましょう。\n\n```sh\nsed -i 's/SystemdCgroup \\= false/SystemdCgroup \\= true/g' /etc/containerd/config.toml\n```\n\n他の手順は参考文献の上3つのリンク先に記載の手順を実施すれば OK です。\n\nネットワークプラグイン設定後、CoreDNS がクラッシュするバグを踏んだら [KubernetesでCoreDNSがループしてしまう問題への対処](/posts/2022/12/kubernetes-coredns-loop) の記事を参考にしてみてください。\n\n## 参考文献\n\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n* [cgroupドライバーの設定](https://kubernetes.io/ja/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/)\n* [Ubuntu 22.04でkubeadmでKubernetesクラスターが動かない？](https://tech.virtualtech.jp/entry/2022/06/08/115030)\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}]},{"title":"KubernetesでCoreDNSがループしてしまう問題への対処","date":"2022-12-24T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-coredns-loop","desc":" 1年前にも Kubernetes クラスターを自力で組んでトラブルシューティングしてみる【The Hard Way】の記事の中で軽く解説したネタです。\n\n## 環境\n\n* Ubuntu 22","draft":false,"content":"\n1年前にも [Kubernetes クラスターを自力で組んでトラブルシューティングしてみる【The Hard Way】](https://qiita.com/SogoK/items/192d475c20e07dd38984)の記事の中で軽く解説したネタです。\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n\n## 問題\n\nKubernetes クラスター内で名前解決に使われる CoreDNS の Pod が `CrashLoopBackOff` になってしまい再起動を繰り返す問題が発生することがあります。\n\n```\n# kubectl -n kube-system logs coredns-787d4945fb-6kb5t\n.:53\n[INFO] plugin/reload: Running configuration SHA512 = 591cf328cccc12bc490481273e738df59329c62c0b729d94e8b61db9961c2fa5f046dd37f1cf888b953814040d180f52594972691cd6ff41be96639138a43908\nCoreDNS-1.9.3\nlinux/amd64, go1.18.2, 45b0a11\n[FATAL] plugin/loop: Loop (127.0.0.1:34129 -> :53) detected for zone \".\", see https://coredns.io/plugins/loop#troubleshooting. Query: \"HINFO 1033981844954998931.6641498229839068582.\"\n```\n\n## 原因\n\nhttps://coredns.io/plugins/loop/#troubleshooting\n\nUbuntu 18.04 以降などの最近のディストリビューションで、ローカルの DNS スタブリゾルバ (systemd-resolved) が使われるようになったことが原因です。Kubelet の設定ファイル `/var/lib/kubelet/config.yaml` を見るとデフォルトでは下記のように設定されています。\n\n```conf\nresolvConf: /run/systemd/resolve/resolv.conf\n```\n\nここで指定されているファイル `/run/systemd/resolve/resolv.conf` が kubelet によって、CoreDNS コンテナに渡されます。デフォルトでは中身は以下のようになっているはずです。\n\n```conf\n# This is /run/systemd/resolve/resolv.conf managed by man:systemd-resolved(8).\n# Do not edit.\n#\n# This file might be symlinked as /etc/resolv.conf. If you're looking at\n# /etc/resolv.conf and seeing this text, you have followed the symlink.\n#\n# This is a dynamic resolv.conf file for connecting local clients directly to\n# all known uplink DNS servers. This file lists all configured search domains.\n#\n# Third party programs should typically not access this file directly, but only\n# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a\n# different way, replace this symlink by a static file or a different symlink.\n#\n# See man:systemd-resolved.service(8) for details about the supported modes of\n# operation for /etc/resolv.conf.\n\nnameserver 127.0.0.1\nsearch .\n```\n\nOS 上ではスタブリゾルバがいるので `127.0.0.1` を DNS とするように設定されていますが、CoreDNS のコンテナ内ではそのコンテナ自身を指すことになります。結果的にループしてしまい、クラッシュします。\n\n## 解決方法\n\n原因は上記の通りなので、`127.0.0.1` ではない外部の DNS サーバーを設定すれば解決できます。\n\n`/run/systemd/resolve/resolv.conf` は systemd-resolved の管理下にある自動生成ファイルですので、大元の設定ファイル `/etc/systemd/resolved.conf` を修正し、systemd-resolved を再起動することで `/run/systemd/resolve/resolv.conf` を再生成させます。\n\nその後新しい `resolv.conf` の内容を反映させるために kubelet と Container runtime (containerd) を再起動します。\n\n```\nNAMESERVER_ADDRESSES=8.8.8.8\nsed -i \"s/^DNS=127.0.0.1$/DNS=${NAMESERVER_ADDRESSES}/\" /etc/systemd/resolved.conf\nsystemctl restart systemd-resolved\nsystemctl restart kubelet\nsystemctl restart containerd\n```\n\nCoreDNS が無事 Running になれば OK です。\n\n```\nroot@controlplane:~# kubectl -n kube-system get po -w\nNAME                                      READY   STATUS             RESTARTS     AGE\ncalico-kube-controllers-7bdbfc669-w4xxt   1/1     Running            0            2m57s\ncalico-node-2f2qc                         1/1     Running            0            15m\ncoredns-787d4945fb-6kb5t                  0/1     CrashLoopBackOff   5 (7s ago)   16m\ncoredns-787d4945fb-q5bhz                  0/1     CrashLoopBackOff   5 (7s ago)   16m\netcd-controlplane                         1/1     Running            0            16m\nkube-apiserver-controlplane               1/1     Running            0            16m\nkube-controller-manager-controlplane      1/1     Running            0            16m\nkube-proxy-692c8                          1/1     Running            0            16m\nkube-scheduler-controlplane               1/1     Running            0            16m\ncoredns-787d4945fb-6kb5t                  0/1     Running            6 (19s ago)   16m\ncoredns-787d4945fb-6kb5t                  1/1     Running            6 (19s ago)   16m\ncoredns-787d4945fb-q5bhz                  0/1     Running            6 (25s ago)   16m\ncoredns-787d4945fb-q5bhz                  1/1     Running            6 (25s ago)   16m\n```\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}]},{"title":"VS Code Serverでリモートホストのコンテナ上開発環境に直接アクセスする","date":"2022-12-17T00:00:00.000Z","ref":"/posts/2022/12/vscode-server-devcontainer","desc":" 今回は「ぼくのかんがえたさいきょうのかいはつかんきょう」を紹介したいと思います。\n\nVS Code Server を使い、リモートサーバー上でコンテナとして動かしている開発環境に直","draft":false,"content":"\n今回は「ぼくのかんがえたさいきょうのかいはつかんきょう」を紹介したいと思います。\n\n[VS Code Server](https://code.visualstudio.com/docs/remote/vscode-server) を使い、リモートサーバー上でコンテナとして動かしている開発環境に直接乗り込んでみよう、というアイデアです。\n\nSSH もポート開放も不要なのでとてもお手軽です。\n\n## 環境\n\nサーバー\n* Raspberry Pi 400 (Ubuntu 22.04.1, arm64)\n  * Docker & Docker Compose がインストールされていること\n\nクライアント\n* VS Code 1.74.1\n  * [Remote - Tunnels](https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-server) 拡張機能がインストールされていること\n\n払い出された URL にアクセスすればブラウザからでも使えるので、iPad などのモバイル端末でも使えますね。\n\n## ソースコード\n\nhttps://github.com/SogoKato/simple-devenv-py\n\n## アーキテクチャ\n\n![architecture](//www.plantuml.com/plantuml/png/dLAnJiCm4Dtz5QSmPu2vieegPb1JmNnoZjJ2EKU-Isc5-k-ene5q849ikPVttZq_UosAISS-64nkxtjKWfiTkJt74BiJLCyDR69B5Q202vvOORNIRqBTqi4xijQOH4wHkq1GRQcFIl3OLF1X06P_Df4LFLFwCfocJBiYbhtGK3eKjkJFGWNu9V1BJ6yoe2DuE2gn-CXPJKUzlOuk9r7gQucl-ew9hFstyTrVZCzcmRo9OtBqKxNaUKcnezHxnW1FAJeI8Sb2BV2IT3ioU-xWVXY2TwZJIN0Op2NdsPXorRKjhPjIVbtRacsEJ4jdM3PR4xUNj_K9)\n\n### なぜコンテナで動かすか？\n\n最近はホスト上に言語やライブラリをインストールするのではなく、コンテナを使って開発環境を整えることの方が多いと思います。\n\nもちろん仮想環境を使うという手段もありますが、可搬性ではコンテナの方が上なので、私は大抵の場合コンテナを使った開発環境を作り、VS Code の dev container を使ってコンテナ内で作業をします。\n\nしかしながら、今回導入する VS Code Server では2022年12月現在まだ dev container をはじめとするリモート開発の拡張機能はサポートされていません。\n\n> Can I use the Remote Development Extensions or a dev container with the VS Code Server?  \n> Not at this time.\n\nhttps://code.visualstudio.com/docs/remote/vscode-server#_can-i-use-the-remote-development-extensions-or-a-dev-container-with-the-vs-code-server\n\nなので、ホスト上に VS Code Server をインストールしたところで実際の開発環境に入り込むことができないので、であれば開発環境のコンテナ上に VS Code Server を入れて直接乗り込もう、というのが今回の趣旨になります。\n\n## セットアップ\n\n```sh\ngit clone https://github.com/SogoKato/simple-devenv-py.git\n```\n\nDockerfile の抜粋です。イメージのビルド時にスクリプトをダウンロード&実行して VS Code Server をインストールしています。\n\nCMD に `code-server` コマンドを書いて、コンテナ起動時に VS Code Server が実行されるようにします。\n\n`--accept-server-license-terms` と `--random-name` オプションはユーザーインタラクションを不要にするためのもので、順に[ライセンス](https://code.visualstudio.com/license/server)への同意とランダムな命名をしています。  \n`--server-data-dir` を使ってデータの永続化のため VS Code Server のデータの保存領域をバインドマウントするディレクトリ配下にしておきます。[^1]\n\n[^1]: ただし、筆者が一度コンテナを再作成してみたところ GitHub の再認証は不要でしたが、インストールした拡張機能などは消えてしまっていました（調査中）。\n\n```dockerfile\nRUN wget -O- https://aka.ms/install-vscode-server/setup.sh | sh\n\nCMD [\"code-server\", \"serve\", \"--accept-server-license-terms\", \"--random-name\", \"--server-data-dir\", \"/workspace/.vscode-server\"]\n```\n\nイメージをビルドしましょう。\n\n```sh\ndocker compose build\n```\n\ndocker-compose.yml です。なんの変哲もありません。\n\n```yml\nversion: '3'\nservices:\n  app:\n    build:\n      context: ./\n      dockerfile: Dockerfile\n    volumes:\n      - type: bind\n        source: ./\n        target: /workspace\n```\n\n起動します。\n\n```sh\ndocker compose up -d\n```\n\nログを見ると GitHub へのログインを求められています。\n\n```sh\ndocker compose logs -f\n```\n\n```\nsimple-devenv-py-app-1  | To grant access to the server, please log into https://github.com/login/device and use code xxxx-xxxx\n```\n\n言われた通り https://github.com/login/device にアクセスして、コードを入力しましょう。\n\nログインが完了するとトンネルが作成され、ブラウザアクセス用の URL が払い出されることがわかります。\n\n```\nsimple-devenv-py-app-1  | [2022-12-17 09:06:03] info Creating tunnel with the name: dazzling-antshrike\nsimple-devenv-py-app-1  | \nsimple-devenv-py-app-1  | Open this link in your browser https://insiders.vscode.dev/+ms-vscode.remote-server/dazzling-antshrike/workspace\n```\n\n## 接続（ブラウザ）\n\n好きなブラウザで払い出されたリンクを開くだけです。簡単。\n\n## 接続（VS Code）\n\n[Remote - Tunnels](https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-server) 拡張機能がインストールし、GitHub にログインすると登録されているトンネルの一覧を確認できます。\n\n![Tunnels](/images/posts/2022/12/vsc_remote_tunnels.png)\n\nボタンをクリックしてリモートに接続します。\n\n## 遊んでみる\n\nあとはいつも通り VS Code の設定を行なっていけば OK です。\n\n![editor](/images/posts/2022/12/vsc_remote_editor.png)\n\nサーバーを起動してみます。\n\n![run](/images/posts/2022/12/vsc_remote_run.png)\n\nポートが使われていることを検知するとローカル実行時と同じように通知が出てきます。  \n「ブラウザーで開く」をクリックするとポートがクラウド経由でポートが転送されて、起動したサーバーにリクエストが届きます。\n\n![port forwarding](/images/posts/2022/12/vsc_port_forwarding.png)\n\nちなみにこの URL は GitHub 未認証の状態では見ることができない（ログインを求められる）のでセキュリティ的にも安心です。\n\n## 使い心地は？\n\n若干ラグがあるように感じます。\n\n今回検証に使った Raspberry Pi のスペックの問題なのか（MicroSD から SSD にしたら変わるかも？）、ネットワーク環境の問題なのか、原因はまだ切り分けできていません。\n\nまた、ちょいちょい接続が切れて `Connecting to hogehoge...` と出てくるのですが、これはおそらくうちのネットワーク環境のせいな気がします。。\n\n### 2022/12/18 追記\n\nMicro SD から SSD に変えてみたら体感が大きく改善され、ストレスを感じない程度に快適になりました。SSD しか勝たん。\n\n## まとめ\n\n今までこれと同様のことを実現する選択肢として [code-server](https://coder.com/docs/code-server/latest) がありましたが、Pylance などオープンソースでは利用できない拡張機能があったりして、ローカルの VSCode と同じ環境を整えることは困難でした。\n\nMicrosoft 謹製の VS Code Server がリリースされたことにより、よりローカルの VS Code に近い環境を作ることができるようになりました。  \nサーバー側のポートを開ける必要がないのもメリットです。企業のポリシー次第ですが、会社でこれを使えたら嬉しいというユーザーも多いのではないでしょうか。\n\nそれでは、ハッピーなエンジニアライフを！\n\n## 参考文献\n\n* [Visual Studio Code Server](https://code.visualstudio.com/docs/remote/vscode-server)\n","tags":[{"name":"VS Code","ref":"/tags/vs-code"},{"name":"開発環境","ref":"/tags/開発環境"}]},{"title":"よくあるSPA+API構成でのOpenID Connectクライアント実装","date":"2022-12-02T00:00:00.000Z","ref":"/posts/2022/12/openid-connect-fastapi","desc":" この記事はニフクラ等を提供している、富士通クラウドテクノロジーズ Advent Calendar 2022の2日目の記事です。\n\n昨日は [@nt","draft":false,"content":"\nこの記事は[ニフクラ](https://www.nifcloud.com/)等を提供している、[富士通クラウドテクノロジーズ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/fjct)の2日目の記事です。\n\n昨日は [@ntoofu](https://qiita.com/ntoofu) さんの [パケットキャプチャからKubernetes APIのTLS通信を解析する](https://ntoofu.github.io/blog/post/sniffing-kube-apiserver-tls/) でした。  \n私は TLS な時点でパケットキャプチャを諦めてしまいそうですが Linux の便利な仕組みと気合があれば TLS 1.3 のパケットキャプチャも可能だとわかり、とても有益でした。私もギークなエンジニア目指して頑張ります。\n\n今日は OpenID Connect のクライアントをどう実装するかについて検討してみたいと思います。\n\nFastAPI + SPA (Vue.js) でちょっとした社内ツールを開発した時に社内の認可基盤との OpenID Connect を用いたログイン連携機能を作りたかったのですが、実装のための情報が少なかったので記事に残しておきたいと思ったのがきっかけです。「これがベストプラクティスだ！」というわけではありませんが、1つの実践例としてどなたかの参考になれば幸いです。\n\n## 対象読者\n\n* OpenID Connect を使ってログインするアプリを作りたいけど実装方法がわからない人\n  * 色んなフローがあるっぽいけどどれを使うべき？\n  * アクセストークン？ ID トークン？\n  * サーバーで何してクライアントで何するの？\n* Python の FastAPI で作ったサーバーでのログイン〜リダイレクト〜トークン検証の実装例が知りたい人\n\n## OpenID Connect とは\n\n**OpenID Connect は OAuth 2.0 を拡張する形で策定された、認証・認可のための仕組み**です。OAuth 2.0 は認可を行うことを目的とした仕様です。すでに10年も前の話ですが、OAuth を認証にも使ってしまう「SNS ログイン」の手法は「[単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる](https://www.sakimura.org/2012/02/1487/)」と指摘されていました。OpenID Connect は OAuth 2.0 を拡張して認証の用途にも使えるようにした、ID トークンを発行するための仕組みとなっています。\n\n下図は認証・認可の流れの一例です（response_type=id_token の場合）。\n\n![overview](//www.plantuml.com/plantuml/png/NP6zIiDG5CVt-nINJkbGgBg9I0SNfrlo1g7DKD0q9EckzpW4KHfGS6aH9KWeIeMYK1FmOGv9u-GhUEvDH9lbSCBv_J_2xVc1vGMJqnDc3OAnnn6U43AKxpIvvVE9Rtjyx0rfxdIPI-neC78j9-0jb6yAXHkKQswO_NPB2Sn-ZUysSE7Qpl4HmXt22qA4CaOuuuQeTU9NjzTbEhHpgBpskSBbgyPN23EKdsgHIuG50j3222DOABXSN9T9HYS5o8IQ8OILtq67a8RVvZRzcZyYf7bqLLnCgy_o8Td47vMewPlIaa-NJEX8y__fMOVDTRcreVuqHCXqqLMRcN-2xLCHpqXUtrLces8HHldb_NTspdgsCwI7-W40)\n\nOP: OpenID Provider; ID トークンの発行者  \nRP: Relying Party; OP に認証機能を既存するクライアントアプリ\n\nユーザーがサービスにログインしようとすると、サービスはまず OpenID プロバイダー（OP）のエンドポイントに対してユーザーをリダイレクトします。OP は未認証であればログイン画面を出しユーザーを認証してから、サービスに対して認可を行うかどうか同意を取ります。ユーザーが同意すると、OP は ID トークンをリクエストに含めてサービスのコールバック URL にリダイレクトします。サービスは受け取った ID トークンが正規の OP からのものであることを OP の公開鍵を使用して検証します（そのほかにも複数の検証をする）。検証が正常に終了すればサービスへのログインの処理は完了です。\n\n## で、どうやってクライアントを実装するの？\n\n### まずは結論\n\n![code flow](//www.plantuml.com/plantuml/png/RPBFIW9H5CRtzoakhdGXJNzM4Q7GnfL3FS6aBeHI6KTewTmROQ4e94YWX28XKXdq1t8a7-OuEgvwXRwPKN2apULSlz_vpdUk4oiQccwKBY-ObZBoEYVvH792uWidrugyLCpeFA-dSUugx3n_nKCaFbr4tfFuvk5JDH9Y1NXaKzc2bZFucHfVDUmf0I6k9bR2li8okJI7Mm089GkPNEA4P8la2ya6YJx9CWydCSBDabHN_GSAyt95ZxrfXzpbnPl7lvDiavYwXHYH79AKA1Wuu6w6RTniaVb3vWE31WHJG3Z3cZEOkEqm4GDiIhBY3psA0jaoMJIjPQT7qh8RrVbrtRywtS6YF_QRjdqj57PznF2Zdsf3U_QcTM2B8ko39B0NjDj8C6PGN9RDsRGRC2NHyrQm_1N0uGhh7RppnjMPDktQX--zRWqIytuRwLpY_sUtNwkpyStwdRsbWy2yqh3l7dyd9elXpySNzmS0)\n\n* API サーバーで認証リクエストや ID トークン検証を行う\n  * 今回は採用するライブラリの都合で Authorization Code Flow を使います\n* ID トークンは Cookie で管理\n  * localStorage ではセキュリティ上問題がある\n  * インメモリでは利便性に欠ける\n  * Cookie の属性\n    * HttpOnly: true\n      * JavaScript からは触らせない\n    * SameSite: Lax\n      * 他サイトへの Cookie 送信を最低限にする\n      * Strict にすると OP にリダイレクトした際に破棄されてしまうため Lax\n    * Secure: true\n      * HTTPS でのみ Cookie を送信する\n\n### SPA なら全部 SPA にやらせればいいんじゃないの？\n\nはい、Implicit Flow を使うことで実現できます。\n\n冒頭の「車が通れるほどのどでかいセキュリティー・ホール」の話は OAuth 2.0 を Implicit Flow で使用した時の話ですが、OpenID Connect はそれを踏まえて策定された仕様なので、OpenID Connect において Implicit Flow を使うことに問題はありません。\n\nImplicit Flow を使う場合、下図のようになります（response_type=id_token）。\n\n![implicit flow](//www.plantuml.com/plantuml/png/TP9FIm916CRlyoa6JteGjZydYL3euicbFi6c7eHIMLVegFD6I1WA1LsKC2H4AWCfq5tmmxpkkfxw2hqpxWO3THbcz_dDypppxcORZcKxpSiBPXMTciqHNX0y55-qSgl1cusopMjsYTOzWvtNhdW2nQT4u1x5WYTFpLI2rScZKgpKhQh3pynST63Vq8IScO-40uELgoLERXgGADJBrVm9mYF26q8VnHYXnPC5Yf1T2cPq_j1WgbVwMALbkEJ5X-Bd20CKAxaHCuGf0j264KSuMH0TJk_2YKUQ9CI4he7GsJaUfIMY6suUtEtm6S7r-ztWkhTx34UJpNWPrz1zNThulHcZbxyDO-rLfGrLlKLINhQZvarLvwcufPnKXklYjjLUhqQCfF-8O3oW24dyFHZ_lRjUtiGPghaE19s-V_lqxRLPbZuF_HC_)\n\n上記のフローでは、SPA 側で Client Secret を管理する必要がありません。ClientSecret が必要になるのは主にトークンエンドポイント（認可コードやアクセストークンを使って、アクセストークンや ID トークンを取得するためのやつ）を使う時なので、response_type=id_token で OIDC クライアントを実装する場合には困りません。response_type=id_token で問題がないかという観点では、ログイン完了時にだけユーザー情報が手に入れば問題ない場合（ユーザー情報が最新である必要がない場合）には事足りると思われます。\n\nSPA でエンドユーザーに見せたくない機密情報を扱うのはほとんど不可能だと思いますので Client Secret を SPA に持たせる必要がないのは嬉しい仕様ですね。**Implicit Flow では CSRF 対策のために nonce の検証が必須**なので注意してください。\n\n### ID トークンどこ置く問題\n\nただ、Client Secret を SPA で管理する必要がないからといって SPA 上で ID トークンを扱えるようにすると、ID トークンをどこに保管するか、という問題が出てきます。これは OIDC のスコープ外の議論ですが、クライアント実装にあたって必ず検討するべき点だと思うので、今回はこれも考えていきたいと思います。\n\nID トークンを置く場所として考えられる候補を比較してみます。\n\n||Cookie (HttpOnly: true, Secure: true, SameSite: Lax)|インメモリ|localStorage|\n|---|---|---|---|\n|保持期間|**設定された有効期限まで**|ページがリロードされるまで|**なし**|\n|CSRF 対策|**更新系は防げる**|**他の JS ライブラリは基本的にアクセスできない**|どの JS ライブラリも取得可|\n|JS での ユーザー情報取得|できない [^1]|**できる**|**できる**|\n\n[^1]: サーバー側で Cookie の ID トークンを検証した上で、JSON レスポンスでユーザー情報を返却する API を作ったりすれば可能です。\n\nどれも一長一短な感がありますが、この中で一番安全性と利便性のバランスがいいのは Cookie (HttpOnly: true, Secure: true, SameSite: Lax) だと思ったので、今回は Cookie に ID トークンを置くようにしました。\n\nなお、Auth0 のクライアントライブラリではインメモリに ID トークンを保存しつつ、セッションを長く保たせることもできるようです。  \n[SPA認証トークンはlocalStorageでもCookieでもない、Auth0方式はいいねというお話](https://mizumotok.hatenablog.jp/entry/2021/08/04/114431)\n\n## FastAPI で OpenID Connect クライアントを実装する\n\n以上で、一通りクライアントの実装方針について議論ができたと思うので、ここからは具体的な Python (FastAPI) での実装に移りたいと思います。  \n今回使うライブラリ Authlib では FastAPI の他に Starlette, Flask や Django の Oauth Client とその実装例も公開されているので、それらを参考にすれば他のフレームワークでも割と簡単に実装できるのではないかなと思います。\n\n### ソースコード\n\nhttps://github.com/SogoKato/oidc-fastapi-authlib\n\n動かしてみたい方は README に従って起動してみてください。\n\n### 必要なもの\n\n前準備として OpenID プロバイダを用意する必要があります。どのプロバイダでも大丈夫ですが、まだ持っていない場合は [Auth0](https://auth0.com/jp) に登録してみるのがおすすめです。個人で使うようなリクエスト量であれば無料で使えます（2022年12月現在）。\n\n登録後、Application を作成したら、リダイレクト URI (Allowed Callback URLs) に `http://localhost:8080/api/auth` を入れておきます。また、下記の情報を探してメモっておきましょう。\n\n* Client ID\n* Client Secret\n* OpenID Configuration Endpoint\n  * アクセスすると OIDC クライアントで必要な情報を返してくれるエンドポイント\n  * 通常 `https://example.com/.well-known/openid-configuration`\n\n### アーキテクチャ\n\n![architecture](//www.plantuml.com/plantuml/png/SoWkIImgAStDuKfCBialKdZSlEnnyvx7JTk0f49YiK9fSMeHLs9HSaPcRc99ge9oIMfoHbv-JdvwfK9UUcPUXOAD3L15MMPogfqT3dME0Pv4g5Bo2F7rqNSE3jRt2bO2sGnqM4bcCefEa6CKTEsWDbi17RlgSTFwnqqh7ZVjVDpSmGKHrzMr0za9bDTFBCX4249D18bpEQJcfG0z3G00)\n\n今回は Cookie の SameSite 属性を使用しているので、SPA と API とで同じドメイン名を使い、パスでリクエストを振り分けます。\n\n### 解説\n\n#### ログイン時の処理\n\n```python\napp = FastAPI()\napp.add_middleware(SessionMiddleware, secret_key=\"MYSTRONGKEY\", https_only=True)\n```\n\nFastAPI の初期化と Cookie のための SessionMiddleware の追加をします。\n\n```python\noauth = OAuth()\noauth.register(\n    name=\"auth0\",\n    server_metadata_url=\"https://example.com/.well-known/openid-configuration\",\n    client_id=\"クライアントID\",\n    client_secret=\"クライアントシークレット\",\n    client_kwargs={\"scope\": \"openid profile\"},\n)\n```\n\nAuthlib のインスタンスを作ります。scope に `openid` と入れておくことで Authorization Code Flow の時にトークンエンドポイントで ID トークンが手に入ります。\n\n```python\n@app.get(\"/api/login\")\nasync def login(request: Request):\n    redirect_uri = request.url_for(\"auth\")\n    return await oauth.auth0.authorize_redirect(request, redirect_uri)\n```\n\n認証リクエストを開始するためのエンドポイントです。ユーザーがここにアクセスすることで `http://localhost:8080/api/auth` をリダイレクト URI とした認証リクエストを開始します（OpenID プロバイダにリダイレクトされる）。\n\nちなみにこんな URL でリダイレクトされます。state と nonce があることも確認できますね。\n\n```\nhttps://example.com/authorize\n  ?response_type=code\n  &client_id=クライアントID\n  &redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fapi%2Fauth\n  &scope=openid+profile\n  &state=PGO5TxTujESoXuLlfzYTWZsioK5Up5\n  &nonce=HfyA3eugosoOuieiTGRZ\n```\n\n![OP login](/images/posts/2022/12/oidc_op_login.png)\n\nログインが完了するとリダイレクト URI にリダイレクトされ、次のエンドポイントが呼ばれます。\n\n```python\n@app.get(\"/api/auth\")\nasync def auth(request: Request):\n    try:\n        token = await oauth.auth0.authorize_access_token(request)\n    except OAuthError:\n        logger.exception(\"An error occurred while verifying authorization response.\")\n        raise UnauthenticatedError()\n    userinfo = token.get(\"userinfo\")\n    # userinfoのclaims(subやnameなど)を使ってDBにユーザーを登録する処理がここにきます.\n    request.session[\"id_token\"] = token.get(\"id_token\")\n    return RedirectResponse(url=\"/\")\n```\n\n`authorize_access_token` で認可コードと state を使って ID トークンを取得し、ID トークンと nonce を検証するところまでやってくれます（楽ちん）。  \nその後は自分の好きなように処理をして OK です。sub クレームをユーザー ID として、ユーザーがまだ DB に登録されていなければ insert するとか、ユーザーのプロフィール情報が変わってたら更新するとか、そういう処理が来るのかなと思います。\n\n最後に、Cookie に ID トークンをセットして `/` にリダイレクトして、ログイン処理は完了です。\n\n#### ログイン後の処理\n\nログイン後は JS 側で fetch や axios でリクエストをすると、Cookie も自動的に送信されます。なので、ログインしたユーザーにしか使わせたくないエンドポイントでは、Depends を使って ID トークンを検証します。\n\n```python\n@app.get(\"/api/items\")\nasync def list_items(user: User = Depends(verify_user)):\n    logger.info(f\"Successful log in: user_id={user.id} name={user.name}\")\n    return {\n        \"items\": [\n            {\"name\": \"Teddy bear\", \"icon\": \"🧸\", \"price\": 99},\n            {\"name\": \"Apple\", \"icon\": \"🍎\", \"price\": 2},\n            {\"name\": \"Sushi\", \"icon\": \"🍣\", \"price\": 200},\n            {\"name\": \"Bento\", \"icon\": \"🍱\", \"price\": 50},\n        ]\n    }\n```\n\n`verify_user` 関数で Cookie から ID トークンを取り出します。\n\n```python\nasync def verify_user(request: Request):\n    id_token = request.session.get(\"id_token\")\n    if id_token is None:\n        raise UnauthenticatedError()\n    decoded_jwt = await verify_token(id_token=id_token)\n    # DBにユーザーが登録されているか確認する処理がここにきます.\n    # user = user_repo.select_by_user_id(user_id=user_id)\n    return user\n```\n\n`verify_token` が ID トークンを検証する関数です。\n\n```python\nasync def verify_token(id_token: str):\n    jwks = await oauth.auth0.fetch_jwk_set()\n    try:\n        decoded_jwt = jwt.decode(s=id_token, key=jwks)\n    except Exception:\n        logger.exception(\"An error occurred while decoding jwt.\")\n        raise UnauthenticatedError()\n    metadata = await oauth.auth0.load_server_metadata()\n    if decoded_jwt[\"iss\"] != metadata[\"issuer\"]:\n        raise UnauthenticatedError()\n    if decoded_jwt[\"aud\"] != settings.oidc_client_id:\n        raise UnauthenticatedError()\n    exp = datetime.fromtimestamp(decoded_jwt[\"exp\"])\n    if exp < datetime.now():\n        raise UnauthenticatedError()\n    return decoded_jwt\n```\n\nID トークンの検証として最低限必要なのは以下の通りです（Authorization Code Flow の場合）。\n\n1. JWK Set（OP の公開鍵）を使用して JWT をデコードする\n2. iss クレーム（Issuer Identifier; 発行者）を検証する\n3. aud クレーム（Audience(s); 誰に対して発行したか = Client ID）を検証する\n4. exp クレーム（Expiration time; 有効期限）を検証する\n\n以上が完了すれば基本的な OIDC クライアント実装は完了です🎉\n\n![log in](/images/posts/2022/12/oidc_log_in.gif)\n\n## 最後に\n\nいかがでしたか？？\n\n一見複雑そうな OpenID Connect ですが、一つずつ紐解いてみると意外と簡単に実装できるように仕様が設計されていることがわかりました。自分でパスワードを頑張って管理するよりもこういうところは信頼できる OpenID プロバイダに任せてしまった方が楽ですし、何よりも安全ですよね。\n\nぜひ皆さんも Web サービスを作る時には活用してみてください。\n\nこの記事は[富士通クラウドテクノロジーズ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/fjct)の2日目の記事でした。\n\n明日は [@Syuparn](https://qiita.com/Syuparn) さんが SQL のテストについて書いてくれるようです。  \nSQL のテストってあまりやってなかったりするので、他の人がどのように考えて実施しているのか気になります。それでは、明日の記事もお楽しみに！\n\n（👇この記事がよかったらいいねボタンを押してください！）\n\n## 参考文献\n\n* [OpenID Connect Basic Client Implementer's Guide 1.0 - draft 42](https://openid.net/specs/openid-connect-basic-1_0.html)\n* [OpenID Connect Implicit Client Implementer's Guide 1.0 - draft 25](https://openid.net/specs/openid-connect-implicit-1_0.html)\n* [Google login for FastAPI](https://blog.authlib.org/2020/fastapi-google-login)\n* [一番分かりやすい OpenID Connect の説明](https://qiita.com/TakahikoKawasaki/items/498ca08bbfcc341691fe)\n* [IDトークンが分かれば OpenID Connect が分かる](https://qiita.com/TakahikoKawasaki/items/8f0e422c7edd2d220e06)\n* [OpenID Connect 全フロー解説](https://qiita.com/TakahikoKawasaki/items/4ee9b55db9f7ef352b47)\n* [OAuth 2.0/OpenID Connectの2つのトークンの使いみち](https://qiita.com/wadahiro/items/ad36c7932c6627149873)\n* [単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる](https://www.sakimura.org/2012/02/1487/)\n* [OIDCのImplicit FlowでClientSecretを使わずにID連携する](https://zenn.dev/ritou/articles/a)\n* [SPA認証トークンはlocalStorageでもCookieでもない、Auth0方式はいいねというお話](https://mizumotok.hatenablog.jp/entry/2021/08/04/114431)\n* [GoでOpenID ConnectのClientを実装する（実装編）](https://times.hrbrain.co.jp/entry/go-openid-connect-implement)\n","tags":[{"name":"OpenID Connect","ref":"/tags/openid-connect"},{"name":"認証/認可","ref":"/tags/認証-認可"},{"name":"SPA","ref":"/tags/spa"},{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"}]},{"title":"GitLab CIのrulesとworkflowを理解する","date":"2022-11-17T00:00:00.000Z","ref":"/posts/2022/11/gitlab-rules-workflow","desc":" GitLab CI の rules を使って Dockerfile などの特定のファイルの変更時のみ Docker イメージを作成するパイプラインを回して、それ以外の時には既存の Docker イメージを使用して CI を実行する、という組み方をしたかったのですが、書き方に結構手間取ったのでメモ。","draft":false,"content":"\nGitLab CI の rules を使って Dockerfile などの特定のファイルの変更時のみ Docker イメージを作成するパイプラインを回して、それ以外の時には既存の Docker イメージを使用して CI を実行する、という組み方をしたかったのですが、書き方に結構手間取ったのでメモ。\n\n環境: GitLab.com 15.6.0-pre\n\n## rules とは\n\nhttps://docs.gitlab.com/ee/ci/yaml/#rules\n\nそれぞれのジョブについて、パイプラインに追加するかしないかの条件を記述するものです。\n\nrules では下記の条件が指定できます。\n\n* `if`\n* `changes`\n* `exists`\n* `allow_failure`\n* `variables`\n* `when`\n\nそれぞれの条件の詳細については公式ドキュメントを参照してください。\n\nrules は [only/except](https://docs.gitlab.com/ee/ci/yaml/#only--except) を置き換えるものなので、rules と only/except を同じジョブで同時に指定することはできません。\n\nrules の指定の一例を公式ドキュメントから引用します。\n\n```yaml\ndocker build:\n  script: docker build -t my-image:$CI_COMMIT_REF_SLUG .\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - Dockerfile\n      when: manual\n      allow_failure: true\n```\n\n上記の例では\n\n* パイプラインがマージリクエストのパイプラインの時に `Dockerfile` が変更されているか確認する\n* `Dockerfile` が変更されている時に、ジョブをパイプラインにマニュアルジョブとして追加する\n  * `allow_failure: true` によって、ジョブがトリガーされなかったとしても後続のジョブが実行される\n* `Dockerfile` が変更されていない時は、ジョブをパイプラインに追加しない\n  * `when: never` と同じ\n\nという挙動になります。\n\nrules はリストなので複数のルールを書くことができますが、 **短絡評価である** 点に注意が必要です。rules はパイプラインが作成されたタイミングで評価され、最初にマッチするまで評価が行われます。そのため、例えば `- when: manual` を最初に記述するとそこで評価が終わり（`manual` は常に真となりパイプラインに追加されます）、その後の条件については評価されません。言われてみたらそれはそうなのですが、筆者はそこでしばらく詰まってました。\n\n## workflow とは\n\nhttps://docs.gitlab.com/ee/ci/yaml/workflow.html\n\nパイプラインそのものを実行するかどうかを決定するものです。workflow で条件にマッチしなかった場合、そのパイプライン内のジョブが実行されることはありません。\n\nよくある使い方としては `$CI_PIPELINE_SOURCE` の種類（`merge_request_event`, `push`, `schedule`, etc.）に応じてパイプラインを実行するかしないかを決めると言った使い方があります。\n\n```yaml\nworkflow:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: never\n    - if: $CI_PIPELINE_SOURCE == \"push\"\n      when: never\n    - when: always\n```\n\n上記の例ではスケジュール実行時または push 時（ブランチとタグ）には `when: never` が指定されているためパイプラインは走りません。それ以外の時にはパイプラインが実行されます。\n\n## 重複したパイプラインを避ける\n\nhttps://docs.gitlab.com/ee/ci/jobs/job_control.html#avoid-duplicate-pipelines\n\nジョブに rules を使用していると、マージリクエスト作成後にブランチに対して push するといった1つのアクションが、push 時に発生したパイプラインとマージリクエストのパイプラインの2つが走らせることが起こりえます。\n\n重複したパイプライン（duplicate pipelines）を避けるためには\n\n* workflow を使ってどの種類のパイプラインは走って良いのかを指定する\n* ジョブが実行される条件をかなり限定的にして、最後のルールとして `when`（`when: never` 以外）を使うのを避ける\n\nことが対策になります。\n\n筆者の場合は、次項で示す例を書いている際に重複したパイプラインが発生し、片方のジョブは正しく機能しないという状況が起こりましたが、workflow を指定することで重複が解消され、正しく機能するようになりました。\n\n## 特定ファイルの変更時のみジョブを実行し、それ以外はスキップして後続のジョブを実行する\n\n`.gitlab-ci.yml` と同階層に `Dockerfile` がある想定です。\n\n```yaml\nstages:\n  - build\n  - test\n\nworkflow:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH && $CI_OPEN_MERGE_REQUESTS\n      when: never\n    - if: $CI_COMMIT_BRANCH\n\nbuild:\n  stage: build\n  image:\n    name: gcr.io/kaniko-project/executor:v1.9.0-debug\n    entrypoint: [\"\"]\n  script:\n    - /kaniko/executor\n      --context \"${CI_PROJECT_DIR}\"\n      --dockerfile \"${CI_PROJECT_DIR}/Dockerfile\"\n      --destination \"${CI_REGISTRY_IMAGE}:latest\"\n  rules:\n    - if: $CI_PIPELINE_SOURCE =~ /merge_request_event|push/\n      changes:\n        - Dockerfile\n    - when: manual\n      allow_failure: true\n\ntest:\n  stage: test\n  image: \"${CI_REGISTRY_IMAGE}:latest\"\n  script:\n    - echo \"DO SOME TESTS\"\n```\n\n上記の例は以下の挙動をします。\n\n* workflow\n  * マージリクエストでのパイプラインの場合は実行される\n  * マージリクエストがある時、ブランチへの push イベントでのパイプラインは実行されない\n  * それ以外のブランチへの push イベントでは実行される\n* rules\n  * パイプラインがマージリクエストのパイプラインの時または push された時に `Dockerfile` が変更されているか確認する\n    * changes は上記以外では常に真となってしまうため\n  * `Dockerfile` が変更されている時に、ジョブをパイプラインにジョブを追加する\n  * 上記の条件に当てはまらない時はマニュアルジョブとしてパイプラインに追加する\n    * `allow_failure: true` となっているので、後続のジョブはそのまま実行される\n\nこのように書くことで、実現したかった「特定ファイルの変更時のみジョブを実行し、それ以外はスキップして後続のジョブを実行する」が実現します。\n","tags":[{"name":"Gitlab","ref":"/tags/gitlab"},{"name":"CI/CD","ref":"/tags/ci-cd"}]},{"title":"Next.jsとTailwind CSSでブログを作るときに考えたこと","date":"2022-11-13T00:00:00.000Z","ref":"/posts/2022/11/blog-with-nextjs-and-tailwindcss","desc":" このブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。","draft":false,"content":"\nこのブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。\n\nそこそこの出来栄えになったので、今回はこのブログができるまでのお話をしたいなと思ったのですが、正直なところ、以下のリンク先のページを~~まるパク~~参考にさせてもらいながら作成したので、具体的な構築方法についてはそちらをご覧いただけると良いかと思います。1ステップずつ丁寧に解説されておりとても有用でした🙏\n\n* [Next.jsを利用した初めての本格的Markdownブログサイトの構築](https://reffect.co.jp/react/nextjs-markdown-blog)\n\nなので、今回は技術的な詳細というよりも、筆者が始める前に疑問だった点や技術選定、設計まわりについて書ければなと思います。\n\n## 対象読者\n\n* 自分のブログを作ってみたい人\n* React や Next.js に興味がある人\n\n## ブログをどこでホストするか\n\n技術に関する記事を書くのであれば Qiita や Zenn でいいじゃんと思いますし、実際その方がはるかに楽で、多くのリアクションをもらいやすいと思います。そんな中、自分のブログを作る理由としては「やってみたかったから」以上の理由は存在しません。つまりロマンです。\n\nしかしながら、いざ自分のブログを作ろうと思ったときに\n\n* 簡単に、かつ高度なカスタマイズができる\n* ランニングコストが安い\n\nといった美味しい環境は思ったよりも少ないです。\n\nブログを作ると言ったら WordPress が超定番ですが、テーマを作るとなると php や WordPress の知識が必要になります。WordPress テーマづくりに携わったことがあるので、やってみると思ったより簡単なのですが、筆者のお仕事の分野とはかすらないのであまりモチベーションが湧きません。  \nまた、最低月数百円のランニングコストもかかりますし、動的にページを生成するのでレスポンスも遅くなりがちです。\n\n次に SSG（Static Site Generation; 静的サイト生成）を検討します。Markdown で原稿を書き、静的な HTML などのファイルを出力すれば、GitHub Pages で無料で公開できるので結構良さそうです。\n\nSSG のツールとしては有名なものがいくつかあります。\n\n* Next.js\n* Gatsby\n* Hugo\n* NuxtJS\n* Jekyll\n\nこのうち、Next.js と Gatsby は React ベースのため当初は検討から外していました。筆者は Hugo を選び、配布テーマを適用してみたり、自作テーマを作り始めたりしましたが、想像より学習コストが高かったので挫折してしまいました。\n\n代わりに最近波に乗っていそうな Next.js を使ってみることにしました。React を使うのは初めてだったので（チュートリアルしかやったことがない）躊躇していましたが、[最初に紹介した記事](https://reffect.co.jp/react/nextjs-markdown-blog)のおかげもあって、すんなりと構築することができました。React の基本的な知識さえあれば問題なさそうです。\n\n## どうやってデザインするか\n\nまずは Adobe XD でデザインカンプを作成します。いきなりマークアップを始めても、作りたいものが定まっていないと無駄に時間がかかってしまうので、多少手間でも作りたいもののイメージを先に決めておくと良いです。\n\n![XD](/images/posts/2022/11/xd.png)\n\n上図のような感じで、ヘッダーやサイドバー、記事一覧、記事ページをざっくりと作りました。\n\n## React の CSS よくわからん問題\n\n筆者の経験不足のせいなのですが、React で CSS でスタイルを適用するベストな方法がよくわかりませんでした😇\n\nデザインカンプを作ってみて、そこまで複雑な CSS を記述する必要がなさそうだったので、Tailwind CSS を使ってみることにしました。\n\n[Tailwind CSS](https://tailwindcss.com/) とは、HTML のクラス属性に `flex`, `pt-4`, `text-center` のようなクラス名を記述することで、`display: flex` をかけたり `padding-top` や `text-align: center` を設定できるというヤツです。\n\n軽く個人的な感想をまとめてみると\n\nPros\n* コード量が減る\n* HTML 要素を消したけど CSS は消し忘れた、みたいなことはなくなる\n* カスタムの色を設定できるなど、一定の柔軟性がある\n\nCons\n* CSS の知識は必要（それはそう）\n* 都度リファレンスを見てクラス名を確認する必要がある\n* 複雑なことはできないので割り切るか、別の方法で書かなくてはいけない\n\nな感じです。良いところも悪いところもありますが、今回筆者はアリだと判断して採用しましたし、実際良かったです。\n\n## クライアント側で実行させたい処理どう書くの\n\nSSG で静的なページを書き出すと言っても、クライアント側で実行させたい処理はあります。このサイトでは、ライトモード↔︎ダークモード切り替えや「いいね」ボタンがそれに該当します。いずれもユーザーのアクションによって DOM を書き換える必要性があります。\n\n普通に React のコンポーネントとして書いてしまうと SSG でのビルド時に静的なページとして書き出されてしまうため、なんとかする必要があります。最初は public ディレクトリ内に js ファイルを置いて Next.js の [Script](https://nextjs.org/docs/basic-features/script) タグで読み込ませていたのですが、それよりも Next.js の [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) 機能を使った方がスマートに書けます。\n\n`{ ssr: false }` 引数を渡してあげることで、そのコンポーネントはブラウザ上でレンダリングされるようになります。\n\n## GitHub Pages で公開するときの罠\n\n晴れて準備完了！いざ公開！と意気揚々と GitHub Pages にデプロイしても、うまくいかないことがあります。\n\nビルド時には以下のコマンドを実行しましょう。\n\n```\nnext build\nnext export -o docs/\ntouch docs/.nojekyll\necho 'sogo.dev' > docs/CNAME\n```\n\nポイントは公開ディレクトリ（上記の場合は `docs`）の直下に `.nojekyll` というファイルを作成していることです。これがないと `_next` ディレクトリは以下が公開されずリンク切れになります。  \n参考: [Next.js の SSG 機能で生成した静的サイトを GitHub Actions 経由で GitHub Pages に公開する](https://sidearrow.github.io/article/next-js-ssg-on-github-pages)\n\n最後のコマンドはカスタムドメイン名を使用しない場合は不要ですが、使用する場合は都度生成しておかないと消えてしまうため、カスタムドメイン名でアクセスできなくなります。\n\n## 今後やっていきたいこと\n\n以上がこのブログを作るにあたって考えたことなのですが、まだやり残したことはあります。\n\n* 記事をリッチにしたい\n  * シンタックスハイライト\n  * リンクカード\n  * 目次（ToC）\n* おすすめ記事をいい感じのアルゴリズムで出したい\n  * まずは記事を書きためなきゃ。。\n\n## 最後に\n\nつらつらと駄文を書き連ねてしまいました。勘の良い方は気づいていると思いますが、このブログは GitHub Pages でホストされている＝[ソースが見れる](https://github.com/SogoKato/sogokato.github.io)なので、もし興味のある方がいらっしゃいましたら覗いてみてください。\n","tags":[{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"},{"name":"Tailwind CSS","ref":"/tags/tailwind-css"}]},{"title":"Hello World!","date":"2022-10-11T00:00:00.000Z","ref":"/posts/2022/10/hello-world","desc":" はじめまして。  \nこれは初めての投稿です。\n\n今までブログが長く続いたことがないのですが、n度目の正直ということで今回こそは長く続くように頑張りたいと思います（とても固い決意）。\n\n@SogoKato といいます。どんな人か気になってくれた方は 自己紹介ページ をご覧いた","draft":false,"content":"\nはじめまして。  \nこれは初めての投稿です。\n\n今までブログが長く続いたことがないのですが、n度目の正直ということで今回こそは長く続くように頑張りたいと思います（とても固い決意）。\n\n@SogoKato といいます。どんな人か気になってくれた方は [自己紹介ページ](/profile) をご覧いただければと思います。\n\nこのブログの制作にあたっては、初めて React + Next.js + Tailwind CSS を触って作ってみましたが、結構いい開発者体験だったのでこれについてもまた記事に起こしていきたいな〜と思っています。。（少しゆるい決意）\n\n今まで書いてきた記事については、[私の Qiita](https://qiita.com/SogoK) を見てみてください。  \nおすすめは↓らへんです。\n\n* [Vue 3から始める人のための学習ロードマップ](https://qiita.com/SogoK/items/15ed0d9b2be4279b2f47)\n* [新卒エンジニアがCKA取得を目指してKubernetesを勉強したときの記録](https://qiita.com/SogoK/items/4ed2e118d0412c868169)\n* [GitLabのタブを開きすぎて見分けづらいのでfaviconを変える拡張機能を作った](https://qiita.com/SogoK/items/31f74b517dc3c6884c04)\n\nさて、初回から頑張りすぎると次回以降の心理的なハードルがあがっちゃうのでこれくらいにしておこうと思います。では、これからよろしくお願いします🙏\n","tags":[{"name":"Personal","ref":"/tags/personal"}]}],"slicedPosts":[{"title":"Next.jsとTailwind CSSでブログを作るときに考えたこと","date":"2022-11-13T00:00:00.000Z","ref":"/posts/2022/11/blog-with-nextjs-and-tailwindcss","desc":" このブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。","draft":false,"content":"\nこのブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。\n\nそこそこの出来栄えになったので、今回はこのブログができるまでのお話をしたいなと思ったのですが、正直なところ、以下のリンク先のページを~~まるパク~~参考にさせてもらいながら作成したので、具体的な構築方法についてはそちらをご覧いただけると良いかと思います。1ステップずつ丁寧に解説されておりとても有用でした🙏\n\n* [Next.jsを利用した初めての本格的Markdownブログサイトの構築](https://reffect.co.jp/react/nextjs-markdown-blog)\n\nなので、今回は技術的な詳細というよりも、筆者が始める前に疑問だった点や技術選定、設計まわりについて書ければなと思います。\n\n## 対象読者\n\n* 自分のブログを作ってみたい人\n* React や Next.js に興味がある人\n\n## ブログをどこでホストするか\n\n技術に関する記事を書くのであれば Qiita や Zenn でいいじゃんと思いますし、実際その方がはるかに楽で、多くのリアクションをもらいやすいと思います。そんな中、自分のブログを作る理由としては「やってみたかったから」以上の理由は存在しません。つまりロマンです。\n\nしかしながら、いざ自分のブログを作ろうと思ったときに\n\n* 簡単に、かつ高度なカスタマイズができる\n* ランニングコストが安い\n\nといった美味しい環境は思ったよりも少ないです。\n\nブログを作ると言ったら WordPress が超定番ですが、テーマを作るとなると php や WordPress の知識が必要になります。WordPress テーマづくりに携わったことがあるので、やってみると思ったより簡単なのですが、筆者のお仕事の分野とはかすらないのであまりモチベーションが湧きません。  \nまた、最低月数百円のランニングコストもかかりますし、動的にページを生成するのでレスポンスも遅くなりがちです。\n\n次に SSG（Static Site Generation; 静的サイト生成）を検討します。Markdown で原稿を書き、静的な HTML などのファイルを出力すれば、GitHub Pages で無料で公開できるので結構良さそうです。\n\nSSG のツールとしては有名なものがいくつかあります。\n\n* Next.js\n* Gatsby\n* Hugo\n* NuxtJS\n* Jekyll\n\nこのうち、Next.js と Gatsby は React ベースのため当初は検討から外していました。筆者は Hugo を選び、配布テーマを適用してみたり、自作テーマを作り始めたりしましたが、想像より学習コストが高かったので挫折してしまいました。\n\n代わりに最近波に乗っていそうな Next.js を使ってみることにしました。React を使うのは初めてだったので（チュートリアルしかやったことがない）躊躇していましたが、[最初に紹介した記事](https://reffect.co.jp/react/nextjs-markdown-blog)のおかげもあって、すんなりと構築することができました。React の基本的な知識さえあれば問題なさそうです。\n\n## どうやってデザインするか\n\nまずは Adobe XD でデザインカンプを作成します。いきなりマークアップを始めても、作りたいものが定まっていないと無駄に時間がかかってしまうので、多少手間でも作りたいもののイメージを先に決めておくと良いです。\n\n![XD](/images/posts/2022/11/xd.png)\n\n上図のような感じで、ヘッダーやサイドバー、記事一覧、記事ページをざっくりと作りました。\n\n## React の CSS よくわからん問題\n\n筆者の経験不足のせいなのですが、React で CSS でスタイルを適用するベストな方法がよくわかりませんでした😇\n\nデザインカンプを作ってみて、そこまで複雑な CSS を記述する必要がなさそうだったので、Tailwind CSS を使ってみることにしました。\n\n[Tailwind CSS](https://tailwindcss.com/) とは、HTML のクラス属性に `flex`, `pt-4`, `text-center` のようなクラス名を記述することで、`display: flex` をかけたり `padding-top` や `text-align: center` を設定できるというヤツです。\n\n軽く個人的な感想をまとめてみると\n\nPros\n* コード量が減る\n* HTML 要素を消したけど CSS は消し忘れた、みたいなことはなくなる\n* カスタムの色を設定できるなど、一定の柔軟性がある\n\nCons\n* CSS の知識は必要（それはそう）\n* 都度リファレンスを見てクラス名を確認する必要がある\n* 複雑なことはできないので割り切るか、別の方法で書かなくてはいけない\n\nな感じです。良いところも悪いところもありますが、今回筆者はアリだと判断して採用しましたし、実際良かったです。\n\n## クライアント側で実行させたい処理どう書くの\n\nSSG で静的なページを書き出すと言っても、クライアント側で実行させたい処理はあります。このサイトでは、ライトモード↔︎ダークモード切り替えや「いいね」ボタンがそれに該当します。いずれもユーザーのアクションによって DOM を書き換える必要性があります。\n\n普通に React のコンポーネントとして書いてしまうと SSG でのビルド時に静的なページとして書き出されてしまうため、なんとかする必要があります。最初は public ディレクトリ内に js ファイルを置いて Next.js の [Script](https://nextjs.org/docs/basic-features/script) タグで読み込ませていたのですが、それよりも Next.js の [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) 機能を使った方がスマートに書けます。\n\n`{ ssr: false }` 引数を渡してあげることで、そのコンポーネントはブラウザ上でレンダリングされるようになります。\n\n## GitHub Pages で公開するときの罠\n\n晴れて準備完了！いざ公開！と意気揚々と GitHub Pages にデプロイしても、うまくいかないことがあります。\n\nビルド時には以下のコマンドを実行しましょう。\n\n```\nnext build\nnext export -o docs/\ntouch docs/.nojekyll\necho 'sogo.dev' > docs/CNAME\n```\n\nポイントは公開ディレクトリ（上記の場合は `docs`）の直下に `.nojekyll` というファイルを作成していることです。これがないと `_next` ディレクトリは以下が公開されずリンク切れになります。  \n参考: [Next.js の SSG 機能で生成した静的サイトを GitHub Actions 経由で GitHub Pages に公開する](https://sidearrow.github.io/article/next-js-ssg-on-github-pages)\n\n最後のコマンドはカスタムドメイン名を使用しない場合は不要ですが、使用する場合は都度生成しておかないと消えてしまうため、カスタムドメイン名でアクセスできなくなります。\n\n## 今後やっていきたいこと\n\n以上がこのブログを作るにあたって考えたことなのですが、まだやり残したことはあります。\n\n* 記事をリッチにしたい\n  * シンタックスハイライト\n  * リンクカード\n  * 目次（ToC）\n* おすすめ記事をいい感じのアルゴリズムで出したい\n  * まずは記事を書きためなきゃ。。\n\n## 最後に\n\nつらつらと駄文を書き連ねてしまいました。勘の良い方は気づいていると思いますが、このブログは GitHub Pages でホストされている＝[ソースが見れる](https://github.com/SogoKato/sogokato.github.io)なので、もし興味のある方がいらっしゃいましたら覗いてみてください。\n","tags":[{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"},{"name":"Tailwind CSS","ref":"/tags/tailwind-css"}]}],"pages":[1],"currentPage":1,"tag":{"name":"React","ref":"/tags/react"}},"__N_SSG":true}