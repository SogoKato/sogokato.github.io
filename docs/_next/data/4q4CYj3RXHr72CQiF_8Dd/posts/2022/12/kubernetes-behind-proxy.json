{"pageProps":{"posts":[{"title":"SynologyのHyper Backupを使って自分のサーバーへバックアップ（rsync over SSH）","date":"2023-07-22T00:00:00.000Z","ref":"/posts/2023/07/synology-hyper-backup-rsync-over-ssh","desc":" 先日 Synology の NAS を導入したのですが、耐障害性を考慮すると別の拠点とのバックアップが欲しくなってきます。Synology の NAS は QuickConnect を利用することで Synology 社のサーバーを経由することで、自宅のポートを開放せずに構築することができるのがメリットです。バックアップ用途のためだけでにポートを開放するのはアレなので、自宅からのアウトバウンドの通信で定期的にバックアップを行う方法を検討しました。\n\n## 構成\n\n超シンプル構成です。\n\n!構成図\n\nNAS","draft":false,"tags":[{"name":"Synology","ref":"/tags/synology"},{"name":"NAS","ref":"/tags/nas"},{"name":"rsync","ref":"/tags/rsync"}],"showTerminalAside":false},{"title":"Fluentdでニフクラのオブジェクトストレージサービスにログを送る","date":"2023-07-05T00:00:00.000Z","ref":"/posts/2023/07/fluentd-nifcloud-object-storage-service","desc":" Fluentd の fluent-plugin-s3 を使ってニフクラのオブジェクトストレージサービスにログをアップロードする時のメモです。\n\n## ポイント\n\n* `s3_endpoint` を指定する\n  * https://jp-east-1.storage.api.nifcloud.com または https://jp-west-2.storage.api.nifcloud.com\n  * 参照: エンドポイント\n* `force_path_style` を true にする\n  * オブジェクト","draft":false,"tags":[{"name":"Fluentd","ref":"/tags/fluentd"},{"name":"ニフクラ","ref":"/tags/ニフクラ"},{"name":"ログ","ref":"/tags/ログ"}],"showTerminalAside":false},{"title":"シンプル思考を徹底しよう：この半年の振り返り","date":"2023-06-25T00:00:00.000Z","ref":"/posts/2023/06/reflection","desc":" 先日、この半年くらい担当させてもらった仕事が一区切りついたので振り返りをしておこうかなと思います。\n\n全部よくある話だと思いますが、「経験しないとわからないこともあるものだ」ということで、今回は思考垂れ流し回です。\n\n## とにかく余裕を\n\n取り掛かり始めたころ、諸先輩方にファーストリリースではとにかく最低限のものを作るように言われたが、今ならそれが身に沁みてわかる。スケジュール的に余裕を持たせる効果のほか、エンハンスの伸びしろも大きくなるので、リリース後に機能拡充していくことで対外的な見た目が良くなる効","draft":false,"tags":[{"name":"Personal","ref":"/tags/personal"}],"showTerminalAside":false},{"title":"KubernetesのPodからラズパイのGPIOを操作する","date":"2023-06-24T00:00:00.000Z","ref":"/posts/2023/06/k8s-raspi-gpio","desc":" 今まで Docker Compose で動かしてたアプリを Kubernetes に移植したときのメモです。\n\n## Docker Compose では\n\nDocker の `--device` オプションと同じ記法で指定できていました。\n\n```yaml\nservices:\n  app:\n    image: hoge\n    devices:\n      - /dev/gpiomem\n```\n\n## Kubernetes では\n\nデバイスプラグインを使用して Kubelet にハードウェアリソースを知","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"},{"name":"Raspberry Pi","ref":"/tags/raspberry-pi"}],"showTerminalAside":false},{"title":"Ubuntu 22.04ではusercfg.txtがデフォルトでincludeされていないので注意","date":"2023-06-14T00:00:00.000Z","ref":"/posts/2023/06/ubuntu-22.04-raspi-config.txt","desc":" タイトルの通りです。これにしばらくハマってしまったので戒めのために書いておきます。\n\n## tl;dr\n\nUbuntu 20.04 の時と同じ設定ファイルをラズパイの /boot/firmware に入れていたけど反映されていなかった。調べてみたらそのファイルを include する文が Ubuntu 22.04 では消されていた。\n\n## そもそも config.txt とは？\n\n> The Raspberry Pi uses a configuration file instead of the BI","draft":false,"tags":[{"name":"Ubuntu","ref":"/tags/ubuntu"},{"name":"Raspberry Pi","ref":"/tags/raspberry-pi"}],"showTerminalAside":false},{"title":"ラズパイでK3sクラスター構築","date":"2023-06-13T00:00:00.000Z","ref":"/posts/2023/06/k3s-setup","desc":" 今まで kubeadm でクラスター運用をしていたのですが、ラズパイくんたちのお引越しの関係で再構築することにしました。Raspberry Pi 4B 2GB や 3A+（RAM 512MB）も join させたかったこともあり、エッジ環境での動作も想定されている K3s を選びました。\n\n## 環境\n\n* Raspberry Pi 4B 8GB x 2, Raspberry Pi 4B 4GB x 1, Raspberry Pi 4B 2GB x 1\n  * SSD ブート\n  * PoE+ 電源\n  ","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"},{"name":"K3s","ref":"/tags/k3s"},{"name":"Raspberry Pi","ref":"/tags/raspberry-pi"}],"showTerminalAside":false},{"title":"CeleryにおけるSQLAlchemyのセッション管理","date":"2023-05-15T00:00:00.000Z","ref":"/posts/2023/05/celery-sqlalchemy","desc":" 前回の記事では SQLAlchemy の Session について解説しました。今回はその応用として、Celery においてどのように Session を管理するかを考えたいと思います。\n\n関連記事：\n* SQLAlchemyのセッション・トランザクションを理解する\n* SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ\n\n## 結論\n\n以下のように DB 操作を行うタスクのためのクラスを作ります。\n\n```python\nfrom typing impo","draft":false,"tags":[{"name":"Python","ref":"/tags/python"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"},{"name":"データベース","ref":"/tags/データベース"},{"name":"Celery","ref":"/tags/celery"}],"showTerminalAside":false},{"title":"SQLAlchemyのセッション・トランザクションを理解する","date":"2023-05-14T00:00:00.000Z","ref":"/posts/2023/05/sqlalchemy-sessions-and-transactions","desc":" SQLAlchemy の Session や scoped_session、トランザクションに関して理解していきます。\n\n## 用語おさらい\n\n### セッション（Session）\n\nSQLAlchemy の Session オブジェクトは、ORM マッピングされたオブジェクトの永続化に関する操作を管理するオブジェクトです。\n\n`sqlalchemy.orm.Session` を直接インスタンス化しても良いですが、実環境では sessionmaker を使うことが一般的です。sessionmaker は ","draft":false,"tags":[{"name":"Python","ref":"/tags/python"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"},{"name":"データベース","ref":"/tags/データベース"}],"showTerminalAside":true},{"title":"Reactで検索・ソート可能なDataTableを自作する","date":"2023-04-22T00:00:00.000Z","ref":"/posts/2023/04/datatable-react","desc":" 最近、MUI の妹分の UI ライブラリである Joy-UI を使ってます。現在進行形で活発に開発が進んでいて、設計（デザイン）も今時な感じで好感触です。ところどころまだ開発されていないコンポーネントもちらほらあるものの、ドキュメントには代替策がコード付きで載っていてとても親切です。\n\nMUI X というより発展的なコンポーネントをもつ UI ライブラリもあるのですが、そこに今回のテーマである「データテーブル」に該当する Data Grid というものがあります。これは超すごくて、雑に言うと Excel ","draft":false,"tags":[{"name":"React","ref":"/tags/react"},{"name":"Joy-UI","ref":"/tags/joy-ui"}],"showTerminalAside":false},{"title":"Kanikoでコンテナイメージつくるならcache=trueは有効にしておこう","date":"2023-04-18T00:00:00.000Z","ref":"/posts/2023/04/kaniko-cache","desc":" !ぜんぜんわからない　俺たちは雰囲気でカニコをやっている\n\n恥ずかしながら、わたしは雰囲気で kaniko にコンテナイメージのビルドをしてもらっていることに気づきました。1年以上 GitLab CI で kaniko を使っておきながら、ただ「特権コンテナを使わずにイメージつくれるやつ」くらいの認識しかしていなかったです。\n\n## kaniko の cache=true オプション\n\nkaniko には `--cache` というフラグがあり、これを true にすることでコンテナのビルド時にキャッシュ","draft":false,"tags":[{"name":"Kaniko","ref":"/tags/kaniko"},{"name":"CI/CD","ref":"/tags/ci-cd"},{"name":"コンテナ","ref":"/tags/コンテナ"},{"name":"GitLab","ref":"/tags/gitlab"}],"showTerminalAside":false},{"title":"IPoE回線の自宅のWebサービスをVPN経由で固定IPのクラウドから公開する","date":"2023-04-15T00:00:00.000Z","ref":"/posts/2023/04/reverse-proxy-to-home-ipoe-network","desc":" PPPoE 回線が遅いので IPoE（IPv4 over IPv6）へ移行しようと思いました。以前は2つのルーターを使って、PPPoE と IPoE の2セッションを張ることができたのですが、ある時からできなくなり、しばらく PPPoE だけで生活していました。とはいえやはり遅い、遅すぎる……ということで、今回の記事に至ります。\n\nIPoE に移行するにあたっての課題は**任意のポートを開放できないこと**です。\n\n代わりの方法を考えていたところ、ちょうど手元に1台 AWS Lightsail のサーバー","draft":false,"tags":[{"name":"自宅サーバー","ref":"/tags/自宅サーバー"},{"name":"ネットワーク","ref":"/tags/ネットワーク"},{"name":"VPN","ref":"/tags/vpn"},{"name":"WireGuard","ref":"/tags/wireguard"},{"name":"HAProxy","ref":"/tags/haproxy"}],"showTerminalAside":false},{"title":"CKAD受検記録【2023年版】","date":"2023-03-30T00:00:00.000Z","ref":"/posts/2023/03/certified-kubernetes-application-developer","desc":" 2023年3月30日に Certified Kubernetes Application Developer (CKAD) を受験し、合格しましたのでその受検記録記事です。ちょうど1年前に Certified Kuberenetes Administrator (CKA) を取っていたので、その続きとなります。\n\n前回の記事：新卒エンジニアがCKA取得を目指してKubernetesを勉強したときの記録\n\n## 対象読者\n\n* Kubernetes を使っているが、資格はまだ取ってない人\n* CKA を取っ","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"},{"name":"資格","ref":"/tags/資格"}],"showTerminalAside":false},{"title":"PyScriptを使ってブログのサンプルコードを実行させる","date":"2023-03-06T00:00:00.000Z","ref":"/posts/2023/03/pyscript-codeblock","desc":" 前回の記事を書くときに WebAssembly でブログのコードブロックのコードを実行させられたら面白いかも、ということで PyScript を使って実装してみました。React & Next.js で使う際の注意点についても書こうと思います。\n\n以下については前提知識としてこの記事では解説しません。\n\n* PyScript\n* Pyodide\n* WebAssembly\n* react-markdown のコードブロック（バッククォート3つ \\```）をカスタマイズする方法\n\n## やったこと\n\n* r","draft":false,"tags":[{"name":"Python","ref":"/tags/python"},{"name":"WebAssembly","ref":"/tags/webassembly"},{"name":"PyScript","ref":"/tags/pyscript"},{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"}],"showTerminalAside":true},{"title":"Pythonのunittest.mock.patchではどこにパッチするかが重要","date":"2023-03-04T00:00:00.000Z","ref":"/posts/2023/03/python-unittest-mock-where-to-patch","desc":" Python 公式ドキュメントの unittest.mock のページにドンピシャの内容が書いてありますが、なかなか気づけずにハマってしまっていたのでメモです。\n\n`unittest.mock.patch` でパッチしたけど当たってない気がする人は参考にしてみてください。\n\n下記の引用に要点が凝縮されています。\n\n> ### どこにパッチするか\n>\n> `patch()` は (一時的に) ある 名前 が参照しているオブジェクトを別のものに変更することで適用されます。任意のオブジェクトには、それを参照する","draft":false,"tags":[{"name":"Python","ref":"/tags/python"},{"name":"単体テスト","ref":"/tags/単体テスト"}],"showTerminalAside":true},{"title":"Ansibleでgpg公開鍵とaptのサードパーティリポジトリを追加する ～Terraformをインストールしたい～","date":"2023-03-01T00:00:00.000Z","ref":"/posts/2023/03/ansible-apt-repo-signed-by-gpg-key","desc":" apt を使って docker や terraform をインストールする時など、提供元のサードパーティ apt リポジトリを追加する場合が結構ありますよね。その際に、今までは `apt-key` を使って OpenPGP 公開鍵をインポートしていたのですが、`apt-key` は Debian 11 と Ubuntu 22.04 を最後に使えなくなる ので、今後は `gnupg` を使った方法が主流になっていきます。\n\nAnsible にも ansible.builtin.apt_key module ","draft":false,"tags":[{"name":"Ansible","ref":"/tags/ansible"},{"name":"Terraform","ref":"/tags/terraform"},{"name":"APT","ref":"/tags/apt"}],"showTerminalAside":false},{"title":"TerraformでAPI Gatewayのスロットリングを設定する","date":"2023-02-23T00:00:00.000Z","ref":"/posts/2023/02/aws-api-gateway-terraform-throttling-settings","desc":" AWS API Gateway のスロットリングを Terraform を使って設定する方法を見つけるまでに少し手間取ったのでメモ。\n\n## AWS マネジメントコンソールでの場所\n\n今回 Terraform で設定するのは、マネジメントコンソールの各ステージの設定画面内の「デフォルトのメソッドスロットリング」に該当する箇所です。\n\n!management console\n\n## そもそも API Gateway のスロットリングとは\n\nAPI Gateway では API が1秒あたりに処理できるリクエ","draft":false,"tags":[{"name":"AWS","ref":"/tags/aws"},{"name":"API Gateway","ref":"/tags/api-gateway"},{"name":"Terraform","ref":"/tags/terraform"}],"showTerminalAside":false},{"title":"プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部","date":"2023-02-22T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part3","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んだので、そのまとめを部ごとに書いていこうと思います。\n\n1. 単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部\n1. リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半\n1. ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半\n1. プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部（こ","draft":false,"tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半","date":"2023-02-19T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-2","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. 単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部\n1. リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半\n1. ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半（この記事）\n1. プロセス外依存は統合テストで確認しよう：単体テストの考え方／使","draft":false,"tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"FastAPIとSQLAlchemy2.0ならもう型ヒントを諦めなくていい","date":"2023-02-08T00:00:00.000Z","ref":"/posts/2023/02/fastapi-orm-sqlalchemy","desc":" サチコ（Google Search Console）を眺めていたら `FastAPI MySQL` がそれなりに需要ありそうと思ったので、FastAPI と SQLAlchemy を組み合わせて ORM を使う方法を紹介したいと思います。最近の SQLAlchemy（1.4以降）ではマッピングされたオブジェクトに型を適用することもできるので、型ヒントを活かして型安全なコードを書くことも難しくなくなっています。\n\n## 環境\n\n* Python 3.10.6\n* FastAPI 0.89.1\n* SQLAl","draft":false,"tags":[{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"},{"name":"ORM","ref":"/tags/orm"}],"showTerminalAside":false},{"title":"TypedDictはdictのsubtypeではないので関数の引数にはMappingを使う","date":"2023-02-06T00:00:00.000Z","ref":"/posts/2023/02/typeddict-is-not-subtype-of-dict","desc":" Python の dict（辞書）を TypeScript の interface のように扱えて便利な TypedDict ですが、**dict のサブクラスではない**というのが少し落とし穴だなと思ったのでメモ。\n\n## まずは PEP を見よう\n\n大抵のことは公式ドキュメントを見れば書いてあります。今回も例外なくそうでした。\n\n> First, any TypedDict type is consistent with `Mapping[str, object]`.\n\nhttps://peps.py","draft":false,"tags":[{"name":"Python","ref":"/tags/python"}],"showTerminalAside":false},{"title":"リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半","date":"2023-02-04T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. 単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部\n1. リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半（この記事）\n1. ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半\n1. プロセス外依存は統合テストで確認しよう：単体テストの考え方／使","draft":false,"tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部","date":"2023-01-17T00:00:00.000Z","ref":"/posts/2023/01/unit-testing-principles-practices-and-patterns-part1","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. 単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部（この記事）\n1. リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半\n1. ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半\n1. プロセス外依存は統合テストで確認しよう：単体テストの考え方／使","draft":false,"tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ","date":"2023-01-12T00:00:00.000Z","ref":"/posts/2023/01/sqlalchemy-dealing-with-disconnects","desc":" FastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2.1.1\n\n## 問題\n\n```\nMySQLdb.OperationalError: (2006, 'MySQL server has gone away')\n```\n\n最後に MySQL サーバーに接続してから","draft":false,"tags":[{"name":"Python","ref":"/tags/python"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"},{"name":"MySQL","ref":"/tags/mysql"},{"name":"データベース","ref":"/tags/データベース"}],"showTerminalAside":false},{"title":"2023年版 キーボードマッピングの個人的メモ","date":"2023-01-08T00:00:00.000Z","ref":"/posts/2023/01/keyboard-remap","desc":" 不定期的に「あーでもない、こーでもない」と言ってキーボードのマッピングをいじりだしてしまうことってありますよね。私はあります。限りあるキーの中から自分にとっての最適解を見つける作業はなんだかんだ楽しいです。\n\n今回は 2023 年版、私のキーボードのマッピングを書きとめておこうと思います。\n\n過去の記事: Windows10 と PowerToys で US キーボードでも無変換・変換キーを使って IME を一発で切り替える\n\n## 環境\n\n* 使うパソコン\n  * Windows デスクトップ\n  * ","draft":false,"tags":[{"name":"キーボード","ref":"/tags/キーボード"}],"showTerminalAside":false},{"title":"プロキシ環境でKubernetes構築（Containerd+Calico）","date":"2022-12-27T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-behind-proxy","desc":" 同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4GB）\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.14\n* Calico v3.24.5\n\nコントロールプレーン、ノード1台ずつの構成としま","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false},{"title":"Ubuntu 22.04でのKubernetesクラスター構築（ContainerdとSystemdCgroup）","date":"2022-12-26T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-ubuntu22.04-cgroup-systemd","desc":" 公式ドキュメントのコマンドを手順通り流し込めば割と簡単に構築できる Kubernetes クラスターですが、Ubuntu 22.04 になってから少し手を入れる必要が出てきたので差分を紹介しておきます。\n\n**2022-02-16 更新：Kubernetes ドキュメントの日本語版が更新されていたのでリライトしました。**\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.16\n\n## 何が変わっ","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false},{"title":"KubernetesでCoreDNSがループしてしまう問題への対処","date":"2022-12-24T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-coredns-loop","desc":" 1年前にも Kubernetes クラスターを自力で組んでトラブルシューティングしてみる【The Hard Way】の記事の中で軽く解説したネタです。\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n\n## 問題\n\nKubernetes クラスター内で名前解決に使われる CoreDNS の Pod が `CrashLoopBackOff` になってしまい再起動を繰り返す問題が発生することがあります。\n\n```\n# kubectl ","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false},{"title":"VS Code Serverでリモートホストのコンテナ上開発環境に直接アクセスする","date":"2022-12-17T00:00:00.000Z","ref":"/posts/2022/12/vscode-server-devcontainer","desc":" 今回は「ぼくのかんがえたさいきょうのかいはつかんきょう」を紹介したいと思います。\n\nVS Code Server を使い、リモートサーバー上でコンテナとして動かしている開発環境に直接乗り込んでみよう、というアイデアです。\n\nSSH もポート開放も不要なのでとてもお手軽です。\n\n## 2023/06/14 追記\n\n以下で紹介する方法が最近は使えなくなってしまったようです。少し前から\n\n> Your tunnel connection is outdated. Upgrade to the latest ve","draft":false,"tags":[{"name":"VS Code","ref":"/tags/vs-code"},{"name":"開発環境","ref":"/tags/開発環境"}],"showTerminalAside":false},{"title":"よくあるSPA+API構成でのOpenID Connectクライアント実装","date":"2022-12-02T00:00:00.000Z","ref":"/posts/2022/12/openid-connect-fastapi","desc":" この記事はニフクラ等を提供している、富士通クラウドテクノロジーズ Advent Calendar 2022の2日目の記事です。\n\n昨日は @ntoofu さんの パケットキャプチャからKubernetes APIのTLS通信を解析する でした。  \n私は TLS な時点でパケットキャプチャを諦めてしまいそうですが Linux の便利な仕組みと気合があれば TLS 1.3 のパケットキャプチャも可能だとわかり、とても有益でした。私もギークなエンジニア目指して頑張ります。\n\n今日は OpenID Connec","draft":false,"tags":[{"name":"OpenID Connect","ref":"/tags/openid-connect"},{"name":"認証/認可","ref":"/tags/認証-認可"},{"name":"SPA","ref":"/tags/spa"},{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"}],"showTerminalAside":false},{"title":"GitLab CIのrulesとworkflowを理解する","date":"2022-11-17T00:00:00.000Z","ref":"/posts/2022/11/gitlab-rules-workflow","desc":" GitLab CI の rules を使って Dockerfile などの特定のファイルの変更時のみ Docker イメージを作成するパイプラインを回して、それ以外の時には既存の Docker イメージを使用して CI を実行する、という組み方をしたかったのですが、書き方に結構手間取ったのでメモ。\n\n環境: GitLab.com 15.6.0-pre\n\n## rules とは\n\nhttps://docs.gitlab.com/ee/ci/yaml/#rules\n\nそれぞれのジョブについて、パイプラインに追","draft":false,"tags":[{"name":"GitLab","ref":"/tags/gitlab"},{"name":"CI/CD","ref":"/tags/ci-cd"}],"showTerminalAside":false},{"title":"Next.jsとTailwind CSSでブログを作るときに考えたこと","date":"2022-11-13T00:00:00.000Z","ref":"/posts/2022/11/blog-with-nextjs-and-tailwindcss","desc":" このブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。\n\nそこそこの出来栄えになったので、今回はこのブログができるまでのお話をしたいなと思ったのですが、正直なところ、以下のリンク先のページを~~まるパク~~参考にさせてもらいながら作成したので、具体的な構築方法につい","draft":false,"tags":[{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"},{"name":"Tailwind CSS","ref":"/tags/tailwind-css"}],"showTerminalAside":false},{"title":"Hello World!","date":"2022-10-11T00:00:00.000Z","ref":"/posts/2022/10/hello-world","desc":" はじめまして。  \nこれは初めての投稿です。\n\n今までブログが長く続いたことがないのですが、n度目の正直ということで今回こそは長く続くように頑張りたいと思います（とても固い決意）。\n\n@SogoKato といいます。どんな人か気になってくれた方は 自己紹介ページ をご覧いただければと思います。\n\nこのブログの制作にあたっては、初めて React + Next.js + Tailwind CSS を触って作ってみましたが、結構いい開発者体験だったのでこれについてもまた記事に起こしていきたいな〜と思っています","draft":false,"tags":[{"name":"Personal","ref":"/tags/personal"}],"showTerminalAside":false}],"post":{"title":"プロキシ環境でKubernetes構築（Containerd+Calico）","date":"2022-12-27T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-behind-proxy","desc":" 同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4GB）\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.14\n* Calico v3.24.5\n\nコントロールプレーン、ノード1台ずつの構成としま","draft":false,"tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false,"content":"\n同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4GB）\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.14\n* Calico v3.24.5\n\nコントロールプレーン、ノード1台ずつの構成とします。プロキシを経由しなければインターネットに出られないようになっています。\n\n![network](//www.plantuml.com/plantuml/png/SoWkIImgAStDuSehJybCJ5Uevb9Go4ijASylobP8pybFIim12O51KNvfIMgHDP1NYwIee2YpBB4a5QugCIMbABMuMC5MGSdGt4ZFs53FGCz0tz1CoPeBnHo5Q6mg3PLYhQ7AalFpIehoSmfo4lDIOM9v-Icf40VKSZcavgK07Gu0)\n\nプライベートネットワークの CIDR は `172.31.0.0/16`、プロキシは `http://172.31.0.1:3128` として進めます。\n\nService CIDR はデフォルトの `10.96.0.0/12` を、Pod Network CIDR は Calico のデフォルトである `192.168.0.0/16` を使います。\n\n💡 筆者の環境ではこの記事で紹介する内容で構築できましたが、環境によって状況が異なる可能性があります。プロキシ配下での構築に挑戦する前に、**まずは似た環境のインターネット接続があるサーバーで試すことをおすすめします**。\n\n## プロキシの設定が必要な箇所\n\n### 環境変数（`~/.bashrc`）\n\n#### コントロールプレーン\n\n```sh\nexport HTTP_PROXY=http://172.31.0.1:3128\nexport HTTPS_PROXY=http://172.31.0.1:3128\nexport NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12,192.168.0.0/16\n```\n\nコントロールプレーンでは `NO_PROXY` に Sercice CIDR の IP レンジ（デフォルトは `10.96.0.0/12`）と Pod Network CIDR の IP レンジを設定しておくことで `kubeadm init` 時の preflight check の WARNING を抑えることができます[^1]。\n\n反映するには `source ~/.bashrc` します。\n\n[^1]: 以前は IP レンジを指定できなかったようですが、今は問題なく使えます。https://github.com/kubernetes/kubeadm/issues/324#issuecomment-331483277\n\n#### ノード\n\n```sh\nexport HTTP_PROXY=http://172.31.0.1:3128\nexport HTTPS_PROXY=http://172.31.0.1:3128\nexport NO_PROXY=localhost,127.0.0.1,172.31.0.0/16\n```\n\nノードでは `kubeadm init` を実行しないのでこれだけで OK。\n\n### `/etc/apt/apt.conf`\n\n各種ライブラリのインストールのために必要です。\n\n```\nAcquire::http::proxy \"http://172.31.0.1:3128\";\nAcquire::https::proxy \"http://172.31.0.1:3128\";\n```\n\n### `/etc/systemd/system/containerd.service.d/http-proxy.conf`\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12\"\n```\n\n`NO_PROXY` に Pod Network CIDR の IP レンジも追加しようかと思ったのですが、ノードを跨いだ Pod 間の通信など試した範囲では追加しなくても異常がなかったので追加していません。  \n筆者の Kubernetes の知識が浅いだけかもしれないので、検証不足でしたら教えていただけるとありがたいです。🙇\n\nこのファイルを変更したら Containerd の再起動が必要です。\n\n```sh\nsystemctl daemon-reload\nsystemctl restart containerd\n```\n\n## 構築手順\n\n上記のプロキシ設定以外は通常の手順と同じです。\n\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n\nUbuntu 22.04 で構築する際の注意点については [Ubuntu 22.04でのKubernetesクラスター構築（ContainerdとSystemdCgroup）](/posts/2022/12/kubernetes-ubuntu22.04-cgroup-systemd) をご参照ください。\n\n```sh\nkubeadm init --pod-network-cidr 192.168.0.0/16\n```\n\n### ネットワークプラグインの適用\n\n構築が完了したらネットワークプラグインを適用します。以下は Calico を使う場合のコマンドです。\n\n```sh\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/calico.yaml -O\nkubectl apply -f calico.yaml\n```\n\n`kubectl -n kube-system get po -w` して、1つの `calico-kube-controllers` とノード数分の `calico-node` Pod が Running なら問題ありません。CoreDNS がクラッシュするバグを踏んだら [KubernetesでCoreDNSがループしてしまう問題への対処](/posts/2022/12/kubernetes-coredns-loop) の記事を参考にしてみてください。\n\n## 動作確認\n\n簡単な動作確認をしてみます。\n\n```sh\nkubectl create deployment nginx --image=nginx\n```\n\n```sh\nPOD_NAME=$(kubectl get pods -l app=nginx -o jsonpath=\"{.items[0].metadata.name}\")\n```\n\n別のシェルを開き、`curl localhost:8080` を試してみます。\n\n```sh\nkubectl port-forward $POD_NAME 8080:80\n```\n\nログを見てみます。\n\n```sh\nkubectl logs $POD_NAME\n```\n\nexec を試します。\n\n```sh\nkubectl exec -ti $POD_NAME -- nginx -v\n```\n\nNodePort Service を試します。\n\n```sh\nkubectl expose deployment nginx --port 80 --type NodePort\n```\n\n```sh\nNODE_PORT=$(kubectl get svc nginx \\\n  --output=jsonpath='{range .spec.ports[0]}{.nodePort}')\n```\n\n```sh\ncurl 127.0.0.1:$NODE_PORT\n```\n\n```sh\nkubectl delete svc nginx\n```\n\n次に Cluster IP Service を試します。\n\n```sh\nkubectl expose deployment nginx --port 80 --type ClusterIP\n```\n\nクライアントを想定した Pod を建てます（nginx ですが）。\n\n```sh\nkubectl create deployment client --image=nginx\n```\n\n```sh\nPOD_NAME_CLIENT=$(kubectl get pods -l app=client -o jsonpath=\"{.items[0].metadata.name}\")\n```\n\nPod 内で `curl nginx` を実行します。\n\n```sh\nkubectl exec -ti $POD_NAME_CLIENT -- curl nginx\n```\n\n`>Welcome to nginx!` の HTML が返ってこれば OK！\n\n## トラブルシューティング集\n\n### `FailedCreatePodSandBox` - ホストのプライベート IP にアクセス不可\n\n`calico-kube-controllers` が ContainerCreating で止まってしまう問題が発生しました。\n\n```\nEvents:\n  Type     Reason                  Age                 From               Message\n  ----     ------                  ----                ----               -------\n  Warning  FailedScheduling        115s                default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..\n  Normal   Scheduled               104s                default-scheduler  Successfully assigned kube-system/calico-kube-controllers-7bdbfc669-97wdp to controlplane\n  Warning  FailedCreatePodSandBox  103s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox \"6a029253befac6840d358f8f78b865510bb3874b971fc7241d4ded6b1e92ce2d\": plugin type=\"calico\" failed (add): stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/\n  Normal   SandboxChanged          16s (x3 over 103s)  kubelet            Pod sandbox changed, it will be killed and re-created.\n```\n\n`stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/` のエラーメッセージが出ていますが、実際にはマウントはできていました。\n\n「マウントはできて nodename（ホスト名）は取得できているが、プロキシに阻まれて通信できていないのでは？」と考え、Containerd の NO_PROXY の設定にホストのプライベートネットワークの CIDR を追記したら `172.31.0.0/16` たらこの問題は解決しました。\n\n```\n# vim /etc/systemd/system/containerd.service.d/http-proxy.conf\n```\n\n`172.31.0.0/16` を追記。\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16\"\n```\n\n```\n# systemctl daemon-reload\n# systemctl restart containerd\n# kubectl -n kube-system delete po calico-kube-controllers-7bdbfc669-97wdp --force\nWarning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\npod \"calico-kube-controllers-7bdbfc669-97wdp\" force deleted\n```\n\n### `FailedCreatePodSandBox` - Service の IP にアクセス不可\n\n状況は変わったものの、こちらも `calico-kube-controllers` が ContainerCreating で止まってしまう問題です。\n\n```\nEvents:\n  Type     Reason                  Age                From               Message\n  ----     ------                  ----               ----               -------\n  Normal   Scheduled               3m12s              default-scheduler  Successfully assigned kube-system/calico-kube-controllers-7bdbfc669-9gltp to controlplane\n  Warning  FailedCreatePodSandBox  72s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox \"68070146a6bd3c3a3044cbe84495c39ef3abafd069f171db2a185c8925aee2d1\": plugin type=\"calico\" failed (add): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": Service Unavailable\n  Normal   SandboxChanged          12s (x2 over 72s)  kubelet            Pod sandbox changed, it will be killed and re-created.\n```\n\nこちらはエラーメッセージの通りなので、Service CIDR を Containerd の NO_PROXY に追加します。\n\n```\n# vim /etc/systemd/system/containerd.service.d/http-proxy.conf\n```\n\n`10.96.0.0/12` を追記。\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12\"\n```\n\n先ほどと同じように daemon-reload, restart containerd, Pod の強制削除をします。\n\n## まとめ\n\n最後までお読みいただきありがとうございます。\n\nプロキシ環境での Kubernetes クラスター構築は、通常のクラスター構築よりも Kubernetes のネットワーク周りの知識が要求されるので少しハードルが上がります。\n\n冒頭にも書きましたが、まずはインターネットに直接繋がる環境で構築を試してみて、その後にプロキシ環境での構築を実施すると原因の切り分けがスムーズになると思います。\n\n## 参考文献\n\n* [Installing kubernetes behind a corporate proxy](https://medium.com/@vivekanand.poojari/installing-kubernetes-behind-a-corporate-proxy-bc5582e43fb8)\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n* [Install Calico networking and network policy for on-premises deployments](https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises)\n"}},"__N_SSG":true}