<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><link rel="icon" href="/favicon.ico"/><title>Python - Sogo.dev</title><meta name="description" content="@SogoKatoのブログ。技術系の記事を書きます。Pythonについての記事を表示しています。"/><meta http-equiv="content-language" content="ja"/><meta property="og:url" content="https://sogo.dev/tags/python/page/1"/><meta property="og:type" content="website"/><meta property="og:title" content="Python - Sogo.dev"/><meta property="og:description" content="@SogoKatoのブログ。技術系の記事を書きます。Pythonについての記事を表示しています。"/><meta property="og:site_name" content="Sogo.dev"/><meta property="og:image" content="https://sogo.dev/images/ogp-image.jpg"/><meta name="twitter:card" content="summary"/><meta name="next-head-count" content="13"/><link rel="stylesheet" href="https://pyscript.net/latest/pyscript.css"/><style>
        .py-overlay, .py-pop-up {display: none;}
        </style><link rel="alternate" href="/feed.xml" type="application/rss+xml" title="Sogo.dev"/><link rel="preconnect" href="https://use.typekit.net" crossorigin /><link rel="preload" href="/_next/static/css/80c8e95b286f26bf.css" as="style"/><link rel="stylesheet" href="/_next/static/css/80c8e95b286f26bf.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-d5a66f680f55dead.js" defer=""></script><script src="/_next/static/chunks/framework-d507767242394e30.js" defer=""></script><script src="/_next/static/chunks/main-f4616c45ce8fd4b5.js" defer=""></script><script src="/_next/static/chunks/pages/_app-544ebbd85389bdbb.js" defer=""></script><script src="/_next/static/chunks/541-77bbfd27f79d7fee.js" defer=""></script><script src="/_next/static/chunks/pages/tags/%5Btag%5D/page/%5Bpage%5D-dd3b1dcf7b65203b.js" defer=""></script><script src="/_next/static/p-ZcBjky8xbDNJC8ns1xV/_buildManifest.js" defer=""></script><script src="/_next/static/p-ZcBjky8xbDNJC8ns1xV/_ssgManifest.js" defer=""></script><style data-href="https://use.typekit.net/suf5fdm.css">@import url("https://p.typekit.net/p.css?s=1&k=suf5fdm&ht=tk&f=18518&a=11062204&app=typekit&e=css");@font-face{font-family:"rooney-sans";src:url("https://use.typekit.net/af/c27ef1/00000000000000007735a2d8/30/l?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3") format("woff2"),url("https://use.typekit.net/af/c27ef1/00000000000000007735a2d8/30/d?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3") format("woff"),url("https://use.typekit.net/af/c27ef1/00000000000000007735a2d8/30/a?primer=7cdcb44be4a7db8877ffa5c0007b8dd865b3bbc383831fe2ea177f62257a9191&fvd=n9&v=3") format("opentype");font-display:auto;font-style:normal;font-weight:900;font-stretch:normal}.tk-rooney-sans{font-family:"rooney-sans",sans-serif}</style></head><body><div id="__next"><div class="bg-neutral-200 dark:bg-neutral-900 duration-400 min-h-screen text-neutral-900 dark:text-neutral-50 transition-all"><div class="grid grid-cols-10 justify-center max-w-7xl mx-auto"><header class="col-span-10"><div class="max-w-4xl mt-4 sm:mt-0 mx-auto flex justify-center sm:justify-between h-36 sm:h-48 items-center relative w-11/12"><div class="hidden sm:block"></div><a class="w-72 sm:w-auto" href="/"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27480%27%20height=%27160%27/%3e"/></span><img alt="logo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="logo" src="/images/logo.svg" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></a></div></header><main class="col-span-10 md:col-span-7"><div><div class="bg-white dark:bg-neutral-800 mx-auto mb-11 p-8 rounded-3xl shadow-lg w-11/12"><div><a class="block" href="/posts/2023/03/pyscript-codeblock"><p>2023<!-- -->年<!-- -->3<!-- -->月<!-- -->6<!-- -->日</p><h2 class="mt-5 font-bold leading-tight mb-5 text-4xl">PyScriptを使ってブログのサンプルコードを実行させる</h2><p class="line-clamp-3 my-5 text-neutral-600 dark:text-neutral-300"> 前回の記事を書くときに WebAssembly でブログのコードブロックのコードを実行させられたら面白いかも、ということで PyScript を使って実装してみました。React &amp; Next.js で使う際の注意点について</p></a><ul class="flex flex-wrap mt-5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/webassembly"># <!-- -->WebAssembly</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/pyscript"># <!-- -->PyScript</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/javascript"># <!-- -->JavaScript</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/react"># <!-- -->React</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/next.js"># <!-- -->Next.js</a></ul></div></div><div class="bg-white dark:bg-neutral-800 mx-auto mb-11 p-8 rounded-3xl shadow-lg w-11/12"><div><a class="block" href="/posts/2023/03/python-unittest-mock-where-to-patch"><p>2023<!-- -->年<!-- -->3<!-- -->月<!-- -->4<!-- -->日</p><h2 class="mt-5 font-bold leading-tight mb-5 text-4xl">Pythonのunittest.mock.patchではどこにパッチするかが重要</h2><p class="line-clamp-3 my-5 text-neutral-600 dark:text-neutral-300"> Python 公式ドキュメントの unittest.mock のページにドンピシャの内容が書いてありますが、なかなか気づけずにハマってしまっていたので</p></a><ul class="flex flex-wrap mt-5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/単体テスト"># <!-- -->単体テスト</a></ul></div></div><div class="bg-white dark:bg-neutral-800 mx-auto mb-11 p-8 rounded-3xl shadow-lg w-11/12"><div><a class="block" href="/posts/2023/02/fastapi-orm-sqlalchemy"><p>2023<!-- -->年<!-- -->2<!-- -->月<!-- -->8<!-- -->日</p><h2 class="mt-5 font-bold leading-tight mb-5 text-4xl">FastAPIとSQLAlchemy2.0ならもう型ヒントを諦めなくていい</h2><p class="line-clamp-3 my-5 text-neutral-600 dark:text-neutral-300"> サチコ（Google Search Console）を眺めていたら `FastAPI MySQL` がそれなりに需要ありそうと思ったので、FastAPI と SQLAlchemy を組み合わせて ORM を使う方法を紹介したいと思います。最近の SQLAlchemy（1.4以降）ではマッピングされ</p></a><ul class="flex flex-wrap mt-5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/fastapi"># <!-- -->FastAPI</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/sqlalchemy"># <!-- -->SQLAlchemy</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/orm"># <!-- -->ORM</a></ul></div></div><div class="bg-white dark:bg-neutral-800 mx-auto mb-11 p-8 rounded-3xl shadow-lg w-11/12"><div><a class="block" href="/posts/2023/02/typeddict-is-not-subtype-of-dict"><p>2023<!-- -->年<!-- -->2<!-- -->月<!-- -->6<!-- -->日</p><h2 class="mt-5 font-bold leading-tight mb-5 text-4xl">TypedDictはdictのsubtypeではないので関数の引数にはMappingを使う</h2><p class="line-clamp-3 my-5 text-neutral-600 dark:text-neutral-300"> Python の dict（辞書）を TypeScript の interface のように扱えて便利な TypedDict ですが、**dict のサブクラスではない**というのが少し落とし穴だなと思ったのでメモ。

##</p></a><ul class="flex flex-wrap mt-5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a></ul></div></div><div class="bg-white dark:bg-neutral-800 mx-auto mb-11 p-8 rounded-3xl shadow-lg w-11/12"><div><a class="block" href="/posts/2023/01/sqlalchemy-dealing-with-disconnects"><p>2023<!-- -->年<!-- -->1<!-- -->月<!-- -->12<!-- -->日</p><h2 class="mt-5 font-bold leading-tight mb-5 text-4xl">SQLAlchemyで&#x27;MySQL server has gone away&#x27;が発生した時の対処法2つ</h2><p class="line-clamp-3 my-5 text-neutral-600 dark:text-neutral-300"> FastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。

## 環境

* mysql 5.7.15
* SQLAlchemy 1.4.45
* mysqlclient 2</p></a><ul class="flex flex-wrap mt-5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/sqlalchemy"># <!-- -->SQLAlchemy</a></ul></div></div><div class="bg-white dark:bg-neutral-800 mx-auto mb-11 p-8 rounded-3xl shadow-lg w-11/12"><div><a class="block" href="/posts/2022/12/openid-connect-fastapi"><p>2022<!-- -->年<!-- -->12<!-- -->月<!-- -->2<!-- -->日</p><h2 class="mt-5 font-bold leading-tight mb-5 text-4xl">よくあるSPA+API構成でのOpenID Connectクライアント実装</h2><p class="line-clamp-3 my-5 text-neutral-600 dark:text-neutral-300"> この記事はニフクラ等を提供している、富士通クラウドテクノロジーズ Advent Calendar 2022の2日目の記事です。

昨日は [@nt</p></a><ul class="flex flex-wrap mt-5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/openid-connect"># <!-- -->OpenID Connect</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/認証-認可"># <!-- -->認証/認可</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/spa"># <!-- -->SPA</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/fastapi"># <!-- -->FastAPI</a></ul></div></div><div class="flex justify-center"><div class="bg-neutral-300 dark:bg-neutral-600 w-14 font-display h-14 mr-5 last:mr-0 px-4 py-2 rounded-full text-4xl text-center transition-all">1</div></div></div></main><aside class="col-span-10 md:col-span-3"><div class="mx-auto w-11/12 mb-8"><h2 class="font-black font-display text-duchs-900 dark:text-duchs-100 text-xl">AUTHOR</h2><div class="flex items-center my-3.5"><div class="mr-2.5"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2780%27%20height=%2780%27/%3e"/></span><img alt="アイコン" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="アイコン" src="/images/icon.png" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="rounded-full" loading="lazy"/></noscript></span></div><div><p class="font-black font-display mb-2 text-duchs-900 dark:text-duchs-100 text-lg">Sogo Kato</p><div class="flex"><a class="mr-2 hover:opacity-75 transition-all" target="_blank" href="https://github.com/SogoKato"><div class="dark:hidden"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2720%27%20height=%2720%27/%3e"/></span><img alt="GitHubアイコン" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="GitHubアイコン" src="/images/github-light.svg" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div><div class="hidden dark:block"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2720%27%20height=%2720%27/%3e"/></span><img alt="GitHubアイコン" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="GitHubアイコン" src="/images/github-dark.svg" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div></a></div></div></div><p class="mb-2.5 text-xs">クラウド業界に生息する駆け出しへっぽこエンジニア。ラズパイとダックスがすき。資格たくさんほしいので余ってる人はお裾分けください。</p><a href="/profile"><button class="bg-duchs-200 hover:bg-duchs-800 font-black font-display px-3.5 py-0.5 rounded-full text-duchs-900 hover:text-duchs-100 transition-all">MORE</button></a></div><div class="mx-auto w-11/12 mb-8"><h2 class="font-black font-display text-duchs-900 dark:text-duchs-100 text-xl">RECOMMENDED</h2><ul class="mt-3.5"><a class="block mb-3 hover:opacity-75 transition-all" href="/posts/2023/04/datatable-react"><p class="mb-1 text-xs">Reactで検索・ソート可能なDataTableを自作する</p><p class="text-neutral-500 text-xs">2023<!-- -->年<!-- -->4<!-- -->月<!-- -->22<!-- -->日</p></a><a class="block mb-3 hover:opacity-75 transition-all" href="/posts/2023/04/kaniko-cache"><p class="mb-1 text-xs">Kanikoでコンテナイメージつくるならcache=trueは有効にしておこう</p><p class="text-neutral-500 text-xs">2023<!-- -->年<!-- -->4<!-- -->月<!-- -->18<!-- -->日</p></a><a class="block mb-3 hover:opacity-75 transition-all" href="/posts/2023/04/reverse-proxy-to-home-ipoe-network"><p class="mb-1 text-xs">IPoE回線の自宅のWebサービスをVPN経由で固定IPのクラウドから公開する</p><p class="text-neutral-500 text-xs">2023<!-- -->年<!-- -->4<!-- -->月<!-- -->15<!-- -->日</p></a><a class="block mb-3 hover:opacity-75 transition-all" href="/posts/2023/03/certified-kubernetes-application-developer"><p class="mb-1 text-xs">CKAD受検記録【2023年版】</p><p class="text-neutral-500 text-xs">2023<!-- -->年<!-- -->3<!-- -->月<!-- -->30<!-- -->日</p></a><a class="block mb-3 hover:opacity-75 transition-all" href="/posts/2023/03/pyscript-codeblock"><p class="mb-1 text-xs">PyScriptを使ってブログのサンプルコードを実行させる</p><p class="text-neutral-500 text-xs">2023<!-- -->年<!-- -->3<!-- -->月<!-- -->6<!-- -->日</p></a></ul></div><div class="mx-auto w-11/12 mb-8"><h2 class="font-black font-display text-duchs-900 dark:text-duchs-100 text-xl">TAGS</h2><ul class="flex flex-wrap mt-3.5"><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/python"># <!-- -->Python</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/単体テスト"># <!-- -->単体テスト</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/kubernetes"># <!-- -->Kubernetes</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/読書"># <!-- -->読書</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/react"># <!-- -->React</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/ci-cd"># <!-- -->CI/CD</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/gitlab"># <!-- -->GitLab</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/javascript"># <!-- -->JavaScript</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/next.js"># <!-- -->Next.js</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/terraform"># <!-- -->Terraform</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/fastapi"># <!-- -->FastAPI</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/sqlalchemy"># <!-- -->SQLAlchemy</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/joy-ui"># <!-- -->Joy-UI</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/kaniko"># <!-- -->Kaniko</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/コンテナ"># <!-- -->コンテナ</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/自宅サーバー"># <!-- -->自宅サーバー</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/ネットワーク"># <!-- -->ネットワーク</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/vpn"># <!-- -->VPN</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/wireguard"># <!-- -->WireGuard</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/haproxy"># <!-- -->HAProxy</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/資格"># <!-- -->資格</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/webassembly"># <!-- -->WebAssembly</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/pyscript"># <!-- -->PyScript</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/ansible"># <!-- -->Ansible</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/apt"># <!-- -->APT</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/aws"># <!-- -->AWS</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/api-gateway"># <!-- -->API Gateway</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/orm"># <!-- -->ORM</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/キーボード"># <!-- -->キーボード</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/vs-code"># <!-- -->VS Code</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/開発環境"># <!-- -->開発環境</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/openid-connect"># <!-- -->OpenID Connect</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/認証-認可"># <!-- -->認証/認可</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/spa"># <!-- -->SPA</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/tailwind-css"># <!-- -->Tailwind CSS</a><a class="bg-duchs-100 hover:bg-duchs-500 font-bold mb-2 mr-3 px-5 py-1 rounded-full dark:text-neutral-900 hover:text-neutral-50 hover:dark:text-neutral-50 text-xs transition-all" href="/tags/personal"># <!-- -->Personal</a></ul></div><div class="mx-auto w-11/12 "><h2 class="font-black font-display text-duchs-900 dark:text-duchs-100 text-xl">LINKS</h2><a class="block mb-1 mt-3.5 hover:opacity-75 transition-all" href="/feed.xml"><p>RSS</p></a><a class="block mb-1 hover:opacity-75 transition-all" target="_blank" href="https://github.com/SogoKato/sogokato.github.io"><p class="flex items-center">GitHub <svg class="fill-neutral-900 dark:fill-neutral-100 h-3 ml-2" viewBox="0 0 7.82 7.82"><g><path d="M4.41,2.01c-.15,.02-.3,.04-.46,.06s-.31,.02-.46,.01l-1.1-.02c-.14,0-.27-.02-.38-.06s-.21-.1-.3-.19c-.1-.1-.17-.22-.22-.36s-.07-.29-.07-.44c0-.15,.02-.29,.07-.43s.12-.26,.22-.35c.09-.09,.18-.15,.29-.18S2.24,0,2.39,0H6.8c.15,0,.29,.03,.41,.08s.23,.12,.31,.21c.09,.09,.17,.2,.22,.32s.08,.26,.08,.41V5.46c0,.13-.02,.26-.05,.37s-.09,.22-.19,.31-.21,.17-.35,.22-.27,.07-.4,.07-.27-.03-.4-.07-.24-.12-.33-.21-.15-.19-.19-.31-.05-.24-.05-.38l-.02-1.24c0-.16,0-.31,.02-.46s.03-.3,.06-.46L1.7,7.53c-.11,.11-.22,.18-.34,.23s-.24,.07-.36,.06-.24-.04-.35-.09-.22-.13-.32-.23-.17-.2-.23-.31S0,6.95,0,6.83s.01-.24,.06-.36,.12-.23,.23-.34L4.41,2.01Z"></path></g></svg></p></a></div></aside><footer class="col-span-10"><div class="flex flex-col items-center py-10"><a class="mb-2 text-xs" href="/privacy">プライバシーポリシー</a><small>Copyright © <!-- -->2023<!-- --> Sogo Kato All rights reserved.</small></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Reactで検索・ソート可能なDataTableを自作する","date":"2023-04-22T00:00:00.000Z","ref":"/posts/2023/04/datatable-react","desc":" 最近、MUI の妹分の UI ライブラリである Joy-UI を使ってます。現在進行形で活発に開発が進んでいて、設計（デザイン）も今時な感じで好感触です。ところどころまだ開発されていないコンポー","draft":false,"content":"\n最近、MUI の妹分の UI ライブラリである [Joy-UI](https://mui.com/joy-ui/getting-started/overview/) を使ってます。現在進行形で活発に開発が進んでいて、設計（デザイン）も今時な感じで好感触です。ところどころまだ開発されていないコンポーネントもちらほらあるものの、ドキュメントには代替策がコード付きで載っていてとても親切です。\n\n[MUI X](https://mui.com/x/introduction/) というより発展的なコンポーネントをもつ UI ライブラリもあるのですが、そこに今回のテーマである「データテーブル」に該当する [Data Grid](https://mui.com/x/react-data-grid/) というものがあります。これは超すごくて、雑に言うと Excel がそのまま再現できちゃいそうなコンポーネントです（超雑）。\n\nただ残念ながら2023年4月現在では Data Grid の Joy-UI との統合は正式にサポートされていないらしいので、今回は簡易的なデータテーブルを自作していきたいと思います。\n\n## 要件\n\n* `rows` には表示するデータである `object[]` を渡す\n* `columns` に指定したフィールド名の値が表示される\n* データの検索ができる\n* 特定のカラムの昇順・降順での並び替えができる\n\n## できたもの\n\n上の表が素の HTML 要素だけで作ったもの、下の表が Joy-UI を使ったものです。検索やソートのロジックは一緒です。Joy-UI の方はヘッダーの hover 時に矢印が表示されるのでちょっとわかりやすいです。\n\n\u003ciframe\n  src=\"https://codesandbox.io/embed/datatable-react-joyui-j409vf?fontsize=14\u0026hidenavigation=1\u0026theme=dark\u0026view=preview\"\n  style=\"width:100%; height:750px; border:0; border-radius: 4px; overflow:hidden;\"\n  title=\"datatable-react-joyui\"\n  allow=\"accelerometer; ambient-light-sensor; camera; encrypted-media; geolocation; gyroscope; hid; microphone; midi; payment; usb; vr; xr-spatial-tracking\"\n  sandbox=\"allow-forms allow-modals allow-popups allow-presentation allow-same-origin allow-scripts\"\n\u003e\u003c/iframe\u003e\n\n## ポイント\n\n検索（絞り込み）はただ filter かけているだけなので書くことないです。  \n並び替えの条件のところが少し複雑なのでちょっと解説します。\n\n状態として `sortBy` と `order` を持っています。`sortBy` は並び替える対象のカラム名、`order` は昇順か降順かです。どちらも undefined になりえます（オリジナルの順番を保持する時）。\n\n```ts\ntype Order = \"asc\" | \"desc\";\nconst [sortBy, setSortBy] = useState\u003cstring | undefined\u003e();\nconst [order, setOrder] = useState\u003cOrder | undefined\u003e();\n```\n\nヘッダー部分はこのようになります。ヘッダーのカラム名をクリックすると、未指定（undefined）→降順（desc）→昇順（asc）→未指定の順で切り替わります。\n\n各カラムについて CSS の `transform` と `opacity` を計算します。下向き矢印のアイコンを使用しているので、`order === \"asc\"` の時のみ180度回転します。`order` の状態は全カラム共通になっています。`opacity` は `sortBy === col.field` つまり該当のカラムによってソートされている時のみ表示されるようになっています。\n\nonClick 時には `sort` 関数が呼ばれます。  \n該当カラムによってソートされている時は順繰りに desc → asc → undefined を切り替えます。次が undefined の時は `sortBy` も undefined にします。  \n他のカラムによってソートされている時は現在の order を維持しつつ `sortBy` だけ該当カラムに移します。どのカラムでもソートされていない時（オリジナルの順番の時）は `sortBy` を移しつつ、`order` を undefined → desc にします。\n\n```tsx\nconst header = columns.map((col) =\u003e {\n  const transform = order === \"asc\" ? \"rotate(180deg)\" : undefined;\n  const opacity = sortBy === col.field ? 1 : 0;\n  const sort = () =\u003e {\n    if (sortBy === col.field) {\n      const orderNext =\n        order === \"desc\" ? \"asc\" : order === \"asc\" ? undefined : \"desc\";\n      setSortBy(orderNext ? col.field : undefined);\n      setOrder(orderNext);\n    } else {\n      setSortBy(col.field);\n      setOrder(order ? order : \"desc\");\n    }\n  };\n  return (\n    \u003cth key={`header-${col.field}`} style={{ width: col.width }}\u003e\n      \u003cbutton\n        style={{\n          fontWeight: \"bold\"\n        }}\n        onClick={sort}\n      \u003e\n        \u003cspan\u003e{col.headerName}\u003c/span\u003e\n        \u003cArrowDownIcon\n          style={{\n            transition: \"0.2s\",\n            transform: transform,\n            opacity: opacity\n          }}\n        /\u003e\n      \u003c/button\u003e\n    \u003c/th\u003e\n  );\n});\n```\n\n実際に配列をソートしている処理はこちらです。  \n[Array.prototype.sort()](https://developer.mozilla.org/ja/docs/Web/JavaScript/Reference/Global_Objects/Array/sort) は破壊的に配列を変更するので、注意です。下記では前の処理で filter をかけているので元の配列が変更されていませんが、そうしない場合は `[...rows].sort()` とするなど、コピーするようにしましょう。\n\nIE11 をサポートすることはもはやないと思いますが、古いブラウザでは sort の安定性が保証されていません。サポートする場合は MUI の [Order Dashboard](https://codesandbox.io/s/7rtmil?file=/components/OrderTable.tsx) のデモにある `stableSort` を見てみてください。\n\n```ts\nconst sortedRows = filteredRows.sort((a, b) =\u003e {\n  if (!sortBy || !order) {\n    return 0;\n  }\n  const aVal = sortBy in a ? a[sortBy] : \"\";\n  const bVal = sortBy in b ? b[sortBy] : \"\";\n  if (order === \"asc\") {\n    return aVal \u003e bVal ? 1 : -1;\n  } else {\n    return aVal \u003c bVal ? 1 : -1;\n  }\n});\n```\n\n## インターフェイス\n\n`DataTable` (素の HTML)\n\n```ts\ntype DataTableProps = {\n  columns: Column[];\n  rows: object[];\n  getRowId?: (row: object) =\u003e any;\n  search?: any;\n  style?: StyleHTMLAttributes\u003cHTMLTableElement\u003e;  // tableのstyle属性\n};\n```\n\n`JoyDataTable` (Joy-UI の Table を使用)\n\n```ts\ntype JoyDataTableProps = {\n  columns: Column[];\n  rows: object[];\n  getRowId?: (row: object) =\u003e any;\n  search?: any;\n  sx?: SxProps;  // @mui/joy/TableのSx属性\n};\n```\n\n* `column` はカラムの定義です\n  ```ts\n  export type Column = {\n    field: string;  // rowsの各objectのフィールド名\n    headerName: string;  // ヘッダーに表示するカラム名\n    width?: number;  // カラムの幅\n  };\n  ```\n* `rows` には任意のオブジェクトの配列を渡します\n* `getRowId` は rows の各 object の一意の識別子を取得する関数です。デフォルトでは id フィールドを取得します\n  * DataGrid にも同じ役割のものがあります[^1]\n* `search` には検索する文字列や数値を渡します\n\n[^1]: [Row identifier](https://mui.com/x/react-data-grid/row-definition/#row-identifier)\n\n## おわりに\n\n成熟した UI ライブラリならこういった DataTable を備えていることが多いと思いますが、開発途上のものだとあるとは限らないので、React に限らず DataTable を実装してみたい方の参考になれば幸いです！\n\n## 参考文献\n\n* [Table](https://mui.com/joy-ui/react-table/)\n* [Order Dashboard](https://codesandbox.io/s/7rtmil?file=/components/OrderTable.tsx)\n* [Data Grid](https://mui.com/x/react-data-grid/)\n","tags":[{"name":"React","ref":"/tags/react"},{"name":"Joy-UI","ref":"/tags/joy-ui"}],"showTerminalAside":false},{"title":"Kanikoでコンテナイメージつくるならcache=trueは有効にしておこう","date":"2023-04-18T00:00:00.000Z","ref":"/posts/2023/04/kaniko-cache","desc":" !ぜんぜんわからない　俺たちは雰囲気でカニコをやっている\n\n恥ずかしながら、わたしは雰囲気で kaniko にコンテナイメージのビルドをしてもらっていることに気づきました。1年以上 GitLab CI で kaniko を使っ","draft":false,"content":"\n![ぜんぜんわからない　俺たちは雰囲気でカニコをやっている](/images/posts/2023/04/kaniko.png)\n\n恥ずかしながら、わたしは雰囲気で kaniko にコンテナイメージのビルドをしてもらっていることに気づきました。1年以上 GitLab CI で kaniko を使っておきながら、ただ「特権コンテナを使わずにイメージつくれるやつ」くらいの認識しかしていなかったです。\n\n## kaniko の cache=true オプション\n\nkaniko には `--cache` というフラグがあり、これを true にすることでコンテナのビルド時にキャッシュ保存するようになり、次回以降のビルドではそのキャッシュを使用するようになるため、コンテナイメージのビルド時間を短縮できます。\n\nキャッシュは、コンテナレジストリ上に `destinationのイメージリポジトリ名/cache` というイメージリポジトリ名で格納されます。例えば `gcr.io/kaniko-project/test` というイメージのビルドキャッシュは `gcr.io/kaniko-project/test/cache` に格納されます。そのため、ビルドに使う CI プラットフォームが、Google Cloud Build であっても GitLab CI であっても特殊な設定なしに使えるので便利です。\n\n毎回 docker の実行環境がリセットされる CI 環境では、ローカルと異なり cache が残らないのでコンテナイメージのビルドに多くの時間がかかります。`--cache-from イメージリポジトリ名` を指定することでキャッシュを利用することもできますが、 multi-stage build の場合には最終的なイメージにキャッシュとして使う情報が残っていないので、中間のイメージを push してそれぞれ `--cache-from` に指定しなくてはいけません（やったことないけど大変そう）。\n\nそれに対して kaniko では、（イメージ単位ではなく）**レイヤー単位でキャッシュが保存（push）されるので、multi-stage build であってもなくても関係なく cache の恩恵を受けられます**（すてき）。\n\n## ほかのオプション\n\n### cache-dir\n\nkaniko が走る pod に永続ボリュームがマウントされている場合、ベースイメージをキャッシュさせることができます。`gcr.io/kaniko-project/warmer` と組み合わせて使うようです。\n\nhttps://github.com/GoogleContainerTools/kaniko#caching-base-images\n\n### cache-repo\n\n上でキャッシュが `destinationのイメージリポジトリ名/cache` に保存されると説明しましたが、任意のリポジトリに保存させることもできます。\n\nこれを指定しない場合は `--destination` から推測されます（上述の通り `gcr.io/kaniko-project/test` の場合は `gcr.io/kaniko-project/test/cache`）。\n\n### cache-copy-layers と cache-run-layers\n\n`--cache-copy-layers` と `--cache-run-layers` という論理値型のフラグもあります。これらはそれぞれ以下の意味です。\n\n* `--cache-copy-layers`: Dockerfile の COPY レイヤーをキャッシュするか（既定値: false）\n* `--cache-run-layers`: Dockerfile の RUN レイヤーをキャッシュするか（既定値: true）\n\n`--cache-copy-layers` がデフォルト無効になったのは以下リンク先の issue の経緯があるようです。  \nhttps://github.com/GoogleContainerTools/kaniko/pull/1408\n\n### cache-ttl\n\nキャッシュが何時間有効であるかを指定できます。単位は時間（hours）です。指定しない場合の既定値は2週間です。\n\n## つかってみよう\n\nkaniko のキャッシュの仕組みが分かってきたところで、さっそく試してみましょう。\n\n今回は GitLab CI と GitLab Container Registry を使います。ビルドするイメージは node.js のアプリで、3段階の multi-stage build が行われています（ご参考: [next.js/Dockerfile at canary · vercel/next.js](https://github.com/vercel/next.js/blob/canary/examples/with-docker/Dockerfile)）。\n\n`.gitlab-ci.yml`\n\n```yaml\nbuild-image:\n  stage: build\n  image:\n    name: gcr.io/kaniko-project/executor:debug\n    entrypoint: [\"\"]\n  script:\n    - mkdir -p /kaniko/.docker\n    - echo \"{\\\"auths\\\":{\\\"${CI_REGISTRY}\\\":{\\\"auth\\\":\\\"$(printf \"%s:%s\" \"${CI_REGISTRY_USER}\" \"${CI_REGISTRY_PASSWORD}\" | base64 | tr -d '\\n')\\\"}}}\" \u003e /kaniko/.docker/config.json\n    - \u003e-\n      /kaniko/executor\n      --cache=true\n      --context \"${CI_PROJECT_DIR}\"\n      --destination \"${CI_REGISTRY_IMAGE}:${CI_COMMIT_SHORT_SHA}\"\n      --destination \"${CI_REGISTRY_IMAGE}:latest\"\n```\n\n### 1回目\n\n`--cache-true` を指定した直後のビルドです。当然、過去にキャッシュがつくられていないのですべてのレイヤーで処理が実行されます（ログに `No cached layer found for cmd RUN ...` と見える）。\n\n結果は14分14秒でした。\n\nコンテナレジストリを覗くと成果物のコンテナイメージのほかに `destinationのイメージリポジトリ/cache` のイメージリポジトリがあり、それぞれのタグにレイヤーのキャッシュが push されていました。\n\n### 2回目\n\nアプリのコードを一部修正して、2回目の実行です。アプリの build と関係ない部分（依存ライブラリのインストールなど）はキャッシュが使われるはず。\n\nログを見ると `Using caching version of cmd: RUN ...` というのが確認できました。\n\n結果は9分50秒でした。そのあとも何回か試したけど毎回同じくらいの時間でした。4分半程度、ビルドが速くなりました。\n\n## キャッシュの保持期間\n\nとても簡単に使える kaniko のキャッシュですが、デメリットがあるとすればコンテナレジストリの容量を食ってしまうことでしょうか。\n\nコンテナレジストリのベンダーによるところではあると思いますが、筆者が使っている GitLab Container Registry の場合は [cleanup policy](https://docs.gitlab.com/ee/user/packages/container_registry/reduce_container_registry_storage.html#create-a-cleanup-policy) という機能があるので、タグが「任意の64文字に一致する正規表現」に一致する場合は消すというポリシーを設定すれば対応できます。\n\n|項目|値|備考|\n|---|---|---|\n|`Remove tags older than`|なし/7日/14日/30日/60日/90日||\n|`Remove tags matching`|設定例）`.{64}`|`^` や `$` は書かなくて大丈夫[^1]|\n\n[^1]: GitLab 社のドキュメントに記載があります  \nhttps://docs.gitlab.com/ee/user/packages/container_registry/reduce_container_registry_storage.html#regex-pattern-examples\n\n## おわりに\n\nなんでこんな便利なオプションを今まで知らなかったのと悔やまれます。たくさん活用していきたいと思います。\n\n## 参考文献\n\n* [kaniko](https://github.com/GoogleContainerTools/kaniko)\n* [Kaniko キャッシュの使用](https://cloud.google.com/build/docs/optimize-builds/kaniko-cache?hl=ja)\n* [kaniko が何をしているか, 何ができるか](https://orisano.hatenablog.com/entry/2019/05/20/120032)\n* [CIにおけるMulti-stage Buildsのcache](https://orisano.hatenablog.com/entry/2018/12/25/224011)\n","tags":[{"name":"Kaniko","ref":"/tags/kaniko"},{"name":"CI/CD","ref":"/tags/ci-cd"},{"name":"コンテナ","ref":"/tags/コンテナ"},{"name":"GitLab","ref":"/tags/gitlab"}],"showTerminalAside":false},{"title":"IPoE回線の自宅のWebサービスをVPN経由で固定IPのクラウドから公開する","date":"2023-04-15T00:00:00.000Z","ref":"/posts/2023/04/reverse-proxy-to-home-ipoe-network","desc":" PPPoE 回線が遅いので IPoE（IPv4 over IPv6）へ移行しようと思いました。以前は2つのルーターを使って、PPPoE と IPoE の2セッションを張ることができたのですが、ある時からできなくなり、しばらく PPPoE だけで生活していました。とはいえやはり遅い、遅すぎる……とい","draft":false,"content":"\nPPPoE 回線が遅いので IPoE（IPv4 over IPv6）へ移行しようと思いました。以前は2つのルーターを使って、PPPoE と IPoE の2セッションを張ることができたのですが、ある時からできなくなり、しばらく PPPoE だけで生活していました。とはいえやはり遅い、遅すぎる……ということで、今回の記事に至ります。\n\nIPoE に移行するにあたっての課題は**任意のポートを開放できないこと**です。\n\n代わりの方法を考えていたところ、ちょうど手元に1台 AWS Lightsail のサーバーがあったので、今回はこのサーバーに L4 Load Balancer 的なものをたて、自宅サーバーと VPN で接続することで実現しようと思いました。\n\n## つくった構成\n\nHome Server となっている部分は実際には単一のサーバーではなく Kubernetes クラスタ（MetalLB, Ingress NGINX Controller, cert-manager 使用）となっていてもう少し複雑ですが、基本的な構成は以下の通りです。\n\n![network](//www.plantuml.com/plantuml/png/VP91IyCm68Rl_HKlEPUOT9tKZi661-TDzE11TeZDnrRScf6cLf7zTvlYOhLGwA5VyhoyUKXMjLFMDST3LBMwL3jyHK15hZNs3VUL8ziD_IAmCKTwD8qZYnUbjQMwnX9CtcHyBhaKWYTik-ZHsuDfz1FPztyikRs8CKX81arrOSkJAqtbaK4qncRzOCt79_9C84_JMOpdqj9Tewn6FfTP8YwDwyAPhglUgnDX2UN7VkiS3Ooyme_D7uE4o-kC2owkafGjeadT04ks3U24Qy37hh_9JenUuV_BWe8k6naC_CSQNSVCVy5YuYRQdOWH4j8t3LqcwUHohdEqeahxr_CD)\n\n* クラウドサーバー\n  * 固定グローバル IP があり、その IP が DNS に登録されている\n  * WireGuard が 51820 番ポートで接続を受け付ける（サーバー役）\n  * HAProxy が80・443番ポートで接続を受け付ける\n    * リクエストが来たら仮想ネットワーク側に転送する\n* 自宅\n  * IPoE（IPv4 over IPv6）回線\n  * 自宅サーバー\n    * クラウドサーバーの WireGuard につなぎに行く（クライアント役）\n      * OUT 方向なのでポート開放は不要\n    * 80・443番ポートで Web サービスが稼働していることを想定\n      * クラウドサーバーから仮想ネットワーク経由でつなぎに来る\n\n## レシピ\n\n### クラウドサーバー\n\nクラウドサーバー上の各コンポーネントは docker compose で起動します。\n\n`haproxy.cfg`\n\n```\nfrontend http_rproxy\n    mode tcp\n    default_backend http_servers\n    bind *:80\n\nfrontend https_rproxy\n    mode tcp\n    default_backend https_servers\n    bind *:443\n\nbackend http_servers\n    server home-server 10.13.13.2:80\n\nbackend https_servers\n    server home-server 10.13.13.2:443\n```\n\n`compose.yaml`\n\n```yaml\nservices:\n  wireguard:\n    image: linuxserver/wireguard\n    cap_add:\n      - NET_ADMIN\n      - SYS_MODULE\n    environment:\n      - PUID=1000\n      - PGID=1000\n      - TZ=Asia/Tokyo\n      - SERVERURL=クラウドサーバーのIP\n      - SERVERPORT=51820\n      - PEERS=home-server\n      - INTERNAL_SUBNET=10.13.13.0\n      - ALLOWEDIPS=10.13.13.0/24\n    volumes:\n      - type: bind\n        source: ./config\n        target: /config\n      - type: bind\n        source: /lib/modules\n        target: /lib/modules\n    network_mode: \"host\"\n    restart: unless-stopped\n  haproxy:\n    image: haproxy:lts\n    volumes:\n      - type: bind\n        source: haproxy.cfg\n        target: /usr/local/etc/haproxy/haproxy.cfg\n    ports:\n      - 80:80/tcp\n      - 443:443/tcp\n    sysctls:\n      - net.ipv4.ip_unprivileged_port_start=0\n    restart: unless-stopped\n```\n\n`docker compose up -d` します。\n\n`ip a` や `ip r` で `wg0` のネットワークインターフェイスがあることや静的ルートが登録されていることを確認します。\n\n起動すると config ディレクトリが作成され、その中に各 peer で使うためのコンフィグがあります。上記の設定例の場合は `config/peer_home-server/peer_home-server.conf` がそのファイルです。これを何らかの方法で自宅サーバーに転送してください。\n\n`config/wg0.conf` は VPN サーバーのためのコンフィグです。この中の `[Peer]` セクションの AllowedIPs に任意の CIDR を書くことで、その CIDR への静的ルートを設定して wg0 で引き受けることができるようになります（要コンテナ再起動）。\n\nまた、今回は WireGuard のコンテナをホストのネットワークを使って構成しています。コンテナ環境に閉じた方が安全なのはそうなのですが、ちょっと手を抜きました。。\n\n### 自宅サーバー側\n\nホストに WireGuard をインストールします。[^1]\n\n[^1]: コンテナで起動させたい方は参考文献のリンク先に Client Mode の説明がありますのでそちらを見てください。\n\n```shell\nsudo apt update\nsudo apt install wireguard resolvconf\n```\n\n転送してきた `peer_home-server.conf` を編集します。\n\n`[Peer]` のセクションの後ろに `PersistentKeepAlive = 25` と1行追記します。この設定があることで、25秒おきにクライアントからサーバーに接続を確立し続けます（WireGuard は起動しただけでは接続を確立しません）。\n\nこの設定によって、常に VPN クライアント（自宅サーバー）から VPN サーバー（クラウドサーバー）に接続するようになるので、クラウドサーバーにいつエンドユーザーからのリクエストが飛んできても、そのリクエストを HAProxy が自宅サーバーに回すことができるようになります。\n\n逆にこの設定がないと、サーバー側からクライアント側に接続しに行くことはできないので、エンドユーザーからのリクエストを転送できないことになります。\n\n```\n[Peer]\nPublicKey = XI6TJ...\nEndpoint = クラウドサーバーのIP:51820\nAllowedIPs = 10.13.13.0/24\nPersistentKeepAlive = 25\n```\n\n配置して、systemd が自動起動するように設定します。\n\n```shell\nsudo cp path/to/peer_home-server.conf /etc/wireguard/wg0.conf\nsudo systemctl enable wg-quick@wg0.service --now\n```\n\n`ip a` で `wg0` のネットワークインターフェイスがあることを確認できれば OK です。\n\n### 動作確認\n\nDNS にクラウドの IP アドレスを設定して、リクエストが成功すれば OK です！\n\n### おわりに\n\nいったん最小の構成でうまくいくことがわかりました。レスポンス時間も個人で適当に使っているやつなのでほとんど気になりません。\n\nVPN でクラウドと自宅との間が暗号化されているので、HAProxy で SSL 終端する、みたいな構成も可能かも。WireGuard の自宅サーバー側の peer や HAProxy の転送先を冗長化する、みたいな構成をとるのも面白いかも。\n\nではでは。\n\n## 参考文献\n\n* [haproxy](https://hub.docker.com/_/haproxy/)\n* [linuxserver/wireguard](https://hub.docker.com/r/linuxserver/wireguard)\n","tags":[{"name":"自宅サーバー","ref":"/tags/自宅サーバー"},{"name":"ネットワーク","ref":"/tags/ネットワーク"},{"name":"VPN","ref":"/tags/vpn"},{"name":"WireGuard","ref":"/tags/wireguard"},{"name":"HAProxy","ref":"/tags/haproxy"}],"showTerminalAside":false},{"title":"CKAD受検記録【2023年版】","date":"2023-03-30T00:00:00.000Z","ref":"/posts/2023/03/certified-kubernetes-application-developer","desc":" 2023年3月30日に Certified Kubernetes Application Developer (CKAD) を受験し、合格しましたのでその受検記録記事です。ちょうど1年前に Certified Kuberenetes Administrator (CKA) を取っていたので、その続","draft":false,"content":"\n2023年3月30日に Certified Kubernetes Application Developer (CKAD) を受験し、合格しましたのでその受検記録記事です。ちょうど1年前に Certified Kuberenetes Administrator (CKA) を取っていたので、その続きとなります。\n\n前回の記事：[新卒エンジニアがCKA取得を目指してKubernetesを勉強したときの記録](https://qiita.com/SogoK/items/4ed2e118d0412c868169)\n\n## 対象読者\n\n* Kubernetes を使っているが、資格はまだ取ってない人\n* CKA を取ったので CKAD も取りたい人\n\n## 試験対策\n\n* 去年の夏に CKAD-JP が半額になっていたタイミングで購入\n  * サイバーマンデーでも半額セールをやっていたりします\n* 期間は2～3週間くらい（たぶん10時間くらい）\n* Udemy の [Kubernetes Certified Application Developer (CKAD) with Tests](https://www.udemy.com/course/certified-kubernetes-application-developer/) コースに付属するラボを使用\n  * 頻繁にセールをやっているらしいので安くなっているタイミングを狙いましょう（この記事の執筆中も92% OFFセールをやっている）\n  * CKAD の受験料が15% OFFになるクーポンもついてきます\n  * 各分野の練習問題のほか、Lightning Lab x 2と Mock Exam x 2が含まれています（制限時間1時間）\n  * Lightning Lab は少し難しめの問題5～6題\n    * 対策開始直後に解いたときは kubectl の勝手を忘れていて1時間フルに使って間に合わなかった\n    * 一通り慣れてきたら、2つ目は40分くらいで解けた\n  * Mock Exam は実際の試験に近い難易度の問題10題程度\n    * 慣れてきてから解いてみて40～50分程度、どちらも1問ミス\n\n## 受検\n\n* 2022年3月に受けた時から試験の環境が変わっていた（条件は同じ）\n  * 前回はブラウザ上の操作だったが、現在は **Linux デスクトップにリモートデスクトップ接続**\n  * Firefox で追加のタブを一つだけ開くことができ、そこで **Kubernetes ドキュメントを参照可**\n  * ターミナルはデスクトップのアイコンから自分で立ち上げる\n  * レスポンスは良好、スクロールが少し重いくらい\n  * 参考：[Linux Foundation Proctoring Platform –PSIブリッジへの移行](https://training.linuxfoundation.org/ja/bridge-migration-2021/)\n* PSI Secure Browser のインストールボタンがうまく機能せず、ダウンロードが始まらなくて焦った\n  * いくつか前の画面から開きなおしてみたら直りました\n  * 試験時間に影響はないですが、こういったトラブルがあるので時間には余裕を持ったほうがいいです\n* CKAD-JP のはずだけど普通にチャットは全部英語だった\n* パスポートの有効期限が生きてたのでパスポートを見せた\n  * 去年の夏ごろ免許証か何かが受理されなかったという報告を見たので持っている人はパスポートのほうが良いでしょう\n* ダウンロードできないトラブルとお部屋のチェック合わせて30分程度かかった\n* **問題数は19問**\n  * 重み4%の問題が13個、8%の問題が6個（たぶん\n  * 感触としては8%の問題は Lightning Lab の問題に近いかも\n  * いくつかの問題では、値をそのまま入れることができるフィールドがなかったりするので、頭を柔らかくして解きましょう\n* **試験時間は2時間**\n  * 時間は目いっぱい使った\n  * 前回の CKA では70分で解き終わっていたが、今回は時間いっぱい使った\n\n## 結果\n\n100点中、91点で **合格** しました 💮（合格ラインは66点）\n\n受検終了後21時間くらいでメールが届きました。\n\n## おわりに\n\nこの記事が CKAD の受検を考えている人にとって、レベル感や試験の勝手についての参考になれば幸いです。\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"},{"name":"資格","ref":"/tags/資格"}],"showTerminalAside":false},{"title":"PyScriptを使ってブログのサンプルコードを実行させる","date":"2023-03-06T00:00:00.000Z","ref":"/posts/2023/03/pyscript-codeblock","desc":" 前回の記事を書くときに WebAssembly でブログのコードブロックのコードを実行させられたら面白いかも、ということで PyScript を使って実装してみました。React \u0026 Next.js で使う際の注意点について","draft":false,"content":"\n[前回の記事](/posts/2023/03/pyscript-codeblock)を書くときに WebAssembly でブログのコードブロックのコードを実行させられたら面白いかも、ということで PyScript を使って実装してみました。React \u0026 Next.js で使う際の注意点についても書こうと思います。\n\n以下については前提知識としてこの記事では解説しません。\n\n* [PyScript](https://pyscript.net/)\n* [Pyodide](https://pyodide.org/en/stable/)\n* [WebAssembly](https://webassembly.org/)\n* [react-markdown](https://github.com/remarkjs/react-markdown) のコードブロック（バッククォート3つ \\```）をカスタマイズする方法\n\n## やったこと\n\n* react-markdown のコードブロックでのオレオレ文法で PyScript を導入\n* PyScript のカスタム要素（以下）に対応する React コンポーネントを作成\n  * `\u003cpy-script\u003e`, `\u003cpy-repl\u003e`, `\u003cpy-terminal\u003e`, `\u003cpy-config\u003e`\n* React のハイドレーションのエラーを回避するために Next.js の [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) を使用\n* PyScript の初期化の仕様に合わせた最適化\n\n## まずは遊んでみよう\n\nこちらが成果物になります。コードブロック開始の \\`\\`\\` の横に書いた文字列が、コードブロックをカスタマイズする関数の引数に渡されるので、ここでオレオレ文法を制定します。\n\n### py-terminal タグ\n\nターミナルの出力を表示するためのタグです。後述の `\u003cpy-script\u003e` や `\u003cpy-repl\u003e` での標準出力や標準エラーはここに出てきます。ページに複数配置することができますが、表示される内容は同じになります。\n\nMarkdown では以下のように記述しています。\n\n\\`\\`\\`pyterminal  \n\\`\\`\\`\n\n```pyterminal\n```\n\n### py-script タグ\n\n最も基本的なタグです。\n\n\\`\\`\\`python:pyscript  \nprint(\"Hello world!\")  \n\\`\\`\\`\n\nそれを `\u003cpy-script\u003e` タグに変換することで、PyScript 初期化時にスクリプトが実行されます。\n\n```python:pyscript\nprint(\"Hello world!\")\n```\n\n### py-repl タグ\n\nJupyter Notebook のような感じで逐次実行ができます。\n\n```pyrepl\nprint(\"こんにちは世界!\")\nx = 1\nx\n```\n\n```pyrepl\nraise ValueError()\n```\n\n### py-config タグ\n\n[各種設定値](https://docs.pyscript.net/latest/reference/elements/py-config.html)を入れるためのタグです。\n\nページ内に配置できる `\u003cpy-config\u003e` は一つだけであることに注意が必要です。\n\n今回の実装時には PyScript の fetch 機能を使ってスクリプトファイルのロードを行うという要件があったので、`pyconfig` の markdown の記述は、記事ではファイル一覧として見せるようにしました。\n\n\\`\\`\\`pyconfig  \nterminal = false  \n\n\\[\\[fetch\\]\\]  \nfrom = \"../../../assets/posts/2023/03/dog.py\"  \nto_file = \"./dog.py\"  \n\\`\\`\\`\n\n```pyconfig\nterminal = false\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/dog.py\"\nto_file = \"./dog.py\"\n```\n\nアップロードしたファイルを PyScript に読み込むことで、自作スクリプトを使用できます。\n\n`dog.py` の中身はこうなっています。\n\n```python:dog.py\nclass Dog:\n    def bark(self):\n        print(\"Bow-wow!\")\n```\n\n`\u003cpy-script\u003e` で実行すると print したものがターミナルに出てきます。\n\n```python:pyscript\nfrom dog import Dog\n\nwanchan = Dog()\nwanchan.bark()\n```\n\n## react-markdown のコードブロックでのオレオレ文法で PyScript を導入\n\nすでに見ていただいたように、コードブロックの言語を記載する部分を拡張したオレオレ文法で実装しています。\n\nコードブロック開始の \\`\\`\\` の横に書いた文字列が [`CodeBlock`](https://github.com/SogoKato/sogokato.github.io/blob/8769da4e6bb4bdecf4a0c59d274d4a439b66535b/components/CodeBlock.tsx) コンポーネントの `className` 引数に渡されるので、それを `split` して条件分岐を作ります。\n\n関連するソースコード（執筆時点）\n* [components/CodeBlock.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/CodeBlock.tsx)\n\n## PyScript のカスタム要素に対応する React コンポーネントを作成\n\n上記の CodeBlock やその他の場所から呼び出される PyScript のカスタム要素を表すコンポーネントです。汎用的なライブラリを目指しているわけではないので、すべての引数を受け取れるようにはしていません。\n\n関連するソースコード（執筆時点）\n* `\u003cpy-script\u003e`\n  * [components/PyScript.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyScript.tsx)\n* `\u003cpy-repl\u003e`\n  * [components/PyRepl.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyRepl.tsx)\n* `\u003cpy-terminal\u003e`\n  * [components/PyTerminal.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyTerminal.tsx)\n* `\u003cpy-config\u003e`\n  * [components/PyConfig.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyConfig.tsx)\n\n## React のハイドレーションのエラーを回避するために Next.js の Dynamic Import を使用\n\nPyScript が DOM の書き換えを行うので、サーバー側で SSR した結果とクライアントの DOM との不整合が発生し、ハイドレーションのエラーが発生してしまいます。\n\n[Next.jsとTailwind CSSでブログを作るときに考えたこと](/posts/2022/11/blog-with-nextjs-and-tailwindcss)の記事でも紹介したことがありますが Next.js には [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) という機能があり、これを使うことでクライアント側のみで実行したい処理を書くことができます。\n\n上で作成した PyScript のカスタム要素に対応するコンポーネント（`PyConfig` 以外）を使う際は Dynamic Import を使用するようにしています。`PyConfig` については DOM が変更されることがないので Dynamic Import にする必要がないです（また、これを Dynamic Import にしたらうまく動作しませんでした）。\n\n関連するソースコード（執筆時点）\n* [components/CodeBlock.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/CodeBlock.tsx)\n\n## PyScript の初期化の仕様に合わせた最適化\n\nPyScript では script タグで読み込みが完了したタイミングで、初期化の処理が行われ、現状では初期化後に設定の変更等は行えません。つまり、script タグの読み込みが完了する時には `\u003cpy-config\u003e` をはじめとする各要素が宣言されている必要があります（詳しくは要検証ですが）。\n\nこの仕様は、動的に要素を管理する React と相性が良くないです。とりあえず、`\u003cReactMarkdown\u003e` の呼び出し側で、PyScript の各要素よりも後ろに配置し `lazyOnload` strategy で読み込むようにしています。\n\nまた、SPA のようなクライアント側でのルーティングを行なっているので、別の記事に移動しても前のページの実行結果がターミナルに残ってしまいます。現状では PyScript 側に destroy 系のメソッドが用意されていないので、こちらもとりあえずの対応として閲覧者にページをリロードするように促す仕組みを入れています・・・。🙇\n\n関連するソースコード（執筆時点）\n* [components/PostCard.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PostCard.tsx)\n* [components/PyTerminal.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyTerminal.tsx)\n\n## おわりに\n\nPyScript はまだまだ発展途上感があり、周辺のエコシステムも整備されていませんが、今回は気合でブログのコードブロックに WASM を導入しました。サードパーティのライブラリも読み込めたりするので、ちょっとしたコードを載せて動かすには十分だと思います。\n\nこの記事が良ければ RSS 登録と「いいね」「役に立った」ボタンをポチッとお願いします！（YouTuber 風）  \nそして、同じようなことを思いついた誰かの助けになれば幸いです！\n\n## 参考文献\n\n* [PyScript](https://pyscript.net/)\n* [Pyodide](https://pyodide.org/en/stable/)\n* [pyscript-react](https://github.com/Py4Js/pyscript-react)\n* [オレオレ記法のMarkdownを任意のReactElementとして変換する](https://qiita.com/bigmon/items/de62335fbf8388192499)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"WebAssembly","ref":"/tags/webassembly"},{"name":"PyScript","ref":"/tags/pyscript"},{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"}],"showTerminalAside":true},{"title":"Pythonのunittest.mock.patchではどこにパッチするかが重要","date":"2023-03-04T00:00:00.000Z","ref":"/posts/2023/03/python-unittest-mock-where-to-patch","desc":" Python 公式ドキュメントの unittest.mock のページにドンピシャの内容が書いてありますが、なかなか気づけずにハマってしまっていたので","draft":false,"content":"\n[Python 公式ドキュメントの unittest.mock のページ](https://docs.python.org/ja/3/library/unittest.mock.html#where-to-patch)にドンピシャの内容が書いてありますが、なかなか気づけずにハマってしまっていたのでメモです。\n\n`unittest.mock.patch` でパッチしたけど当たってない気がする人は参考にしてみてください。\n\n下記の引用に要点が凝縮されています。\n\n\u003e ### どこにパッチするか\n\u003e\n\u003e `patch()` は (一時的に) ある 名前 が参照しているオブジェクトを別のものに変更することで適用されます。任意のオブジェクトには、それを参照するたくさんの名前が存在しえます。なので、必ずテスト対象のシステムが使っている名前に対して patch しなければなりません。\n\u003e\n\u003e 基本的な原則は、オブジェクトが _ルックアップ_ されるところにパッチすることです。その場所はオブジェクトが定義されたところとは限りません。\n\nつまり、宣言した場所ではなく import している側から見たオブジェクトの位置を指定しなさい、ということです。ただ、`from a import SomeClass` とするか、`import a` して `a.SomeClass` とするかでパッチの当て方が変わってくるので注意が必要です。\n\n以下のファイルがある想定で実験してみます。\n\n```pyconfig\nterminal = false\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/a.py\"\nto_file = \"./a.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/b.py\"\nto_file = \"./b.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/c.py\"\nto_file = \"./c.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/test_b.py\"\nto_file = \"./test_b.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/test_c.py\"\nto_file = \"./test_c.py\"\n```\n\n`a.py` の `SomeClass` はテスト対象システムが依存しているクラスです。これがモックの対象となるクラスです。\n\n```python:a.py\nclass SomeClass:\n    def some_method(self):\n        raise NotImplementedError()\n```\n\n`b.py` の `SystemUnderTest` はその名の通りテスト対象システムです。`b.py` では `from a import SomeClass` で import してから `SomeClass()` でインスタンス化しています。\n\n\u003e この状態で `a.SomeClass` を patch() を使って mock out してもテストには影響しません。モジュール b はすでに 本物の `SomeClass` への参照を持っていて、パッチの影響を受けないからです。\n\u003e\n\u003e 重要なのは、 SomeClass が使われている (もしくはルックアップされている) 場所にパッチすることです。この場合、 `some_function` はモジュール b の中にインポートされた `SomeClass` をルックアップしています。\n\nなのでパッチする時は `@patch(\"b.SomeClass\")` とします。\n\n```python:b.py\nfrom a import SomeClass\n\n\nclass SystemUnderTest:\n    def some_function(self):\n        sc = SomeClass()\n        return sc.some_method()\n```\n\n`c.py` の `SystemUnderTest` もその名の通りテスト対象システムです。`ｃ.py` では `import a` で import してから `a.SomeClass()` でインスタンス化しています。\n\n\u003e この場合、パッチしたいクラスはそのモジュールからルックアップされているので、 `a.SomeClass` をパッチする必要があります\n\nなので `@patch(\"a.SomeClass\")` と書いてパッチを当てます。\n\n```python:c.py\nimport a\n\n\nclass SystemUnderTest:\n    def some_function(self):\n        sc = a.SomeClass()\n        return sc.some_method()\n```\n\nそれぞれに対するテストを書いて確かめてみます。`TestB` の `test_patching_a` はパッチが当たらないので失敗するはずです。\n\n```python:test_b.py\nimport unittest\nfrom unittest.mock import patch\n\nfrom b import SystemUnderTest\n\n\nclass TestB(unittest.TestCase):\n    @patch(\"a.SomeClass\")\n    def test_patching_a(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        # Call below will raise NotImplementedError since it is not patched\n        actual = sut.some_function()\n        assert actual == \"mock\"\n\n    @patch(\"b.SomeClass\")\n    def test_patching_b(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        actual = sut.some_function()\n        assert actual == \"mock\"\n```\n\n`TestC` の `test_patching_c` ではパッチを当てることに失敗します。\n\n```python:test_c.py\nimport unittest\nfrom unittest.mock import patch\n\nfrom c import SystemUnderTest\n\n\nclass TestC(unittest.TestCase):\n    @patch(\"a.SomeClass\")\n    def test_patching_a(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        actual = sut.some_function()\n        assert actual == \"mock\"\n\n    @patch(\"c.SomeClass\")  # will raise AttributeError\n    def test_patching_c(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        actual = sut.some_function()\n        assert actual == \"mock\"\n```\n\n実行します。\n\n```python:main.py:pyscript\nfrom unittest import TestLoader\nfrom unittest import TextTestRunner\n\n\nloader = TestLoader()\ntest = loader.discover(\".\")\nrunner = TextTestRunner()\nrunner.run(test)\n```\n\n```pyterminal\n```\n\n期待通りの結果が得られていますね。Python の import まわりはやっぱりなんか面倒くさい・・・。\n\n## 参考文献\n\n* [unittest.mock --- モックオブジェクトライブラリ](https://docs.python.org/ja/3/library/unittest.mock.html)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"単体テスト","ref":"/tags/単体テスト"}],"showTerminalAside":true},{"title":"Ansibleでgpg公開鍵とaptのサードパーティリポジトリを追加する ～Terraformをインストールしたい～","date":"2023-03-01T00:00:00.000Z","ref":"/posts/2023/03/ansible-apt-repo-signed-by-gpg-key","desc":" apt を使って docker や terraform をインストールする時など、提供元のサードパーティ apt リポジトリを追加する場合が結構ありますよね。その際に、今までは `apt-key` を使って OpenPGP 公開鍵をインポートしていたのですが、`apt-key` は [Debian","draft":false,"content":"\napt を使って docker や terraform をインストールする時など、提供元のサードパーティ apt リポジトリを追加する場合が結構ありますよね。その際に、今までは `apt-key` を使って OpenPGP 公開鍵をインポートしていたのですが、`apt-key` は [Debian 11 と Ubuntu 22.04 を最後に使えなくなる](https://manpages.debian.org/unstable/apt/apt-key.8.ja.html) ので、今後は `gnupg` を使った方法が主流になっていきます。\n\nAnsible にも [ansible.builtin.apt_key module](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_key_module.html) がありますが、これは後方互換性のために残されるものの、今後新たに使うのは避けたほうが良いでしょう。\n\n幸い、これからの公開鍵と apt リポジトリの紐づけの方法はとてもシンプルです。\n\n* 公開鍵はどこにおいても OK\n  * `/usr/share/keyrings/` に置くことが多そう\n* `deb [signed-by=/path/to/key] ...` と書いたファイルを `/etc/apt/sources.list.d` に追加する\n  * `add-apt-repository` でも同様\n* 公開鍵の形式は `.asc` でも `.gpg` でも OK\n  * [apt-key が非推奨になったので](https://zenn.dev/spiegel/articles/20220508-apt-key-is-deprecated) の記事が参考になります\n\n3点目の公開鍵の形式については、私はそもそも2種類あることを今回初めて知りました。\n\n* バイナリ形式\n  * `.gpg` 拡張子\n* ASCII 形式（armored）\n  * `.asc` 拡張子\n\nまぁバイナリかテキストエンコードされているかという違いだけですね。インターネットからダウンロードしてくるときは asc になっていて、そのあと dearmor して格納するという手順を [Docker](https://docs.docker.com/engine/install/ubuntu/) および [Hashicorp](https://www.hashicorp.com/official-packaging-guide) のドキュメントで見つけることができました（いつも意味を理解せずにコマンドを流し込んでいたことを反省）。\n\n## 成果物\n\n前段が長くなりましたが、今回作っていく Ansible の task は以下の流れになります。\n\n1. `apt update` \u0026\u0026 依存ライブラリのインストール\n1. 公開鍵（`.asc` 形式）をダウンロード\n1. 公開鍵のフィンガープリントを検証\n1. サードパーティ apt リポジトリの追加 \u0026\u0026 `apt update`\n1. サードパーティ apt リポジトリからパッケージをインストール\n\nHashicorp の公開鍵と apt リポジトリを追加して、terraform パッケージをインストールするためのサンプルが下記になります。他のサードパーティ apt リポジトリを追加する場合にも応用が利くかもしれません。\n\n```yaml\n- name: apt cache is updated\n  apt:\n    update_cache: yes\n    cache_valid_time: 3600\n  when: ansible_distribution == 'Debian' or ansible_distribution == 'Ubuntu'\n\n- name: prerequisites are installed\n  package:\n    name: \"{{ item }}\"\n    state: present\n  with_items:\n    - gnupg\n    - software-properties-common\n\n- name: hashicorp gpg key is installed\n  ansible.builtin.get_url:\n    url: https://apt.releases.hashicorp.com/gpg\n    dest: /usr/share/keyrings/hashicorp-archive-keyring.asc\n\n- name: hashicorp gpg key is verified\n  command: gpg --dry-run -q --import --import-options import-show /usr/share/keyrings/hashicorp-archive-keyring.asc\n  register: hashicorp_gpg_show_result\n  changed_when: no\n  # MEMO: Check the URL below for the latest fingerprint.\n  #       https://www.hashicorp.com/official-packaging-guide\n  failed_when: \"'798AEC654E5C15428C8E42EEAA16FCBCA621E701' not in hashicorp_gpg_show_result.stdout\"\n\n- name: hashicorp repository is added\n  ansible.builtin.apt_repository:\n    repo: deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.asc] https://apt.releases.hashicorp.com {{ ansible_distribution_release }} main\n    filename: hashicorp\n    state: present\n\n- name: terraform is installed\n  package:\n    name: terraform\n    state: present\n```\n\n## すこし解説\n\n`hashicorp gpg key is verified` ではダウンロードした公開鍵が公式のものかどうかをフィンガープリントを比較して検証しています。フィンガープリントは執筆時点（2023/3/1）のものです。\n\n若干気持ち悪い実装な気もするので（とはいえ目視でやっていることと同じだけども）、もっと良い実装を知っている人はぜひ教えてください。。\n\n参考までに `gpg --dry-run -q --import --import-options import-show /usr/share/keyrings/hashicorp-archive-keyring.asc` の出力は下記のようになります。\n\n```\npub   rsa4096 2023-01-10 [SC] [expires: 2028-01-09]\n      798AEC654E5C15428C8E42EEAA16FCBCA621E701\nuid                      HashiCorp Security (HashiCorp Package Signing) \u003csecurity+packaging@hashicorp.com\u003e\nsub   rsa4096 2023-01-10 [S] [expires: 2028-01-09]\n```\n\n`hashicorp repository is added` では `signed-by=` でダウンロードした公開鍵のパスを指定することで公開鍵と apt リポジトリを紐づけています。Ansible の `ansible_distribution_release` 変数を使うことで、コードネーム（jammy とか focal とか bionic とか）を取得することができます（`lsb_release -cs` と同等）。\n\n`ansible.builtin.apt_repository module` がデフォルトで changed の時に自動で `apt update` もしてくれるので明示的に書く必要はありません。\n\n## 実行結果\n\n```\nPLAY [localhost] **********************************************************************************************************\n\nTASK [Gathering Facts] ****************************************************************************************************\nok: [localhost]\n\nTASK [apt cache is updated] ***********************************************************************************************\nok: [localhost]\n\nTASK [prerequisites are installed] ****************************************************************************************\nok: [localhost] =\u003e (item=gnupg)\nok: [localhost] =\u003e (item=software-properties-common)\n\nTASK [hashicorp gpg key is installed] *************************************************************************************\nchanged: [localhost]\n\nTASK [hashicorp gpg key is verified] **************************************************************************************\nok: [localhost]\n\nTASK [hashicorp repository is added] **************************************************************************************\nchanged: [localhost]\n\nTASK [terraform is installed] *********************************************************************************************\nchanged: [localhost]\n\nPLAY RECAP ****************************************************************************************************************\nlocalhost                  : ok=7    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0\n```\n\n## 参考文献\n\n* [APT-KEY(8)](https://manpages.debian.org/unstable/apt/apt-key.8.ja.html)\n* [ansible.builtin.apt_key module – Add or remove an apt key](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_key_module.html)\n* [ansible.builtin.apt_repository module – Add and remove APT repositories](https://docs.ansible.com/ansible/latest/collections/ansible/builtin/apt_repository_module.html)\n* [Official Packaging Guide](https://www.hashicorp.com/official-packaging-guide)\n* [Install Terraform](https://developer.hashicorp.com/terraform/tutorials/aws-get-started/install-cli)\n* [Install Docker Engine on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)\n* [apt-key が非推奨になったので](https://zenn.dev/spiegel/articles/20220508-apt-key-is-deprecated)\n* [非推奨となったapt-keyの代わりにsigned-byとgnupgを使う方法](https://www.clear-code.com/blog/2021/5/5.html)\n* [GnuPG の使用法](https://www.math.s.chiba-u.ac.jp/~matsu/gpg/gpg-3.html)\n* [How do I verify an asc key fingerprint?](https://askubuntu.com/questions/48508/how-do-i-verify-an-asc-key-fingerprint)\n","tags":[{"name":"Ansible","ref":"/tags/ansible"},{"name":"Terraform","ref":"/tags/terraform"},{"name":"APT","ref":"/tags/apt"}],"showTerminalAside":false},{"title":"TerraformでAPI Gatewayのスロットリングを設定する","date":"2023-02-23T00:00:00.000Z","ref":"/posts/2023/02/aws-api-gateway-terraform-throttling-settings","desc":" AWS API Gateway のスロットリングを Terraform を使って設定する方法を見つけるまでに少し手間取ったのでメモ。\n\n## AWS マネジメントコンソールでの場所\n\n今回 Terraform で設定するのは、マネジメントコンソールの各ステージの設定画面内の「デフォルトのメソッドス","draft":false,"content":"\nAWS API Gateway のスロットリングを Terraform を使って設定する方法を見つけるまでに少し手間取ったのでメモ。\n\n## AWS マネジメントコンソールでの場所\n\n今回 Terraform で設定するのは、マネジメントコンソールの各ステージの設定画面内の「デフォルトのメソッドスロットリング」に該当する箇所です。\n\n![management console](/images/posts/2023/02/aws_apigw_console.png)\n\n## そもそも API Gateway のスロットリングとは\n\nAPI Gateway では API が1秒あたりに処理できるリクエスト数や同時に処理できるリクエスト数を制限することができます。これによって負荷が高くなりすぎたり、攻撃によって意図しない高額請求を受けてしまったりするリスクを減らすことができます。\n\nただし、この設定はベストエフォートで提供されるため、**この設定値がリクエスト上限になるわけではない**という点に注意は必要です。\n\n\u003e API のスロットリングおよびクォータを設定して、多すぎるリクエストで API の負荷が高くなりすぎないように保護できます。スロットルとクォータの両方はベストエフォートベースで適用されるため、これらは保証されたリクエスト上限ではなく、目標として考える必要があります。\n\n_[AWS デベロッパーガイド](https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-request-throttling.html)より引用。_\n\n### 設定できる値\n\n以下の2つがあります。これらのリクエスト数の制限を上回った時、`429 Too Many Requests` が返るようになります。\n\n* **レート：1秒あたりに処理できるリクエスト数**\n* **バースト：同時に処理できるリクエスト数**\n\n### スコープ\n\n次のスコープの順序で適用されます（１が最も優先される）。\n\n\u003e 1. 使用量プランで API ステージに設定したクライアントあたり、またはメソッドあたりのスロットリング制限\n\u003e 2. API ステージに設定したメソッドあたりのスロットリング制限\n\u003e 3. リージョンごとのアカウントレベルのスロットリング\n\u003e 4. AWS リージョンのスロットリング\n\n_[AWS デベロッパーガイド](https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-request-throttling.html)より引用。_\n\n1はクライアント（API キー）単位の設定です。これに関しては今回の記事のスコープ外ですので、試してみたい方は AWS デベロッパーガイド [API キーを使用した使用量プランの作成と使用](https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-api-usage-plans.html)のページをご覧ください。\n\n2が今回設定する項目になります。今回はあるステージにおけるすべてのメソッドを対象にした設定を行いますが、**パスごとメソッドごとの設定を行うことも可能**です。\n\n3は AWS アカウント単位の設定になります。今回の記事のスコープ外です。\n\n4は AWS が設定しているリージョンごとの設定になります。ユーザーは変更することができません。また、1〜3の設定値は4の値よりも高くすることはできません。\n\n## Terraform での設定方法\n\nTerraform で API Gateway のあるステージにおけるすべてのメソッドを対象にスロットリングの設定を行うには以下のように書けば OK です。\n\n```tf\nresource \"aws_api_gateway_method_settings\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  stage_name  = aws_api_gateway_stage.example.stage_name\n  method_path = \"*/*\"\n\n  settings {\n    throttling_rate_limit  = 2\n    throttling_burst_limit = 1\n  }\n}\n```\n\nこの `settings` には上記2つ以外にも API Gateway 関連の設定ができますので気になる方は Terraform 社ドキュメント [Resource: aws_api_gateway_method_settings](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_method_settings) をご覧ください。\n\n## サンプル\n\n下記サンプルは [API Gateway REST API OpenAPI Example](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi) を基に作成しています。\n\n注意点として、Terraform 社ドキュメントに次の記載があります。\n\n\u003e We recommend using this resource in conjunction with the `aws_api_gateway_stage` resource instead of a stage managed by the `aws_api_gateway_deployment` resource optional `stage_name` argument. Stages managed by the `aws_api_gateway_deployment` resource are recreated on redeployment and this resource will require a second apply to recreate the method settings.  \n\u003e 訳：このリソース（訳註：`aws_api_gateway_method_settings`）を　`aws_api_gateway_stage` リソースとあわせて使うことをおすすめします。`aws_api_gateway_deployment` リソースの任意の引数 `stage_name` で管理されるステージと一緒に使うことはおすすめしません。`aws_api_gateway_deployment` で管理されるステージは再デプロイ時に再作成され、メソッドの設定を再作成するために再度 apply する必要が出てきます。\n\n_[Terraform 社ドキュメント](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_method_settings) より引用。_\n\nもしすでに API Gateway に関する Terraform 設定があり、`aws_api_gateway_deployment` の `stage_name` 引数を使っている場合は、`aws_api_gateway_stage` を使って書くように修正したほうが良いでしょう。\n\nその際、\n\n```tf\ntriggers = {\n  redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n}\n\nlifecycle {\n  create_before_destroy = true\n}\n```\n\nあたりが関連する設定になっていると思います。私の実際のプロジェクトの場合はこのサンプルと異なり、Lambda との統合を行っていたので、`sha1(jsonencode(aws_api_gateway_rest_api.example.body))` に相当する書き方がわからず、`triggers` `lifecycle` は消しちゃいました。。（今のところは大丈夫そうですが、もし更新がありましたら追記します）\n\n```tf\n#\n# Variables\n#\n\nvariable \"aws_region\" {\n  default     = \"ap-northeast-1\"\n  description = \"AWS Region to deploy example API Gateway REST API\"\n  type        = string\n}\n\nvariable \"rest_api_name\" {\n  default     = \"api-gateway-rest-api-openapi-example\"\n  description = \"Name of the API Gateway REST API (can be used to trigger redeployments)\"\n  type        = string\n}\n\nvariable \"rest_api_path\" {\n  default     = \"/path1\"\n  description = \"Path to create in the API Gateway REST API (can be used to trigger redeployments)\"\n  type        = string\n}\n\n#\n# Provider\n#\n\nprovider \"aws\" {\n  region = var.aws_region\n}\n\n#\n# API Gateway\n#\n\nresource \"aws_api_gateway_rest_api\" \"example\" {\n  body = jsonencode({\n    openapi = \"3.0.1\"\n    info = {\n      title   = var.rest_api_name\n      version = \"1.0\"\n    }\n    paths = {\n      (var.rest_api_path) = {\n        get = {\n          x-amazon-apigateway-integration = {\n            httpMethod           = \"GET\"\n            payloadFormatVersion = \"1.0\"\n            type                 = \"HTTP_PROXY\"\n            uri                  = \"https://ip-ranges.amazonaws.com/ip-ranges.json\"\n          }\n        }\n      }\n    }\n  })\n\n  name = var.rest_api_name\n\n  endpoint_configuration {\n    types = [\"REGIONAL\"]\n  }\n}\n\nresource \"aws_api_gateway_deployment\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n\n  triggers = {\n    redeployment = sha1(jsonencode(aws_api_gateway_rest_api.example.body))\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n#\n# Stage and Stage Settings\n#\n\nresource \"aws_api_gateway_stage\" \"example\" {\n  deployment_id = aws_api_gateway_deployment.example.id\n  rest_api_id   = aws_api_gateway_rest_api.example.id\n  stage_name    = \"example\"\n}\n\nresource \"aws_api_gateway_method_settings\" \"example\" {\n  rest_api_id = aws_api_gateway_rest_api.example.id\n  stage_name  = aws_api_gateway_stage.example.stage_name\n  method_path = \"*/*\"\n\n  settings {\n    throttling_rate_limit  = 2\n    throttling_burst_limit = 1\n  }\n}\n```\n\n```shell\nexport AWS_ACCESS_KEY_ID=\nexport AWS_SECRET_ACCESS_KEY=\n```\n\n```shell\nterraform init\nterraform plan\nterraform apply\n```\n\ncurl で同時に複数のリクエストを投げてみて429が返ってくるかを確かめます。curl の `--parallel` を使うために、同じ内容のリクエストを12個作成します。\n\n```shell\nfor i in 0 1 2 3 4 5 6 7 8 9 10 11;\ndo echo 'url = \"https://xxxxxxxxxx.execute-api.ap-northeast-1.amazonaws.com/example/path1\"' \u003e\u003e data.txt;\necho 'output = \"/dev/null\"' \u003e\u003e data.txt;\necho 'write-out = \"%{http_code}\\n\"' \u003e\u003e data.txt;\necho 'silent' \u003e\u003e data.txt;\ndone\n```\n\n```shell\ntime curl --parallel --parallel-immediate --parallel-max 4 --config data.txt\n```\n\n実行結果は毎回変わりますが、以下のような結果になります。きっかりレート2・バースト1になっていなさそうなので、やはりベストエフォートなのだなということが伺えます。\n\n```\n200\n200\n200\n200\n429\n429\n200\n200\n429\n200\n200\n200\n\nreal    0m1.527s\nuser    0m0.114s\nsys     0m0.151s\n```\n\n## 参考文献\n\n* [API リクエストを調整してスループットを向上させる](https://docs.aws.amazon.com/ja_jp/apigateway/latest/developerguide/api-gateway-request-throttling.html)\n* [Resource: aws_api_gateway_method_settings](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/api_gateway_method_settings)\n* [API Gateway REST API OpenAPI Example](https://github.com/hashicorp/terraform-provider-aws/tree/main/examples/api-gateway-rest-api-openapi)\n* [Burst Throttling on AWS API Gateway Explained](https://www.petefreitag.com/item/853.cfm)\n","tags":[{"name":"AWS","ref":"/tags/aws"},{"name":"API Gateway","ref":"/tags/api-gateway"},{"name":"Terraform","ref":"/tags/terraform"}],"showTerminalAside":false},{"title":"プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部","date":"2023-02-22T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part3","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んだので、そのまとめを部ごとに書いていこうと思います。\n\n1. [単体テストの目的・定義・学派・命名","draft":false,"content":"\n[『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）](https://book.mynavi.jp/ec/products/detail/id=134252)を読んだので、そのまとめを部ごとに書いていこうと思います。\n\n1. [単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部](/posts/2023/01/unit-testing-principles-practices-and-patterns-part1)\n1. [リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1)\n1. [ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-2)\n1. プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部（この記事）\n\n今回は第3部「統合（integration）テスト」についての感想と考察になります。第3部は以下の3章で構成されています。第4部「単体テストのアンチ・パターン」については割愛しますが、ここにもまた重要かつ気になるトピックの内容が書かれていたので、興味のある方はぜひ手に取って読んでみてください。\n\n* 第8章：なぜ、統合（integration）テストを行うのか？\n* 第9章：モックのベスト・プラクティス\n* 第10章：データベースに対するテスト\n\nこれらの章では、私がこの本を読みながら実際にどのように自分のプロジェクトをリファクタリングしていくかを考えているときに浮かんでいた疑問点をほぼすべて解消してくれました。\n\n特に印象に残ったところをまとめていきたいと思います。\n\n## モックを使うべきタイミング\n\n\u003e 管理下にある依存に対しては実際のインスタンスを使うようにし、管理下にない依存に対してはモックを使うようにしましょう。\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.270 より引用。_\n\nここでいう「管理下にある依存」とは、テスト対象のアプリケーションからしか利用されない「好きなようにできる」依存のことで、多くのアプリケーションにおいてはデータベースなどが該当します。「管理下にない依存」とは、テスト対象のアプリケーションが「好きなようにできない」依存のことで、外部から観測可能な振る舞いになります。\n\n著者は、管理下にない依存をモックの置き換えることで「どのようなリファクタリングを行ったとしても、管理下にない依存とのコミュニケーションを行う際の仕様が壊れていないことを確認できる」ため、非常に効果的と言っています。逆に、管理下にある依存に対しては、そのまま使うことで「対象のアプリケーションが最終的にどのような状態になるのかを外部の視点から検証しやすく」なり、加えて、「データベースへのリファクタリング（たとえば、カラムの名前の変更やほかのデータベースへの移行）もおこないやすく」なると言っています（p.270）。\n\n## 開発者しか見ないログはテストで確認しない\n\n\u003e ログ出力をテストすべきか、という問いの答えは、**テスト対象とするログ出力がアプリケーションの観測可能な振る舞いの一部なのか、それとも、実装の詳細なのかによって変わる**、ということになります。\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.292 より引用。太字は原文ママ。_\n\nなので、ほかのすべての外部依存と同じように「外部から観測可能な振る舞い」なのか「実装の詳細」なのかで考えればよく、つまり、「ビジネス要求に応じたログ」なのか「開発者しか見ないログ」なのか、ということになります。\n\n## 本番と同じ種類のデータベースでテストを行おう\n\n実際のデータベースをテストで使えるようにするためにはそれなりの工夫が必要でしょう。また、そのコストを考えてモックにしているという人も多いのではないでしょうか。とはいえ、前々項で著者が挙げている利点は、そのコストを上回るものだと思います。テスト用のデータベースを用意する際の指針をまとめると以下のようになります。\n\n\u003e * 統合テストでのデータの後始末\n\u003e   * 各テスト・ケースを実行する前にバックアップからデータベースを復元させる\n\u003e     * テストに費やされる時間は他の方法よりも長くなる\n\u003e   * テスト・ケースの実行後にデータの後始末をする\n\u003e     * データの後始末の処理が実行されなかったときに問題となってしまう\n\u003e   * 各テスト・ケースを1つのデータベース・トランザクション内で行い、コミットせずにロールバックする\n\u003e     * 本番環境では行わないデータベース・トランザクションの利用をテストでは行うことになってしまう\n\u003e   * **テスト・ケースの実行前にデータの後始末を行う**\n\u003e     * これらの中では、この方法がもっとも優れている\n\u003e     * あまり時間がかからず、本番環境での振る舞いとテスト時の振る舞いが異なることもなく、データの後始末がきちんと実行されるのかを心配する必要もなくなるから\n\u003e * メモリ内（in-memory）データベースの使用に関する問題\n\u003e   * SQLite\n\u003e   * 本書では、テストの際に、**メモリ内データベースを使うことを推奨していません**\n\u003e   * 機能面において一般的なデータベースと異なる部分があるから\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）pp.349-352 より引用し箇条書きにまとめた。太字は筆者によるもの。_\n\nローカル環境では大抵の場合ローカルで動かす用の DB コンテナが建っているのでそれをテストでも使用すれば問題なさそうですし、CI 環境でも実行環境に別のコンテナを立てる手段が用意されている（たとえば、[Gitllab では services を使う方法がある](https://docs.gitlab.com/ee/ci/services/mysql.html)）ので、何とかなる気がします。\n\n## モックの対象になる型は自身のプロジェクトが所有する型のみにする\n\nモックを使うような、管理下にない依存を扱うとき、サード・パーティ製の SDK などのライブラリを使うことが多いでしょう。著者はモックを使用する際のベスト・プラクティスの1つとして「そのライブラリに対するアダプタを独自に作成し、そのアダプタに対してモックを作成する」ということを勧めています。理由は下記です。\n\n\u003e * サード・パーティ製のライブラリが実際に機能しているのかを深く知ることは滅多にできないから。\n\u003e * サード・パーティ製のライブラリ自体が利用可能なインターフェイスを既に提供していた場合、そのインターフェイスをモックに置き換える対象にすると、モックの振る舞いとサード・パーティ製のライブラリの実際の振る舞いとが一致することを保証しなくてはならなくなり、リスクを伴うことになるから。\n\u003e * アダプタを挟むことで、サード・パーティ製のライブラリに含まれるビジネス的に本質ではない技術的な詳細を隠蔽できるようになり、さらに、自身のアプリケーションの用語を用いてライブラリとの関係を定義できるようになるから。\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.323 より引用。_\n\nこれによって、ライブラリの更新によってインターフェイスが変わった場合でも、「変更による影響をそのアダプタだけに抑えられる」ことも利点として挙げられています（p.323）。\n\n## リポジトリ（データベース操作クラス）はテストすべきか？\n\nデータベースを操作するためのリポジトリに対する単位テストを行わなくてよいのか、ということがこの本を読んでいく中で気になっていました。\n\nリポジトリを[前回出てきたプロダクション・コードの4種類](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-2)に当てはめると「あまり複雑にはならないが、プロセス外依存を扱うため……『コントローラ』に属することになる」とされています。プロセス外依存を扱っていて保守コストが高い一方で、複雑さを伴っていないので退行に対する保護があまり備わっていないということから、著者は「**リポジトリを直接検証するのではなく、統合テストのシナリオの一部に含めて検証する**」という結論を出しています（pp.363-365）。\n\nたとえば、assert フェーズで実際のリポジトリのメソッドを使って取得することで、取得メソッドの動作確認が行えます。\n\n## まとめ\n\n以上、第3部「統合（integration）テスト」についてのまとめと所感でした。\n\n『単体テストの考え方／使い方』では本当に多くの学びがあったので、いま私が担当しているコード・ベースにもその学びを反映させたいと思い、計画を立ててみました。まず、コード・ベースをあるべき姿の3種類に分類しました。\n\n* ドメイン・モデル／アルゴリズム\n* コントローラ\n* 取るに足らないコード\n\n現状では「ドメイン・モデル／アルゴリズム」の多くでコントローラに関するコードが混在してしまっている（外部依存をそのまま扱っている）ので、該当箇所に印をつけていき、それぞれについてどのようにコントローラの分離が行えるかを検討しました。\n\n次に、今あるテスト・ケースをどのようにリファクタリングしていくかを検討しました。これらのリファクタリングは、リファクタリングのためのリファクタリングと言えそうです（これが完了することで、リファクタリングへの耐性がつくので）。\n\nこれらはまだ素案の段階ですが、これからチームメンバーと議論してさらに煮詰めていき、これを実行に移していくのがとても楽しみです。\n\n最後に、素晴らしい本を執筆・翻訳くださった方々へ、その努力に敬意を表するとともに感謝申し上げます。\n","tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半","date":"2023-02-19T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-2","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. [単体テストの目的・定義・学派・","draft":false,"content":"\n[『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）](https://book.mynavi.jp/ec/products/detail/id=134252)を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. [単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部](/posts/2023/01/unit-testing-principles-practices-and-patterns-part1)\n1. [リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1)\n1. ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半（この記事）\n1. [プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部](/posts/2023/02/unit-testing-principles-practices-and-patterns-part3)\n\n今回は第2部「単体テストとその価値」の後半についての感想と考察になります。第2部は以下の4章で構成されていますが、今回は後半の第6章と第7章について扱います。\n\n* 第6章：単体テストの3つの手法\n* 第7章：単体テストの価値を高めるリファクタリング\n\n## 関数型プログラミング\n\n単体テストの手法には以下の3つが存在します。\n\n\u003e * 出力値ベース・テスト（戻り値を確認するテスト）\n\u003e * 状態ベース・テスト（状態を確認するテスト）\n\u003e * コミュニケーション・ベース・テスト（オブジェクト間のやり取りを確認するテスト）\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.167 より引用し箇条書きにまとめた。_\n\n著者は、リファクタリングへの耐性と保守のしやすさを維持するのに必要なコストの観点から「出力値ベース・テストがもっとも費用対効果の高いテスト・ケースを作成できる」としています。そして、出力値ベース・テストは、「関数型による単体テストの手法」であることから、第6章では主に関数型プログラミング・関数型アーキテクチャについて解説されています。\n\n\u003e * 関数型プログラミングとは、数学的関数を用いたプログラミングのことです。そして、この数学的関数（mathematical function）は純粋関数（pure function）とも呼ばれ、**隠れた入力や出力がない**関数（もしくはメソッド）のことになります\n\u003e * 関数型アーキテクチャとは何か？\n\u003e   * 関数型アーキテクチャでは、純粋関数（不変）を用いて書かれたコードを最大限に増やす一方、副作用を扱うコードを最小限に抑えるようにします\n\u003e   * 関数型アーキテクチャでは、**副作用をビジネス・オペレーションの最初や最後に持っていく**ことで、**ビジネス・ロジックと副作用とを分離**しやすくしています\n\u003e   * 決定を下すコードは関数的核（functional core）もしくは不変核（immutable core）と呼ばれるのに対し、決定に基づくアクションを実行するコードは可変殻（mutable shell）と呼ばれます\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）pp.181-185 より引用し箇条書きにまとめた。太字は筆者によるもの。_\n\n私は関数型プログラミング・関数型アーキテクチャについて何も知識がなかったのですが、本書の解説によってそのあらましを理解することができました。そして、関数型アーキテクチャの話を前提に第7章へと続いていきます。\n\n## ビジネス・ロジックと連携の指揮を分離させよ\n\nMVC（Model-View-Controller）の考え方でも重要な、ビジネス・ロジックとコントローラの分離ですが、これを適切に行うことで、「特に重要な部分だけがテスト対象」となっていて、「最小限の保守コストで最大限の価値を生み出す」優れたテスト・スイートが書けるようになります。\n\n著者はプロダクション・コードを次の4種類に分類しました。\n\n\u003e * **ドメイン・モデル／アルゴリズム**：コードの複雑さ／ドメインにおける重要性が高いが、協力者オブジェクトの数は少ない\n\u003e * 取るに足らないコード：コードの複雑さ／ドメインにおける重要性が低く、協力者オブジェクトの数も少ない\n\u003e * **コントローラ**：協力者オブジェクトの数は多いが、コードの複雑さ／ドメインにおける重要性は低い\n\u003e * **過度に複雑なコード**：協力者オブジェクトの数が多く、コードの複雑さ／ドメインにおける重要性も高い\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.217 より引用し箇条書きにまとめた。太字は筆者によるもの。_\n\nこの「過度に複雑なコード」がどげんとせんといかんヤツで、「ドメイン・モデル／アルゴリズム」と「コントローラ」に分割していきます。そのために導入されるのが「**質素なオブジェクト（Humble Object）**」という設計パターンです。\n\n\u003e * 質素なオブジェクト自体にはロジックを（ほぼ）含ませないようにすることで、質素なオブジェクトをテストする必要がないようにする\n\u003e * このパターンは各クラスが持てる責任を1つだけにする単一責任の原則（Single Responsibility Principle: SRP）を遵守するための手段としても見ることができます\n\u003e * MVP（Model-View-Presenter）パターンやMVC（Model-View-Controller）パターン……では、PresenterもしくはControllerが質素なオブジェクトとなり、ビューとモデルを結びつける役割を担います\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）pp.220-222 より引用し箇条書きにまとめた。_\n\n本書では上記を実現するためのサンプル・コードのリファクタリングが分かりやすく解説されており、とても参考になりました。個人的にはコントローラという言葉の意味をちゃんと理解せずにプログラムを書いてしまっていた（ほかの人のアーキテクチャの猿真似をしていた）ところがあったので反省しました……。\n\nそのため、コントローラと認識しつつ、普通に分岐が入ってしまっていて過度に複雑なコードになってしまってたのですが、本書では「コントローラにおける条件付きロジックの扱い」についても言及されています。\n\n\u003e ビジネス・ロジックのコードと連携を指揮するコードの分離をもっとも行いやすいのは、1つのビジネス・オペレーションが次の3段階の流れになっている場合です：\n\u003e\n\u003e 1. ストレージからのデータの取得\n\u003e 2. ビジネス・ロジックの実行\n\u003e 3. 変更されたデータの保存\n\u003e\n\u003e しかしながら、これらの手順を完璧に順守できない場合もよくあります。たとえば……決定を下す過程の中で、途中で得た結果を使ってプロセス外依存から新たにデータを取得しなければならないような場合です。\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.240 より引用。一部省略。_\n\nそして、この課題を解決するための選択肢としては以下の3つがあります。\n\n\u003e * 外部の依存に対するすべての読み込みと書き込みをビジネス・オペレーションの始めや終わりに持っていく\n\u003e   * パフォーマンスは劣化する\n\u003e   * パフォーマンスの高さは重要な性質である → **選べない**\n\u003e * ドメイン・モデルにプロセス外依存を注入する\n\u003e   * ドメイン・モデルに対するテストのしやすさは失われる\n\u003e   * ほとんどのコードを過度に複雑なコードに属するようにしてしまいます → **選べない**\n\u003e * 決定を下す過程をさらに細かく分割する\n\u003e   * コントローラの簡潔さを保てなくなる\n\u003e   * ある程度であれば対処することが可能 → **選べる**\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.241 より引用し箇条書きにまとめた。太字は筆者によるもの。_\n\n前の2つの選択肢については容認できない欠点があるので選ぶことはできないのですが、3つ目の選択肢については許容できるので、本書では「決定を下す過程をさらに細かく分割する」ことが推奨されています。\n\n「決定を下す過程をさらに細かく分割する」ための方法として「**確認後実行（CanExecute/Execute）パターン**」があります。\n\nドメイン・モデルに `CanChangeEmail` のような確認するためのメソッドを追加し、これを `ChangeEmail` メソッドをたたくための**事前条件**とすることで、コントローラは事前条件の中身については知らずに済むので、**ビジネス・ロジックがコントローラに流出するのを防ぐ**ことができるようになります（p.243）。\n\nこれは非常に有用なテクニックだと思いました。  \nコントローラ（私の参加するチームでは MVC を使っていないのでそれっぽいもの）に、ビジネス的な条件分岐を書いていて、どこまでがドメイン知識でどこからがそうでないのかが曖昧でモヤモヤすることもあったので、今後はこのようなテクニックを活用して、ビジネス・ロジックとコントローラとの分離を明確にしていきたいと思います。\n\n## 観測可能なふるまいの範囲\n\n[前回の記事](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1)で気になっていた「外部から観測できないプロセス外依存とのコミュニケーションを実装の詳細にしちゃったら、それほぼ E2E テストだから迅速なフィードバック得られなくない？」に対する著者の答えは「玉ねぎの層のように考える」ことでした。\n\n外部クライアントにとっての観測可能な振る舞い、コントローラにとっての観測可能な振る舞い、そしてコントローラで呼び出されるメソッドにとっての観測可能な振る舞いはそれぞれ異なっていて、それぞれにとって直接関係ないことについては意識しない、ということのようです。前章では究極を言えば外部クライアントからのテストだけで良いのではという話になっていましたが、それは違う、ということですね。\n\nそれはそう、という感じはありますが、実際にそのようにテストを作るには、今回の範囲で取り上げたビジネス・ロジックとコントローラの分離が適切に行われていないと、否が応でも直接関係しない呼び出しについても意識せざるを得なくなる気がします。例えば、呼び出し先でさらに DB に依存するクラスを呼び出している場合には DB のモックを作る必要が出てきます。\n\nビジネス・ロジック（関数的核）のクラスから、モックを必要としてしまうプロセス外依存を徹底的に排除することで（これが関数型アーキテクチャの思想）、きれいにテストを書くことができるようになります。回りまわって関数型アーキテクチャの解説がされていたことに腑に落ちました。\n\n## まとめ\n\n以上、第2部「単体テストとその価値」の後半についてのまとめと所感でした。アーキテクチャについては理解していない部分が多く、参考にしているほかのプロジェクトのリポジトリを見ながら唸っていたりするので、今回の範囲ではそうしたところが次々と分かるようになりました。良い単体テストを書くことを目指すと、プロダクション・コードも改善されていくのだなと感じました。\n","tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"FastAPIとSQLAlchemy2.0ならもう型ヒントを諦めなくていい","date":"2023-02-08T00:00:00.000Z","ref":"/posts/2023/02/fastapi-orm-sqlalchemy","desc":" サチコ（Google Search Console）を眺めていたら `FastAPI MySQL` がそれなりに需要ありそうと思ったので、FastAPI と SQLAlchemy を組み合わせて ORM を使う方法を紹介したいと思います。最近の SQLAlchemy（1.4以降）ではマッピングされ","draft":false,"content":"\nサチコ（Google Search Console）を眺めていたら `FastAPI MySQL` がそれなりに需要ありそうと思ったので、FastAPI と SQLAlchemy を組み合わせて ORM を使う方法を紹介したいと思います。最近の SQLAlchemy（1.4以降）ではマッピングされたオブジェクトに型を適用することもできるので、型ヒントを活かして型安全なコードを書くことも難しくなくなっています。\n\n## 環境\n\n* Python 3.10.6\n* FastAPI 0.89.1\n* SQLAlchemy 2.0.1\n* Docker 20.10.13\n* Docker Compose v2.3.3\n\n## 前提\n\nFastAPI 公式ドキュメントの [SQL (Relational) Databases](https://fastapi.tiangolo.com/ja/tutorial/sql-databases/) のページを熟読しておいてください。\n\n2023年1月にリリースされた SQLAlchemy 2.0を使用します。1系を使用している既存プロジェクトの場合は [SQLAlchemy 2.0 - Major Migration Guide](https://docs.sqlalchemy.org/en/20/changelog/migration_20.html) を参考に2.0へ移行してください。1.4から2.0の移行はスムーズだと思います。\n\nSQLAlchemy で利用できる ORM のモデルの書き方はいくつかあります。個人的には [dataclass と統合した書き方](https://docs.sqlalchemy.org/en/20/orm/dataclasses.html)も好きですが、今回はシンプルにベーシックな実装を行います。\n\n## 成果物\n\nhttps://github.com/SogoKato/fastapi-sqlalchemy2\n\n```py\nfrom fastapi import Depends, FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom sqlalchemy import ForeignKey, String, create_engine, select\nfrom sqlalchemy.orm import (\n    DeclarativeBase,\n    Mapped,\n    Session,\n    mapped_column,\n    relationship,\n    sessionmaker,\n)\n\n\"\"\"\nSQLAlchemyのモデル.\n\nBased on:\n* https://docs.sqlalchemy.org/en/20/orm/quickstart.html#declare-models\n* https://fastapi.tiangolo.com/ja/tutorial/sql-databases/#create-the-database-models\n\"\"\"\n\n\nclass Base(DeclarativeBase):\n    \"\"\"各DBモデルの基底クラス.\"\"\"\n\n    pass\n\n\nclass User(Base):\n    \"\"\"usersテーブルのDBモデル.\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    email: Mapped[str] = mapped_column(String(100), unique=True, index=True)\n    hashed_password: Mapped[str] = mapped_column(String(100))\n    is_active: Mapped[bool]\n\n    items: Mapped[list[\"Item\"]] = relationship(back_populates=\"owner\")\n\n\nclass Item(Base):\n    \"\"\"itemsテーブルのDBモデル.\"\"\"\n\n    __tablename__ = \"items\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    title: Mapped[str] = mapped_column(String(30), index=True)\n    description: Mapped[str] = mapped_column(String(30), index=True)\n    owner_id: Mapped[int] = mapped_column(ForeignKey(\"users.id\"))\n\n    owner: Mapped[\"User\"] = relationship(back_populates=\"items\")\n\n\n\"\"\"\nPydanticのモデル.\n\nBased on:\n* https://fastapi.tiangolo.com/ja/tutorial/sql-databases/#create-the-pydantic-models\n\"\"\"\n\n\nclass ItemBase(BaseModel):\n    \"\"\"Itemの基底クラス.\"\"\"\n\n    title: str\n    description: str | None = None\n\n\nclass ItemCreateRequest(ItemBase):\n    \"\"\"Item作成のリクエストを表現するクラス.\"\"\"\n\n    pass\n\n\nclass ItemResponse(ItemBase):\n    \"\"\"Itemのレスポンスを表現するクラス.\"\"\"\n\n    id: int\n    owner_id: int\n\n    class Config:\n        orm_mode = True\n\n\nclass UserBase(BaseModel):\n    \"\"\"Userの基底クラス.\"\"\"\n\n    email: str\n\n\nclass UserCreateRequest(UserBase):\n    \"\"\"User作成のリクエストを表現するクラス.\"\"\"\n\n    password: str\n\n\nclass UserResponse(UserBase):\n    \"\"\"Userのレスポンスを表現するクラス.\"\"\"\n\n    id: int\n    is_active: bool\n    items: list[ItemResponse] = []\n\n    class Config:\n        orm_mode = True\n\n\n\"\"\"\nDBのCRUD操作を行う関数.\n\nBased on:\n* https://docs.sqlalchemy.org/en/20/changelog/migration_20.html#migration-orm-usage\n* https://fastapi.tiangolo.com/ja/tutorial/sql-databases/#crud-utils\n\"\"\"\n\n\ndef get_db_user(db: Session, user_id: int):\n    \"\"\"usersテーブルからuser_idに一致するUserを取得します.\"\"\"\n    return db.execute(select(User).where(User.id == user_id)).scalars().first()\n\n\ndef get_db_user_by_email(db: Session, email: str):\n    \"\"\"usersテーブルからemailに一致するUserを取得します.\"\"\"\n    return db.execute(select(User).where(User.email == email)).scalars().first()\n\n\ndef get_db_users(db: Session, skip: int = 0, limit: int = 100):\n    \"\"\"usersテーブルからUserをすべて取得します.\"\"\"\n    return db.execute(select(User).offset(skip).limit(limit)).scalars().all()\n\n\ndef create_db_user(db: Session, user: UserCreateRequest):\n    \"\"\"usersテーブルにUserを追加します.\"\"\"\n    fake_hashed_password = user.password + \"notreallyhashed\"\n    db_user = User(\n        email=user.email, hashed_password=fake_hashed_password, is_active=True\n    )\n    db.add(db_user)\n    db.commit()\n    db.refresh(db_user)\n    return db_user\n\n\ndef get_db_items(db: Session, skip: int = 0, limit: int = 100):\n    \"\"\"itemsテーブルからItemをすべて取得します.\"\"\"\n    return db.execute(select(Item).offset(skip).limit(limit)).scalars().all()\n\n\ndef create_db_user_item(db: Session, item: ItemCreateRequest, user_id: int):\n    \"\"\"itemsテーブルにItemを追加します.\"\"\"\n    db_item = Item(**item.dict(), owner_id=user_id)\n    db.add(db_item)\n    db.commit()\n    db.refresh(db_item)\n    return db_item\n\n\n\"\"\"\nFastAPIでSQLAlchemyを使うためのセットアップ.\n\"\"\"\n# DBセッションを作成するクラスを作る.\nSQLALCHEMY_DATABASE_URL = \"mysql+mysqldb://user:password@db/test\"\n\n# デバッグ用にecho=Trueに設定.\nengine = create_engine(SQLALCHEMY_DATABASE_URL, echo=True)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n# DBマイグレーションを行う.\nBase.metadata.create_all(bind=engine)\n\n# FastAPIをインスタンス化.\napp = FastAPI()\n\n\ndef get_db():\n    \"\"\"リクエストが来たらセッションを作成し、処理が完了したら閉じるためのDependency.\"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n\n\"\"\"\nFastAPIのルーティング.\n\"\"\"\n\n\n@app.post(\"/users/\", response_model=UserResponse)\ndef create_user(user: UserCreateRequest, db: Session = Depends(get_db)):\n    \"\"\"ユーザーを作成します.\"\"\"\n    db_user = get_db_user_by_email(db, email=user.email)\n    if db_user:\n        raise HTTPException(status_code=400, detail=\"Email already registered\")\n    return create_db_user(db=db, user=user)\n\n\n@app.get(\"/users/\", response_model=list[UserResponse])\ndef read_users(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n    \"\"\"ユーザーを一覧します.\"\"\"\n    users = get_db_users(db, skip=skip, limit=limit)\n    return users\n\n\n@app.get(\"/users/{user_id}\", response_model=UserResponse)\ndef read_user(user_id: int, db: Session = Depends(get_db)):\n    \"\"\"ユーザーを取得します.\"\"\"\n    db_user = get_db_user(db, user_id=user_id)\n    if db_user is None:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return db_user\n\n\n@app.post(\"/users/{user_id}/items/\", response_model=ItemResponse)\ndef create_item_for_user(\n    user_id: int, item: ItemCreateRequest, db: Session = Depends(get_db)\n):\n    \"\"\"ユーザーのアイテムを作成します.\"\"\"\n    return create_db_user_item(db=db, item=item, user_id=user_id)\n\n\n@app.get(\"/items/\", response_model=list[ItemResponse])\ndef read_items(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n    \"\"\"アイテムを一覧します.\"\"\"\n    items = get_db_items(db, skip=skip, limit=limit)\n    return items\n```\n\n以上を `main.py` として保存して、下記の `Dockerfile` `docker-compose.yml` で `docker compose up --build` すれば動きます。\n\n```dockerfile\nFROM python:3.10\n\nWORKDIR /app\n\nENV PATH=$PATH:/root/.local/bin\nCOPY pyproject.toml poetry.lock ./\n\nRUN curl -sSL https://install.python-poetry.org | python3 - \\\n    \u0026\u0026 poetry install\n\nCMD [\"poetry\", \"run\", \"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--reload\"]\n```\n\n```yaml\nversion: '3'\nservices:\n  app:\n    build:\n      context: ./\n      dockerfile: Dockerfile\n    ports:\n      - '8000:8000'\n    volumes:\n      - type: bind\n        source: ./\n        target: /app\n  db:\n    image: mysql:8.0\n    environment:\n      MYSQL_ROOT_PASSWORD: password\n      MYSQL_DATABASE: test\n      MYSQL_USER: user\n      MYSQL_PASSWORD: password\n```\n\n## ちょこっと解説\n\n### SQL Alchemy 2.0 に対応させる\n\nコードを見ればそれがすべてなのであまり解説することはないのですが、FastAPI 公式ドキュメントの [SQL (Relational) Databases](https://fastapi.tiangolo.com/ja/tutorial/sql-databases/) のページとの大きな違いは、SQLAlchemy 2.0風な書き方になっているかどうかです。\n\nSQLAlchemy を使ったことのある方なら `session.query(User).filter(User.id == user_id).first()` のような書き方に慣れているかと思いますが、SQLAlchemy 2.0 ではこの書き方は[レガシーとされています](https://docs.sqlalchemy.org/en/20/orm/queryguide/query.html#legacy-query-api)。\n\nSQLAlchemy Core に統一された書き方が推奨されており、上記の例は以下のように書き換えられます。\n\n```py\nsession.execute(select(User).where(User.id == user_id)).scalars().first()\n```\n\n特徴は\n\n* ステートメント（SELECT ... WHERE ...）とその実行が明確に分離された\n* `Query` クラスではなく `Result` クラスや `ScalarResult` で `.all()` や `.first()` を使う\n\nことです。今までの API よりも分かりやすくなっていますし、型推論も効いているので使いやすいと思います。\n\nモデルクラスの書き方も変わっています。\n\n今までは以下のように定義していた部分が\n\n```py\nid = Column(Integer, primary_key=True, index=True)\n```\n\nこのようになります。\n\n```py\nid: Mapped[int] = mapped_column(primary_key=True, index=True)\n```\n\nそれっぽく移植していけば迷うことは少ないと思います。\n\n### DB セッションの取得には dependency を使う\n\nFastAPI の主要な機能の一つともいえる dependency を使って、DB セッションの生成を行うのが定番となっています。ちなみに、`SessionLocal` の命名は、`sqlalchemy.orm.Session` と区別するためだそうです。\n\n```py\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n```\n\nこの `get_db` dependency を使うことで、リクエストの開始時に DB セッションを生成し（`yield` の段階で渡される）、リクエストの処理が完了したら（finally 節で）DB セッションが閉じられるようになります。Dependency での `yield` の使い方については [Dependencies with yield](https://fastapi.tiangolo.com/ja/tutorial/dependencies/dependencies-with-yield/) をご参照ください。\n\nDependency は、別の dependency の中でも使うことができるので、リクエストの前処理（バリデーションなど）で引数に `db = Depends(get_db)` と指定することで、その中でも DB セッションを使うことができます。便利ですね。\n\n### Pydantic の ORM mode\n\n私のユースケースでは普段使っていないのですが、マッチすれば便利だなと思うのが Pydantic の `orm_mode = True` です。\n\nこれが有効になっていると、Pydantic が値を取得するときに `data[\"id\"]` のように辞書のキーだけでなく、`data.id` のように属性でも値を取得しようと試みるようになるそうです。これだけ聞いてもあまりピンときませんが、この違いがあることによって ORM が張っている relationship（通常は lazy loading なので求められるまでは存在していない）の値をとってくることが可能になるようです（`@property` で呼び出して値をとってこられるというようなことかなと予想しています）。\n\n## まとめ\n\n[Prisma Client Python](https://prisma-client-py.readthedocs.io/en/stable/) の型付けの開発者体験も結構好きでしたが、SQLAlchemy もまだまだ勢いがありますね。ぜひ活用してみてください。\n\n関連記事もどうぞ。  \n[SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ](/posts/2023/01/sqlalchemy-dealing-with-disconnects)\n\n## おまけ：API をたたいてみる\n\n```\n$ curl -s localhost:8000/users/ -XPOST \\\n  -H 'content-type: application/json' \\\n  -d '{\"email\": \"me@example.com\", \"password\": \"mystrongpassword\"}' \\\n  | jq\n```\n\n```json\n{\n  \"email\": \"me@example.com\",\n  \"id\": 1,\n  \"is_active\": true,\n  \"items\": []\n}\n```\n\n```\n$ curl -s localhost:8000/users/ | jq\n```\n\n```json\n[\n  {\n    \"email\": \"me@example.com\",\n    \"id\": 1,\n    \"is_active\": true,\n    \"items\": []\n  }\n]\n```\n\n```\n$ curl -s localhost:8000/users/?limit=0 | jq\n```\n\n```json\n[]\n```\n\n```\n$ curl -s localhost:8000/users/1 | jq\n```\n\n```json\n{\n  \"email\": \"me@example.com\",\n  \"id\": 1,\n  \"is_active\": true,\n  \"items\": []\n}\n```\n\n```\n$ curl -s localhost:8000/users/1/items/ -XPOST \\\n  -H 'content-type: application/json' \\\n  -d '{\"title\": \"LEVEL3\", \"description\": \"My favourite album\"}' \\\n  | jq\n```\n\n```json\n{\n  \"title\": \"LEVEL3\",\n  \"description\": \"My favourite album\",\n  \"id\": 1,\n  \"owner_id\": 1\n}\n```\n\n```\n$ curl -s localhost:8000/users/1 | jq\n```\n\n```json\n{\n  \"email\": \"me@example.com\",\n  \"id\": 1,\n  \"is_active\": true,\n  \"items\": [\n    {\n      \"title\": \"LEVEL3\",\n      \"description\": \"My favourite album\",\n      \"id\": 1,\n      \"owner_id\": 1\n    }\n  ]\n}\n```\n\n```\n$ curl -s localhost:8000/items/ | jq\n```\n\n```json\n[\n  {\n    \"title\": \"LEVEL3\",\n    \"description\": \"My favourite album\",\n    \"id\": 1,\n    \"owner_id\": 1\n  }\n]\n```\n\n## 参考文献\n\n* [SQL (Relational) Databases](https://fastapi.tiangolo.com/ja/tutorial/sql-databases/)\n* [ORM Quick Start](https://docs.sqlalchemy.org/en/20/orm/quickstart.html)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"},{"name":"ORM","ref":"/tags/orm"}],"showTerminalAside":false},{"title":"TypedDictはdictのsubtypeではないので関数の引数にはMappingを使う","date":"2023-02-06T00:00:00.000Z","ref":"/posts/2023/02/typeddict-is-not-subtype-of-dict","desc":" Python の dict（辞書）を TypeScript の interface のように扱えて便利な TypedDict ですが、**dict のサブクラスではない**というのが少し落とし穴だなと思ったのでメモ。\n\n##","draft":false,"content":"\nPython の dict（辞書）を TypeScript の interface のように扱えて便利な [TypedDict](https://peps.python.org/pep-0589/) ですが、**dict のサブクラスではない**というのが少し落とし穴だなと思ったのでメモ。\n\n## まずは PEP を見よう\n\n大抵のことは公式ドキュメントを見れば書いてあります。今回も例外なくそうでした。\n\n\u003e First, any TypedDict type is consistent with `Mapping[str, object]`.\n\nhttps://peps.python.org/pep-0589/#type-consistency\n\n言いたいことは以上です。関数の引数として、その TypedDict 以外の辞書も受け取りたいときは Mapping を使いましょう。\n\n```py\nfrom typing import Mapping, TypedDict\n\nclass Movie(TypedDict):\n    name: str\n    year: int\n\ndef from_mapping(map: Mapping[str, object]):\n    \"\"\"TypedDictを含む任意のマップを受け取る関数.\"\"\"\n\ndef from_dict(dict: dict[str, object]):\n    \"\"\"任意のdictを受け取る関数.\"\"\"\n\nmovie: Movie = {\n  \"name\": \"Harry Potter and the Philosopher's Stone\",\n  \"year\": 1999,\n}\n\n# OK\nfrom_mapping(movie)\n\n# NG\nfrom_dict(movie)\n```\n\n## どんなエラーが出る？\n\n型ヒントなので実行時にエラーになることはありませんが、静的型検査で怒られます。\n\n```\n$ poetry run pyright main.py\n...\npyright 1.1.292\n/path/to/main.py\n  /path/to/main.py:22:11 - error: Argument of type \"Movie\" cannot be assigned to parameter \"dict\" of type \"dict[str, object]\" in function \"from_dict\"\n    \"Movie\" is incompatible with \"dict[str, object]\" (reportGeneralTypeIssues)\n1 error, 0 warnings, 0 informations\nCompleted in 0.512sec\n```\n\nちなみに上記の例では `Mapping[str, object]` を使っていますが `Mapping[str, Any]` でも問題ないです。\n\n## まとめ\n\nとりあえず `dict[str, Any]` でいけるかな～と思っていたら引っかかったので勉強になりました。\n\n少し話はそれますが[ロバストネス原則](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%90%E3%82%B9%E3%83%88%E3%83%8D%E3%82%B9%E5%8E%9F%E5%89%87)というのを最近知りました。\n\n\u003e 貴方が自分ですることに関しては厳密に、貴方が他人から受けることに関しては寛容に  \n\u003e (be conservative in what you do, be liberal in what you accept from others)\n\n今回の例では `dict[str, Any]` を引数として指定するよりも `Mapping[str, Any]` と書くほうが、よりソフトウェアを堅牢な作りにできるのかもと思いました。ちょっと影が薄い（？）Mapping くん、有効に活用していきたい所存です。\n\n## 参考文献\n\n* https://peps.python.org/pep-0589/\n* https://stackoverflow.com/questions/73242556/typeddict-class-is-an-incompatible-type-for-function-expecting-dict\n\nRobustness Principle 的にも Mapping を使うようにした方がいいかも\n","tags":[{"name":"Python","ref":"/tags/python"}],"showTerminalAside":false},{"title":"リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半","date":"2023-02-04T00:00:00.000Z","ref":"/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. [単体テストの目的・定義・学派・","draft":false,"content":"\n[『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）](https://book.mynavi.jp/ec/products/detail/id=134252)を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. [単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部](/posts/2023/01/unit-testing-principles-practices-and-patterns-part1)\n1. リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半（この記事）\n1. [ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-2)\n1. [プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部](/posts/2023/02/unit-testing-principles-practices-and-patterns-part3)\n\n今回は第2部「単体テストとその価値」の前半についての感想と考察になります。第2部は以下の4章で構成されていますが、今回は前半の第4章と第5章について扱います。\n\n* 第4章：良い単体テストを構成する4本の柱\n* 第5章：モックの利用とテストの壊れやすさ\n\n**2023-02-18 更新：記事のスタイルを修正しました。**\n\n## リファクタリングへの耐性を持つことが常に必要\n\n\u003e 良い単体テストを構成するものとして、次の4本の柱があります：\n\u003e * 退行（regression）に対する保護\n\u003e * リファクタリングへの耐性\n\u003e * 迅速なフィードバック\n\u003e * 保守のしやすさ\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）p.96 より引用。_\n\n今回読んだ範囲では「良い単体テストを構成する4本の柱」について説明されていましたが、その中でも一貫して重要視されていたのが2本目の柱**リファクタリングへの耐性**です。リファクタリングへの耐性は常に最大限にしつつ、同時に成り立たない**退行に対する保護**と**迅速なフィードバック**については、テストの種類ごとにどちらを優先するか決めることが推奨されています（p.125）。\n\n![fig 4.12](//www.plantuml.com/plantuml/png/LP3DIiD058NtUOfPraKsNOjqqwSmBiRajWRh59BfVdvGKbG8Y611aQ9Gg6WL4HMYUPZRr6JLLt2Q22QB6MQutptdS3eXfm4V7Gsi5kevwajKKrGBL6dvVKNrZF83vLCkufMOEMoTHAjhaTtFYacCyW7b1DNfEXbl4HgI07hKvSF0QXL2vDCp0pWiMtnNr3AzoH_V_y1-067e3vdLojFZGjoYd3kizBz3dQ0UeuvHQvEbNEW1UFlKFRG2S3bb_G6GRhkB-WJL9-feWq0RQjEVjvSiZXg0pxYnfTouri3i_6hvTT40Hypdrdz4icsNukOGkw5IUnExMjjSnDwf1wuw8VRkWUzvmFQQ6XrWdkd_5m00)\n\nリファクタリングへの耐性を持たせるためのコツは「観測可能な振る舞い」のみをテストし、それを得るまでの過程は見ない（how ではなく what をみる）ということです（pp.127-128）。そのため E2E テストは退行に対する保護を最大限に備えていると言えます。私が所属するチームでも E2E テストのことを普段「リグレッション・テスト」と呼んでおり、その通りだなと思いました。\n\n一方で E2E テストには実行時間が長くかかってしまうので、E2E テストだけで開発を行うのは厳しいです。しかしながら、著者は第5章で「システム内コミュニケーションは実装の詳細になります」と言い、観測可能な振る舞いではない（テストで見るべき最終的な結果ではない）としています。\n\n\u003e * **アプリケーション・サービスに対するテスト・ケースはビジネスにおける全体的なユースケースがいかに実行されるのかを検証する**のに対し、**ドメイン・クラスに対するテスト・ケースは同じユース・ケースが完了に至るまでの一部を検証する**ことになる\n\u003e   * ![fig 5.10](//www.plantuml.com/plantuml/png/SoWkIImgAStDuIfAJIv9p4lFILLGUhfasilc5O-RrZzkNlcuQSdZfaMFcpS_RkvGKaWiLaZEoKpDAq5M3fQV_hXvrUEcZO-RzpnkslwuUJbOn-x7JLj18isJ7pVj1EikJYqgoqnEHT7UtFcuUI7G7eWMcBKx3S4QKl9p4pFp38dHO8IamOWBuau5tPJyyZnTEvZ52bOAIizdhtksOkRxFHsFcvU1tRiJRCf62FlzdaubBfXgtT82e5weKJ1Hc9amjo7CVDouxicE1c3OAN51vQ0cG7NYCC48Zmb6Q2OufEQb0ACB0000)\n\u003e * システム内コミュニケーションとシステム間コミュニケーション\n\u003e   * **システム内コミュニケーションは実装の詳細になります**。その理由は、クライアントからのリクエストを処理する際、ドメイン・クラス間で行われるやり取りは観測可能な振る舞いの一部にはならないからです\n\u003e   * システム間コミュニケーションの場合は違います。なぜなら、テスト対象のアプリケーションがどのように外部とのコミュニケーションを取るのか、ということはそのシステムの観測可能な振る舞い全体を形成するものだからです\n\u003e * **外部から観察できないプロセス外依存とのコミュニケーションは実装の詳細になる**\n\u003e   * もし、データベースに対してテスト対象のアプリケーションを除くすべてのアプリケーションからアクセスされることが決してないのであれば、テスト対象のアプリケーションとデータベースのコミュニケーションに関する仕様を（既存の機能を破綻させない限り）好きなように変えられることになります\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）pp.153-164より引用し箇条書きにまとめた。太字は筆者によるもの。図は筆者作成。_\n\nそうなるとほとんどやっていることは E2E テストと同じなので単体テストの範疇ではない気がします。これは明らかな矛盾ですが、ここについては第6・7章で説明してくれるようなので続きを楽しみにしたいと思います。\n\nまた、単体テストがカバーする範囲を広くしすぎると p-r をレビューする時に、対象のコードが問題ないかの判断をするのが難しくなるのではないかな？という疑問点が浮かんできました。テスト粒度のバランスについても以降の章で説明があるのを期待しています。\n\n## モックとスタブ\n\n\u003e * **モック**：モック、スパイ\n\u003e   * テスト対象システムからその依存に向かって行われる**外部に向かうコミュニケーション（出力）を模倣**し、そして、**検証する**\n\u003e   * スパイはモックと同じ役割を担う\n\u003e     * モックはモック・フレームワークの助けを借りて生成される\n\u003e     * スパイは開発者自身の手で実装される\n\u003e * **スタブ**：スタブ、ダミー、フェイク\n\u003e   * 依存からテスト対象システムに向かって行われる**内部に向かうコミュニケーション（入力）を模倣**\n\u003e   * ダミーとは、null値や一時しのぎで使われる文字列などのシンプルなハード・コーディングされた値のこと\n\u003e   * スタブはもっと洗練されており、設定によって返す結果を異なるシナリオごとに変えられる完全に自立した依存として振る舞うもの\n\u003e   * フェイクと使う目的はスタブの場合とほぼ同じである一方、通常、フェイクはまだ存在しない依存を置き換えるために作成される\n\n_『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）pp.132-134 より引用し箇条書きにまとめた。太字は筆者によるもの。_\n\nモックに関連して5つの用語が出てきました。モック・スパイ・スタブ・ダミー・フェイクです。正直、これらの役割のものは全部モックだと思っていました。言葉の意味を知ったからには意識して使い分けていこうと思います。\n\nここで重要だと思ったのは「スタブとのやりとりを決して検証してはならない」という点です。\n\nリファクタリングへの耐性の話でも出てきたように、観測可能な振る舞いのみをテストするべきということと一貫して、テスト対象システムが持ってくる値を検証することは、テスト対象システムの実装の詳細（how）を調べることになり、過剰検証となります。\n\n今まで実装してきた単体テストを思い返してみて、これをやってしまっていることはあまりないとは思いますが、うっかりするとやってしまいそうなので意識していきたいです。\n\n## まとめ\n\n以上、第2部「単体テストとその価値」の前半についてのまとめと所感を拙文ながら書きました。気づきが多いので、自分が携わるコードでもこの本で得た知識を導入しようと試みています。早く全部読み切らなきゃ。ではでは。\n","tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部","date":"2023-01-17T00:00:00.000Z","ref":"/posts/2023/01/unit-testing-principles-practices-and-patterns-part1","desc":" 『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. 単体テストの目的・定義・学派・命","draft":false,"content":"\n[『単体テストの考え方／使い方』（Vladimir Khorikov 著、須田智之訳）](https://book.mynavi.jp/ec/products/detail/id=134252)を読んでいるので、そのまとめを部ごとに書いていこうと思います。\n\n1. 単体テストの目的・定義・学派・命名について：単体テストの考え方／使い方 第1部（この記事）\n1. [リファクタリングしやすいテストを書こう：単体テストの考え方／使い方 第2部前半](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-1)\n1. [ビジネス・ロジックと連携の指揮を分離すれば良いテストが書ける：単体テストの考え方／使い方 第2部後半](/posts/2023/02/unit-testing-principles-practices-and-patterns-part2-2)\n1. [プロセス外依存は統合テストで確認しよう：単体テストの考え方／使い方 第3部](/posts/2023/02/unit-testing-principles-practices-and-patterns-part3)\n\n今回は第1部「単体（unit）テストとは」についての感想と考察になります。第1部は以下の3章で構成されています。\n\n* 第1章：なぜ、単体（unit）テストを行うのか？\n* 第2章：単体テストとは何か？\n* 第3章：単体テストの構造的解析\n\n**2023-02-18 更新：記事のスタイルを修正しました。**\n\n## 本を読む前のテストに対する認識\n\nまず前提として、本を読む前の私のテストに対する認識をまとめます。\n\n* 単体テストは普段から書いている\n  * Python と [pytest](https://docs.pytest.org/en/7.2.x/) を使用\n  * カバレッジは100%にしようというチームのルールがある\n  * CI パイプラインに組み込まれている\n* モックの使い方にいまいち自信がない\n  * 自作自演になっている気がする時がある\n* データベースのテストはやるべきか迷う\n* ラージテスト・スモールテスト、統合テスト、退行テストなどの用語の正確な意味や使い分けを知らない\n* TDD について勉強したことはない\n\n上記のような感じで、あらためて振り返るとテストに関して自分がなんとなくやってきたことがさらけ出されてしまいました。今回の本では、私のようなレベルの読者でも引っかかることなく親切に解説されています。\n\n## 古典学派 vs ロンドン学派\n\n学びは色々とあるのですが、まず知ったのは「古典学派」と「ロンドン学派」がある、ということです。古典学派は[『テスト駆動開発』（Kent Beck 著、和田卓人訳）](https://www.ohmsha.co.jp/book/9784274217883/)を原点としています。ロンドン学派はロンドンのプログラミング・コミュニティで生まれたことに由来しています（p.28）。ロンドン学派は1単位のコードをテストするために、テスト対象以外の依存はモックを使うようにするべきと考えていて、古典学派は1単位の振る舞いをテストするために、単体テスト同士が状態を共有する依存に対してのみモックを使うべきと考えています（p.52）。\n\n私の所属するチームでは明確にどちらの学派の主張を採用しているわけではありませんが、どちらかというとロンドン学派に近いように感じました。各メソッドを「1単位のコード」と見て、単体テストを書いています。モックに関してはロンドン学派ほど厳格ではないですが、例えば lib は lib で単体テストを行っているという理由で、lib の呼び出し側に対する単体テストでは lib をモックするというようなケースはしばしばあります。\n\n著者が指摘する通り、私のコードベースでは1つをリファクタするとそのテストや周辺のテストも直さないといけないので、これは維持コストのかかる良くないテストコードなのかも、ということに気づきました。\n\n## テスト・フィクスチャ\n\n第3章の「テスト・フィクスチャの準備」についての議論も興味深かったです。本の中ではコンストラクタを使って繰り返し同じ記述を書くことを避けることに関して、「テスト・ケースが読みづらくなってしまう」ことに言及しています（p.73）。\n\n私はテストクラスでコンストラクタを使うことはあまり多くないですが、[pytest.fixture を autouse=True にする](https://docs.pytest.org/en/7.2.x/how-to/fixtures.html#autouse-fixtures-fixtures-you-don-t-have-to-request)ことは多いです。コードの量を削減できる一方で、これも多用しすぎるとテストコードが読みにくくなってしまうので気を付けたいと思いました。\n\n## 命名規則\n\n命名規則に関しては以下のようなルールを設けています。前提として、テスト対象のメソッドに対して、テストクラスを1つ作るルールになっています。下記の命名はそのテストクラスのメソッド名に対するものです。\n\n* 正常系\n  * `test_success` もしくは `test_success_{事前条件}`\n    * e.g. `test_success_when_hoge_is_fuga`\n* 異常系\n  * `test_failure_{事前条件}`\n    * e.g. `test_failure_when_hoge_is_invalid`\n\n本ではよくある（そして役に立たない）命名規則の例として `{テスト対象メソッド}_{事前条件}_{想定する結果}` というものが挙げられていますが（p.77）、私のチームでもテスト対象メソッドごとにテストクラスを作っている時点で、想定する結果（success/failure）や事前条件（when～）もあるので、これに該当してしまっていると思いました。\n\nただ、これに関しては私自身そこまで悪いとは思っていません。ルールがあるといっても、頭に `test_success` `test_failure` をつけているだけですし、この程度ならむしろ見やすくて良いと思います。しかしながら、そもそもこのテストクラスの作り方の枠組み自体が、振る舞いよりもコードの実装に目が行くものなのは確かなので、この点に関しては本の続きを読みながらより良くしていくためにどうするべきかを考えていきたいと思っています。\n\n## まとめ\n\n以上、第1部「単体（unit）テストとは」についてのまとめと所感を拙文ながら書きました。\n\nまだ途中ですが、読みやすく面白い予感なので、気になった方は是非本を手に取って読んでみてください！\n","tags":[{"name":"単体テスト","ref":"/tags/単体テスト"},{"name":"読書","ref":"/tags/読書"}],"showTerminalAside":false},{"title":"SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ","date":"2023-01-12T00:00:00.000Z","ref":"/posts/2023/01/sqlalchemy-dealing-with-disconnects","desc":" FastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2","draft":false,"content":"\nFastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2.1.1\n\n## 問題\n\n```\nMySQLdb.OperationalError: (2006, 'MySQL server has gone away')\n```\n\n最後に MySQL サーバーに接続してから一定時間（デフォルトで8時間）が経過すると上記のエラーにより DB へのアクセスに失敗します。\n\n## 原因\n\nSQLAlchemy には Connection Pooling という、DB サーバーとのコネクションを内部的に保持する機能が存在します。また、MySQL には一定時間（デフォルトで8時間）が経過するとコネクションを破棄する機能が存在します。\n\nその結果、SQLAlchemy 側で保持しているコネクションを使ってクエリを投げたりしても、MySQL 側でコネクションが破棄されている場合には `MySQL server has gone away` のエラーが出てしまうことになります。\n\n`show global variables like 'wait_timeout';` によって、現在設定されている `wait_timeout` の秒数を知ることができます。\n\n```\nmysql\u003e show global variables like 'wait_timeout';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| wait_timeout  | 28800 |\n+---------------+-------+\n1 row in set (0.00 sec)\n```\n\n生きているコネクションは `show processlist` で知ることができます。`Time` が経過時間（秒）です。\n\n```\nmysql\u003e show processlist;\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n| Id      | User  | Host            | db   | Command | Time  | State    | Info             |\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n| 1200000 | scott | localhost:47000 | test | Query   |     0 | starting | show processlist |\n| 1200001 | scott | localhost:47001 | test | Sleep   |  3600 |          | NULL             |\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n2 rows in set (0.00 sec)\n```\n\n## 解決方法\n\n[SQLAlchemy の公式ドキュメント](https://docs.sqlalchemy.org/en/20/core/pooling.html#dealing-with-disconnects)に書かれているように、大きく「悲観的」「楽観的」2つのアプローチがあります。\n\nどちらを採用するかは要件や好みによると思います。どちらの方法にしても、コネクションプールからチェックアウトした後に MySQL 側で破棄されてしまうようなケースでは無効なのでご注意ください（一度の処理でそんなに長く扱うことは少ないとは思いますが）。\n\n### 悲観的アプローチ\n\nコネクションプールから取り出すときに、そのコネクションがまだ生きているかどうかをテストする方法です。私は今回こちらを採用しました。\n\nコネクションのチェックアウト時に若干のオーバーヘッドができてしまいますが、最もシンプルで信頼できるアプローチとされています。\n\n```py\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+mysqldb://scott:tiger@localhost/test\", pool_pre_ping=True)\n```\n\n### 楽観的アプローチ\n\n一定時間ごとにコネクションを張り直す方法です。例えば、DB サーバー側で28800秒に設定されているのならば、それよりも短く設定すればよいです。\n\n使っていても使っていなくても一定時間おきに DB へのリクエストが飛んでしまいますが、コネクションのチェックアウト時にオーバーヘッドが発生しないのが利点です。\n\n```py\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+mysqldb://scott:tiger@localhost/test\", pool_recycle=3600)\n```\n\n## 参考文献\n\n* [Connection Pooling](https://docs.sqlalchemy.org/en/20/core/pooling.html)\n* [Python: SQLAlchemy で 'MySQL server has gone away' になる問題を解決する](https://blog.amedama.jp/entry/2015/08/15/133322)\n* [full-stack-fastapi-postgresql/session.py at master · tiangolo/full-stack-fastapi-postgresql](https://github.com/tiangolo/full-stack-fastapi-postgresql/blob/master/%7B%7Bcookiecutter.project_slug%7D%7D/backend/app/app/db/session.py)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"}],"showTerminalAside":false},{"title":"2023年版 キーボードマッピングの個人的メモ","date":"2023-01-08T00:00:00.000Z","ref":"/posts/2023/01/keyboard-remap","desc":" 不定期的に「あーでもない、こーでもない」と言ってキーボードのマッピングをいじりだしてしまうことってありますよね。私はあります。限りあるキーの中から自分にとっての最適解を見つける作業はなんだかんだ楽しいです。\n\n今回は 2023 年版、私のキーボードのマッピングを書きとめておこうと思います。\n\n過去","draft":false,"content":"\n不定期的に「あーでもない、こーでもない」と言ってキーボードのマッピングをいじりだしてしまうことってありますよね。私はあります。限りあるキーの中から自分にとっての最適解を見つける作業はなんだかんだ楽しいです。\n\n今回は 2023 年版、私のキーボードのマッピングを書きとめておこうと思います。\n\n過去の記事: [Windows10 と PowerToys で US キーボードでも無変換・変換キーを使って IME を一発で切り替える](https://qiita.com/SogoK/items/7e0ea37c3e958c39608c)\n\n## 環境\n\n* 使うパソコン\n  * Windows デスクトップ\n  * Windows ラップトップ\n  * MacBook Air (2022)\n* 使うキーボード\n  * HHKB（US 配列）\n  * MacBook Air 内蔵キーボード（US 配列）\n\n仕事は Windows ラップトップ + HHKB なので、この組み合わせで作業する時間が一番長いです。MacBook Air で作業する時は基本的には内蔵キーボードを使いますが、HHKB を接続することもしばしばあります。\n\n## 結論\n\n結局仕事でパソコンを触る時間の方が長いので、Windows + HHKB の組み合わせで使う状況を優先しました。\n\n- HHKB なので、`Control` は `Caps Lock` の位置\n- スペースキーの左右はそれぞれ Mac の `英数` `かな` キーにする\n  - Windows でも Mac の `英数` `かな` キーをちゃんと認識して IME の切り替えをやってくれる\n  - なので過去記事で紹介した PowerToys を使用したハックは不要\n- 上記によってスペースキー左右の `Windows/Command` キーが消えてしまうので、`左 Alt/Option` を `Windows/Command` にする\n- Mac では Karabiner Elements を使用して Windows での操作感に寄せていく\n  - Mac の `Command` と Windows の `Control` が同じ位置に来るようにする\n\n## 実現方法\n\n使うツールは以下の 2 つです。\n\n- [Happy Hacking Keyboard キーマップ変更ツール](https://happyhackingkb.com/jp/download/)\n- [Karabiner Elements](https://karabiner-elements.pqrs.org/)\n\n### Happy Hacking Keyboard キーマップ変更ツール\n\n![HHKB](/images/posts/2023/01/keyboard_hhkb_remap.png)\n\n変更点としては\n\n- `左♢` を `英数` に\n- `右♢` を `かな` に\n- `左 Alt/Option` を `Control` に\n\nこれによって Windows でも Mac でもスペースキーの左を押せば英字入力、スペースキーの右を押せばかな入力にモードを切り替えられます。今となってはこれ以外の IME 切り替え方法は面倒すぎて耐えられません。\n\nそして、この変更によって `♢` が消滅したので `Windows/Command` キーが使えなくなってしまいます。そのため `左 Alt/Option` を `♢` に変更します。`Alt/Option` は左右にあるのでどちらを変更してもいいのですが、個人的には `Windows + Shift + S`（スクリーンショット）や、（Mac では `Command` と `Control` を入れ替えるため）`Control + C` の組み合わせなどが左手だけで押せた方が便利なので、左側を `♢` にしました。  \n本当は左側の `Alt/Option` もあるのが理想なのですが、`Alt/Option` を使うのは VS Code で複数行選択するときがほとんどなので、マウスとの組み合わせですしまだなんとかなると判断しました。\n\nWindows でも Mac でも DIP スイッチは変更せずに、常に同じモードで使います。DIP スイッチについては[公式ページ](https://happyhackingkb.com/jp/products/discontinued/hhkb_backview.html)を参照ください。\n\n| キー | ON/OFF |\n| ---- | ------ |\n| SW1  | OFF    |\n| SW2  | OFF    |\n| SW3  | ON     |\n| SW4  | OFF    |\n| SW5  | OFF    |\n\n参考: HHKB のデフォルトのキー配列\n\n![HHKB のデフォルトのキー配列](https://happyhackingkb.com/jp/products/image/leaflet/pro_keytop_a_l.jpg)\n\n### Karabiner Elements（基本的な設定）\n\nWindows では OS 側での設定は特に行わず、HHKB に書き込んだ設定のみで使用します。  \nここから、Mac で Windows での操作感に寄せていくための調整をやっていきます。\n\n#### 修飾キーを入れ替える\n\nまず、修飾キーを入れ替えていきます。修飾キーの入れ替えは Mac の標準機能で実現できるのですが、ツール統一の観点から Karabiner Elements で実施します。\n\nMac の内蔵キーボード（US 配列）の `Caps Lock` を HHKB 風に Windows での `Control` 相当である `Command` にします。\n\n![内蔵キーボード](/images/posts/2023/01/keyboard_ke_internal.png)\n\nHHKB の `左 Command` と `左 Control` を入れ替えます。これにより、一般的に `Caps Lock` の位置のキーが `Command` になります。一番手前の列の左端が `Control` です。\n\n![HHKB](/images/posts/2023/01/keyboard_ke_hhkb.png)\n\n#### Mac 内蔵キーボードの左右 `Command` を `英数` `かな` にする\n\nKarabiner Elements の `Complex Modifications` → `Add rule` → `Import more rules from the Internet (Open a web browser)` と進みます。\n\n[https://ke-complex-modifications.pqrs.org/](https://ke-complex-modifications.pqrs.org/) が開くので、`RDP for Japanese, US Keyboard （リモートデスクトップとUSキーボード、日本語環境の設定）` を import します。リモートデスクトップを使わなければ `For Japanese （日本語環境向けの設定） (rev 6)` でも OK です。\n\n`[RDP] RDPアプリ以外では、コマンドキーを単体で押したときに、英数・かなキーを送信する。（左コマンドキーは英数、右コマンドキーはかな） (rev 3)`（`コマンドキーを単体で押したときに、英数・かなキーを送信する。（左コマンドキーは英数、右コマンドキーはかな） (rev 3)`）のルールを追加します。\n\nこれにより、HHKB での `英数` `かな` と同じ機能が実現します。本来の位置の左右 `Command` も単押しでなければ引き続き利用可能です。\n\n### Karabiner Elements（細かい設定）\n\n上記の設定で基本的には OK ですが、まだ細かいところで違いがあるので合わせていきます。\n\n#### `Home` `End` キーで行端に移動する\n\n先ほどと同じように、今度は `PC-Style Shortcuts` を探して import します。\n\n`Home key to the beginning of the line (Control + a)` および `End key to the end of the line (Control + e)` のルールを追加します。\n\n#### 日本語入力時の `Control + T/U/I/O/P` を復活させる\n\nHHKB で日本語を入力している方なら使っていることも多いと思われる `Control + T/U/I/O/P` というショートカットがあります。Windows で使えるショートカットですが、Mac でも `Windows 風のキー操作` を有効にすることで使えます。\n\n![Mac IME](/images/posts/2023/01/keyboard_mac_ime.png)\n\n| Windows ショートカット | Mac ショートカット         | 変換先   | F キー |\n| ---------------------- | -------------------------- | -------- | ------ |\n| Control + T            | Control + T                | 半角英数 | F10    |\n| Control + U            | Control + U                | 全角かな | F6     |\n| Control + I            | Control + I                | 全角カナ | F7     |\n| Control + O            | 不明 (Option + A は使えた) | 半角ｶﾅ   | F10    |\n| Control + P            | Control + P                | 全角英数 | F9     |\n\nこれらに関しては、半角ｶﾅを除いて、どちらも `Control` なので、`Caps Lock` 位置に Windows では `Control` を、Mac では `Command` を置く運用だと位置がずれてしまいます。\n\nなので、`Command + T/U/I/O/P` で、Windows と同じような動作をするように変更します。なぜか `Control + O` だけ Windows と互換性がない（半角英数になってしまう）ので、`Option + A` にします。\n\n試してみたい方は [japanese_cmd_tuiop.json](https://raw.githubusercontent.com/SogoKato/KE-complex_modifications/feature/cmd-tuiop/public/json/japanese_cmd_tuiop.json) をダウンロードして `~/.config/karabiner/assets/complex_modifications` ディレクトリ内に保存してください。\n\n（使ってみて安定していたらプルリクを出そうと思います）\n\n上記をすべて設定するとこんな感じです。\n\n![complex modifications](/images/posts/2023/01/keyboard_ke_complex.png)\n\n## 最後に\n\n以上が、2023年版 私のキーボードマッピングでした。多分向こう半年くらいはこの設定で行くと思います。ではでは。\n","tags":[{"name":"キーボード","ref":"/tags/キーボード"}],"showTerminalAside":false},{"title":"プロキシ環境でKubernetes構築（Containerd+Calico）","date":"2022-12-27T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-behind-proxy","desc":" 同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4","draft":false,"content":"\n同期と一緒にトラシュしたので、プロキシ環境下で kubeadm + Containerd + Calico の Kubernetes クラスターを構築する方法について記録を残します。\n\n## 環境\n\n* Ubuntu 22.04\n  * サーバーはニフクラを利用（e-medium4 2vCPU/4GB）\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.14\n* Calico v3.24.5\n\nコントロールプレーン、ノード1台ずつの構成とします。プロキシを経由しなければインターネットに出られないようになっています。\n\n![network](//www.plantuml.com/plantuml/png/SoWkIImgAStDuSehJybCJ5Uevb9Go4ijASylobP8pybFIim12O51KNvfIMgHDP1NYwIee2YpBB4a5QugCIMbABMuMC5MGSdGt4ZFs53FGCz0tz1CoPeBnHo5Q6mg3PLYhQ7AalFpIehoSmfo4lDIOM9v-Icf40VKSZcavgK07Gu0)\n\nプライベートネットワークの CIDR は `172.31.0.0/16`、プロキシは `http://172.31.0.1:3128` として進めます。\n\nService CIDR はデフォルトの `10.96.0.0/12` を、Pod Network CIDR は Calico のデフォルトである `192.168.0.0/16` を使います。\n\n💡 筆者の環境ではこの記事で紹介する内容で構築できましたが、環境によって状況が異なる可能性があります。プロキシ配下での構築に挑戦する前に、**まずは似た環境のインターネット接続があるサーバーで試すことをおすすめします**。\n\n## プロキシの設定が必要な箇所\n\n### 環境変数（`~/.bashrc`）\n\n#### コントロールプレーン\n\n```sh\nexport HTTP_PROXY=http://172.31.0.1:3128\nexport HTTPS_PROXY=http://172.31.0.1:3128\nexport NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12,192.168.0.0/16\n```\n\nコントロールプレーンでは `NO_PROXY` に Sercice CIDR の IP レンジ（デフォルトは `10.96.0.0/12`）と Pod Network CIDR の IP レンジを設定しておくことで `kubeadm init` 時の preflight check の WARNING を抑えることができます[^1]。\n\n反映するには `source ~/.bashrc` します。\n\n[^1]: 以前は IP レンジを指定できなかったようですが、今は問題なく使えます。https://github.com/kubernetes/kubeadm/issues/324#issuecomment-331483277\n\n#### ノード\n\n```sh\nexport HTTP_PROXY=http://172.31.0.1:3128\nexport HTTPS_PROXY=http://172.31.0.1:3128\nexport NO_PROXY=localhost,127.0.0.1,172.31.0.0/16\n```\n\nノードでは `kubeadm init` を実行しないのでこれだけで OK。\n\n### `/etc/apt/apt.conf`\n\n各種ライブラリのインストールのために必要です。\n\n```\nAcquire::http::proxy \"http://172.31.0.1:3128\";\nAcquire::https::proxy \"http://172.31.0.1:3128\";\n```\n\n### `/etc/systemd/system/containerd.service.d/http-proxy.conf`\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12\"\n```\n\n`NO_PROXY` に Pod Network CIDR の IP レンジも追加しようかと思ったのですが、ノードを跨いだ Pod 間の通信など試した範囲では追加しなくても異常がなかったので追加していません。  \n筆者の Kubernetes の知識が浅いだけかもしれないので、検証不足でしたら教えていただけるとありがたいです。🙇\n\nこのファイルを変更したら Containerd の再起動が必要です。\n\n```sh\nsystemctl daemon-reload\nsystemctl restart containerd\n```\n\n## 構築手順\n\n上記のプロキシ設定以外は通常の手順と同じです。\n\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n\nUbuntu 22.04 で構築する際の注意点については [Ubuntu 22.04でのKubernetesクラスター構築（ContainerdとSystemdCgroup）](/posts/2022/12/kubernetes-ubuntu22.04-cgroup-systemd) をご参照ください。\n\n```sh\nkubeadm init --pod-network-cidr 192.168.0.0/16\n```\n\n### ネットワークプラグインの適用\n\n構築が完了したらネットワークプラグインを適用します。以下は Calico を使う場合のコマンドです。\n\n```sh\ncurl https://raw.githubusercontent.com/projectcalico/calico/v3.24.5/manifests/calico.yaml -O\nkubectl apply -f calico.yaml\n```\n\n`kubectl -n kube-system get po -w` して、1つの `calico-kube-controllers` とノード数分の `calico-node` Pod が Running なら問題ありません。CoreDNS がクラッシュするバグを踏んだら [KubernetesでCoreDNSがループしてしまう問題への対処](/posts/2022/12/kubernetes-coredns-loop) の記事を参考にしてみてください。\n\n## 動作確認\n\n簡単な動作確認をしてみます。\n\n```sh\nkubectl create deployment nginx --image=nginx\n```\n\n```sh\nPOD_NAME=$(kubectl get pods -l app=nginx -o jsonpath=\"{.items[0].metadata.name}\")\n```\n\n別のシェルを開き、`curl localhost:8080` を試してみます。\n\n```sh\nkubectl port-forward $POD_NAME 8080:80\n```\n\nログを見てみます。\n\n```sh\nkubectl logs $POD_NAME\n```\n\nexec を試します。\n\n```sh\nkubectl exec -ti $POD_NAME -- nginx -v\n```\n\nNodePort Service を試します。\n\n```sh\nkubectl expose deployment nginx --port 80 --type NodePort\n```\n\n```sh\nNODE_PORT=$(kubectl get svc nginx \\\n  --output=jsonpath='{range .spec.ports[0]}{.nodePort}')\n```\n\n```sh\ncurl 127.0.0.1:$NODE_PORT\n```\n\n```sh\nkubectl delete svc nginx\n```\n\n次に Cluster IP Service を試します。\n\n```sh\nkubectl expose deployment nginx --port 80 --type ClusterIP\n```\n\nクライアントを想定した Pod を建てます（nginx ですが）。\n\n```sh\nkubectl create deployment client --image=nginx\n```\n\n```sh\nPOD_NAME_CLIENT=$(kubectl get pods -l app=client -o jsonpath=\"{.items[0].metadata.name}\")\n```\n\nPod 内で `curl nginx` を実行します。\n\n```sh\nkubectl exec -ti $POD_NAME_CLIENT -- curl nginx\n```\n\n`\u003eWelcome to nginx!` の HTML が返ってこれば OK！\n\n## トラブルシューティング集\n\n### `FailedCreatePodSandBox` - ホストのプライベート IP にアクセス不可\n\n`calico-kube-controllers` が ContainerCreating で止まってしまう問題が発生しました。\n\n```\nEvents:\n  Type     Reason                  Age                 From               Message\n  ----     ------                  ----                ----               -------\n  Warning  FailedScheduling        115s                default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling..\n  Normal   Scheduled               104s                default-scheduler  Successfully assigned kube-system/calico-kube-controllers-7bdbfc669-97wdp to controlplane\n  Warning  FailedCreatePodSandBox  103s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox \"6a029253befac6840d358f8f78b865510bb3874b971fc7241d4ded6b1e92ce2d\": plugin type=\"calico\" failed (add): stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/\n  Normal   SandboxChanged          16s (x3 over 103s)  kubelet            Pod sandbox changed, it will be killed and re-created.\n```\n\n`stat /var/lib/calico/nodename: no such file or directory: check that the calico/node container is running and has mounted /var/lib/calico/` のエラーメッセージが出ていますが、実際にはマウントはできていました。\n\n「マウントはできて nodename（ホスト名）は取得できているが、プロキシに阻まれて通信できていないのでは？」と考え、Containerd の NO_PROXY の設定にホストのプライベートネットワークの CIDR を追記したら `172.31.0.0/16` たらこの問題は解決しました。\n\n```\n# vim /etc/systemd/system/containerd.service.d/http-proxy.conf\n```\n\n`172.31.0.0/16` を追記。\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16\"\n```\n\n```\n# systemctl daemon-reload\n# systemctl restart containerd\n# kubectl -n kube-system delete po calico-kube-controllers-7bdbfc669-97wdp --force\nWarning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\npod \"calico-kube-controllers-7bdbfc669-97wdp\" force deleted\n```\n\n### `FailedCreatePodSandBox` - Service の IP にアクセス不可\n\n状況は変わったものの、こちらも `calico-kube-controllers` が ContainerCreating で止まってしまう問題です。\n\n```\nEvents:\n  Type     Reason                  Age                From               Message\n  ----     ------                  ----               ----               -------\n  Normal   Scheduled               3m12s              default-scheduler  Successfully assigned kube-system/calico-kube-controllers-7bdbfc669-9gltp to controlplane\n  Warning  FailedCreatePodSandBox  72s                kubelet            Failed to create pod sandbox: rpc error: code = Unknown desc = failed to setup network for sandbox \"68070146a6bd3c3a3044cbe84495c39ef3abafd069f171db2a185c8925aee2d1\": plugin type=\"calico\" failed (add): error getting ClusterInformation: Get \"https://10.96.0.1:443/apis/crd.projectcalico.org/v1/clusterinformations/default\": Service Unavailable\n  Normal   SandboxChanged          12s (x2 over 72s)  kubelet            Pod sandbox changed, it will be killed and re-created.\n```\n\nこちらはエラーメッセージの通りなので、Service CIDR を Containerd の NO_PROXY に追加します。\n\n```\n# vim /etc/systemd/system/containerd.service.d/http-proxy.conf\n```\n\n`10.96.0.0/12` を追記。\n\n```\n[Service]\nEnvironment=\"HTTP_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"HTTPS_PROXY=http://172.31.0.1:3128\"\nEnvironment=\"NO_PROXY=localhost,127.0.0.1,172.31.0.0/16,10.96.0.0/12\"\n```\n\n先ほどと同じように daemon-reload, restart containerd, Pod の強制削除をします。\n\n## まとめ\n\n最後までお読みいただきありがとうございます。\n\nプロキシ環境での Kubernetes クラスター構築は、通常のクラスター構築よりも Kubernetes のネットワーク周りの知識が要求されるので少しハードルが上がります。\n\n冒頭にも書きましたが、まずはインターネットに直接繋がる環境で構築を試してみて、その後にプロキシ環境での構築を実施すると原因の切り分けがスムーズになると思います。\n\n## 参考文献\n\n* [Installing kubernetes behind a corporate proxy](https://medium.com/@vivekanand.poojari/installing-kubernetes-behind-a-corporate-proxy-bc5582e43fb8)\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [CRIのインストール](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n* [Install Calico networking and network policy for on-premises deployments](https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises)\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false},{"title":"Ubuntu 22.04でのKubernetesクラスター構築（ContainerdとSystemdCgroup）","date":"2022-12-26T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-ubuntu22.04-cgroup-systemd","desc":" 公式ドキュメントのコマンドを手順通り流し込めば割と簡単に構築できる Kubernetes クラスターですが、Ubuntu 22.04 になってから少し手を入れる必要が出てきたので差分を紹介しておきます。\n\n**2022-02-16 更新：Kubernetes ドキュメントの日本語版が更新されていた","draft":false,"content":"\n公式ドキュメントのコマンドを手順通り流し込めば割と簡単に構築できる Kubernetes クラスターですが、Ubuntu 22.04 になってから少し手を入れる必要が出てきたので差分を紹介しておきます。\n\n**2022-02-16 更新：Kubernetes ドキュメントの日本語版が更新されていたのでリライトしました。**\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n* Containerd v1.6.16\n\n## 何が変わった？\n\nUbuntu 21.10 以降、Cgroup v2 がデフォルトになりました[^1]。  \nCgroup について詳しく知りたい方は [第37回 Linuxカーネルのコンテナ機能 ― cgroupの改良版cgroup v2［1］](https://gihyo.jp/admin/serial/01/linux_containers/0037)の記事がわかりやすいので読んでみてください。\n\nKubernetes においては「cgroupドライバー」を kubelet の設定で選択します。`cgroupfs` ドライバーが v1 に、`systemd` ドライバーが v2 に対応していると考えれば問題ないと思います。\n\n[^1]: https://wiki.ubuntu.com/UbuntuWeeklyNewsletter/Issue697\n\n## 何もしないとどうなる？\n\nコンテナは起動しますが、使い物にならないくらい不安定になり再作成を繰り返します。システムコンポーネントのコンテナ（kube-apiserver）も例外でないので、kubectl を叩いてもレスポンスが返ってこなかったり。。\n\n## 解決方法\n\nCgroup v1 に戻す、というやり方もあるとは思うのですが、systemd を Cgroup ドライバーとして設定すれば Cgroup v2 のままで使えるようになるので、新しくクラスターを構築するのであればそうするのがおすすめです。\n\nkubelet に関しては kubeadm v1.22 以降デフォルトで `systemd` を選択するようになったので[^2]、特に気にする必要はないです。\n\n[^2]: 備考: v1.22 では、ユーザーが KubeletConfiguration の cgroupDriver フィールドを設定していない場合、kubeadm はデフォルトで systemd を設定するようになりました。  \nhttps://kubernetes.io/ja/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/#kubelet-cgroup%E3%83%89%E3%83%A9%E3%82%A4%E3%83%90%E3%83%BC%E3%81%AE%E8%A8%AD%E5%AE%9A\n\n**Containerd を CRI として使用する場合、Containerd 側でも Cgroup ドライバーを選択する必要があります（今回の記事のミソ）。**\n\nLinux の場合、Containerd の設定ファイルは `/etc/containerd/config.toml` にあります。存在しない場合は、下記のコマンドで作成します。\n\n```sh\nmkdir -p /etc/containerd\ncontainerd config default | sudo tee /etc/containerd/config.toml\n```\n\n[Kubernetesドキュメント](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/#systemd-cgroup%E3%83%89%E3%83%A9%E3%82%A4%E3%83%90%E3%83%BC%E3%82%92%E6%A7%8B%E6%88%90%E3%81%99%E3%82%8B)に記載のように `runc` が `systemd` Cgroup ドライバーを使うように設定します。\n\n```toml\n[plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc]\n  ...\n  [plugins.\"io.containerd.grpc.v1.cri\".containerd.runtimes.runc.options]\n    SystemdCgroup = true\n```\n\n以下のコマンドで修正することができます。\n\n```sh\nsed -i 's/SystemdCgroup \\= false/SystemdCgroup \\= true/g' /etc/containerd/config.toml\n```\n\nContainerd を再起動します。\n\n```sh\nsystemctl restart containerd\n```\n\n他の手順は参考文献の上3つのリンク先に記載の手順を実施すれば OK です。\n\nネットワークプラグイン設定後、CoreDNS がクラッシュするバグを踏んだら [KubernetesでCoreDNSがループしてしまう問題への対処](/posts/2022/12/kubernetes-coredns-loop) の記事を参考にしてみてください。\n\n## 参考文献\n\n* [kubeadmを使用したクラスターの作成](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)\n* [kubeadmのインストール](https://kubernetes.io/ja/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)\n* [コンテナランタイム](https://kubernetes.io/ja/docs/setup/production-environment/container-runtimes/)\n* [cgroupドライバーの設定](https://kubernetes.io/ja/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/)\n* [Ubuntu 22.04でkubeadmでKubernetesクラスターが動かない？](https://tech.virtualtech.jp/entry/2022/06/08/115030)\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false},{"title":"KubernetesでCoreDNSがループしてしまう問題への対処","date":"2022-12-24T00:00:00.000Z","ref":"/posts/2022/12/kubernetes-coredns-loop","desc":" 1年前にも Kubernetes クラスターを自力で組んでトラブルシューティングしてみる【The Hard Way】の記事の中で軽く解説したネタです。\n\n## 環境\n\n* Ubuntu 22","draft":false,"content":"\n1年前にも [Kubernetes クラスターを自力で組んでトラブルシューティングしてみる【The Hard Way】](https://qiita.com/SogoK/items/192d475c20e07dd38984)の記事の中で軽く解説したネタです。\n\n## 環境\n\n* Ubuntu 22.04\n* Kubernetes v1.26.0\n* kubeadm v1.26.0\n\n## 問題\n\nKubernetes クラスター内で名前解決に使われる CoreDNS の Pod が `CrashLoopBackOff` になってしまい再起動を繰り返す問題が発生することがあります。\n\n```\n# kubectl -n kube-system logs coredns-787d4945fb-6kb5t\n.:53\n[INFO] plugin/reload: Running configuration SHA512 = 591cf328cccc12bc490481273e738df59329c62c0b729d94e8b61db9961c2fa5f046dd37f1cf888b953814040d180f52594972691cd6ff41be96639138a43908\nCoreDNS-1.9.3\nlinux/amd64, go1.18.2, 45b0a11\n[FATAL] plugin/loop: Loop (127.0.0.1:34129 -\u003e :53) detected for zone \".\", see https://coredns.io/plugins/loop#troubleshooting. Query: \"HINFO 1033981844954998931.6641498229839068582.\"\n```\n\n## 原因\n\nhttps://coredns.io/plugins/loop/#troubleshooting\n\nUbuntu 18.04 以降などの最近のディストリビューションで、ローカルの DNS スタブリゾルバ (systemd-resolved) が使われるようになったことが原因です。Kubelet の設定ファイル `/var/lib/kubelet/config.yaml` を見るとデフォルトでは下記のように設定されています。\n\n```conf\nresolvConf: /run/systemd/resolve/resolv.conf\n```\n\nここで指定されているファイル `/run/systemd/resolve/resolv.conf` が kubelet によって、CoreDNS コンテナに渡されます。デフォルトでは中身は以下のようになっているはずです。\n\n```conf\n# This is /run/systemd/resolve/resolv.conf managed by man:systemd-resolved(8).\n# Do not edit.\n#\n# This file might be symlinked as /etc/resolv.conf. If you're looking at\n# /etc/resolv.conf and seeing this text, you have followed the symlink.\n#\n# This is a dynamic resolv.conf file for connecting local clients directly to\n# all known uplink DNS servers. This file lists all configured search domains.\n#\n# Third party programs should typically not access this file directly, but only\n# through the symlink at /etc/resolv.conf. To manage man:resolv.conf(5) in a\n# different way, replace this symlink by a static file or a different symlink.\n#\n# See man:systemd-resolved.service(8) for details about the supported modes of\n# operation for /etc/resolv.conf.\n\nnameserver 127.0.0.1\nsearch .\n```\n\nOS 上ではスタブリゾルバがいるので `127.0.0.1` を DNS とするように設定されていますが、CoreDNS のコンテナ内ではそのコンテナ自身を指すことになります。結果的にループしてしまい、クラッシュします。\n\n## 解決方法\n\n原因は上記の通りなので、`127.0.0.1` ではない外部の DNS サーバーを設定すれば解決できます。\n\n`/run/systemd/resolve/resolv.conf` は systemd-resolved の管理下にある自動生成ファイルですので、大元の設定ファイル `/etc/systemd/resolved.conf` を修正し、systemd-resolved を再起動することで `/run/systemd/resolve/resolv.conf` を再生成させます。\n\nその後新しい `resolv.conf` の内容を反映させるために kubelet と Container runtime (containerd) を再起動します。\n\n```\nNAMESERVER_ADDRESSES=8.8.8.8\nsed -i \"s/^DNS=127.0.0.1$/DNS=${NAMESERVER_ADDRESSES}/\" /etc/systemd/resolved.conf\nsystemctl restart systemd-resolved\nsystemctl restart kubelet\nsystemctl restart containerd\n```\n\nCoreDNS が無事 Running になれば OK です。\n\n```\nroot@controlplane:~# kubectl -n kube-system get po -w\nNAME                                      READY   STATUS             RESTARTS     AGE\ncalico-kube-controllers-7bdbfc669-w4xxt   1/1     Running            0            2m57s\ncalico-node-2f2qc                         1/1     Running            0            15m\ncoredns-787d4945fb-6kb5t                  0/1     CrashLoopBackOff   5 (7s ago)   16m\ncoredns-787d4945fb-q5bhz                  0/1     CrashLoopBackOff   5 (7s ago)   16m\netcd-controlplane                         1/1     Running            0            16m\nkube-apiserver-controlplane               1/1     Running            0            16m\nkube-controller-manager-controlplane      1/1     Running            0            16m\nkube-proxy-692c8                          1/1     Running            0            16m\nkube-scheduler-controlplane               1/1     Running            0            16m\ncoredns-787d4945fb-6kb5t                  0/1     Running            6 (19s ago)   16m\ncoredns-787d4945fb-6kb5t                  1/1     Running            6 (19s ago)   16m\ncoredns-787d4945fb-q5bhz                  0/1     Running            6 (25s ago)   16m\ncoredns-787d4945fb-q5bhz                  1/1     Running            6 (25s ago)   16m\n```\n","tags":[{"name":"Kubernetes","ref":"/tags/kubernetes"}],"showTerminalAside":false},{"title":"VS Code Serverでリモートホストのコンテナ上開発環境に直接アクセスする","date":"2022-12-17T00:00:00.000Z","ref":"/posts/2022/12/vscode-server-devcontainer","desc":" 今回は「ぼくのかんがえたさいきょうのかいはつかんきょう」を紹介したいと思います。\n\nVS Code Server を使い、リモートサーバー上でコンテナとして動かしている開発環境に直","draft":false,"content":"\n今回は「ぼくのかんがえたさいきょうのかいはつかんきょう」を紹介したいと思います。\n\n[VS Code Server](https://code.visualstudio.com/docs/remote/vscode-server) を使い、リモートサーバー上でコンテナとして動かしている開発環境に直接乗り込んでみよう、というアイデアです。\n\nSSH もポート開放も不要なのでとてもお手軽です。\n\n## 環境\n\nサーバー\n* Raspberry Pi 400 (Ubuntu 22.04.1, arm64)\n  * Docker \u0026 Docker Compose がインストールされていること\n\nクライアント\n* VS Code 1.74.1\n  * [Remote - Tunnels](https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-server) 拡張機能がインストールされていること\n\n払い出された URL にアクセスすればブラウザからでも使えるので、iPad などのモバイル端末でも使えますね。\n\n## ソースコード\n\nhttps://github.com/SogoKato/simple-devenv-py\n\n## アーキテクチャ\n\n![architecture](//www.plantuml.com/plantuml/png/dLAnJiCm4Dtz5QSmPu2vieegPb1JmNnoZjJ2EKU-Isc5-k-ene5q849ikPVttZq_UosAISS-64nkxtjKWfiTkJt74BiJLCyDR69B5Q202vvOORNIRqBTqi4xijQOH4wHkq1GRQcFIl3OLF1X06P_Df4LFLFwCfocJBiYbhtGK3eKjkJFGWNu9V1BJ6yoe2DuE2gn-CXPJKUzlOuk9r7gQucl-ew9hFstyTrVZCzcmRo9OtBqKxNaUKcnezHxnW1FAJeI8Sb2BV2IT3ioU-xWVXY2TwZJIN0Op2NdsPXorRKjhPjIVbtRacsEJ4jdM3PR4xUNj_K9)\n\n### なぜコンテナで動かすか？\n\n最近はホスト上に言語やライブラリをインストールするのではなく、コンテナを使って開発環境を整えることの方が多いと思います。\n\nもちろん仮想環境を使うという手段もありますが、可搬性ではコンテナの方が上なので、私は大抵の場合コンテナを使った開発環境を作り、VS Code の dev container を使ってコンテナ内で作業をします。\n\nしかしながら、今回導入する VS Code Server では2022年12月現在まだ dev container をはじめとするリモート開発の拡張機能はサポートされていません。\n\n\u003e Can I use the Remote Development Extensions or a dev container with the VS Code Server?  \n\u003e Not at this time.\n\nhttps://code.visualstudio.com/docs/remote/vscode-server#_can-i-use-the-remote-development-extensions-or-a-dev-container-with-the-vs-code-server\n\nなので、ホスト上に VS Code Server をインストールしたところで実際の開発環境に入り込むことができないので、であれば開発環境のコンテナ上に VS Code Server を入れて直接乗り込もう、というのが今回の趣旨になります。\n\n## セットアップ\n\n```sh\ngit clone https://github.com/SogoKato/simple-devenv-py.git\n```\n\nDockerfile の抜粋です。イメージのビルド時にスクリプトをダウンロード\u0026実行して VS Code Server をインストールしています。\n\nCMD に `code-server` コマンドを書いて、コンテナ起動時に VS Code Server が実行されるようにします。\n\n`--accept-server-license-terms` と `--random-name` オプションはユーザーインタラクションを不要にするためのもので、順に[ライセンス](https://code.visualstudio.com/license/server)への同意とランダムな命名をしています。  \n`--server-data-dir` を使ってデータの永続化のため VS Code Server のデータの保存領域をバインドマウントするディレクトリ配下にしておきます。[^1]\n\n[^1]: ただし、筆者が一度コンテナを再作成してみたところ GitHub の再認証は不要でしたが、インストールした拡張機能などは消えてしまっていました（調査中）。\n\n```dockerfile\nRUN wget -O- https://aka.ms/install-vscode-server/setup.sh | sh\n\nCMD [\"code-server\", \"serve\", \"--accept-server-license-terms\", \"--random-name\", \"--server-data-dir\", \"/workspace/.vscode-server\"]\n```\n\nイメージをビルドしましょう。\n\n```sh\ndocker compose build\n```\n\ndocker-compose.yml です。なんの変哲もありません。\n\n```yml\nversion: '3'\nservices:\n  app:\n    build:\n      context: ./\n      dockerfile: Dockerfile\n    volumes:\n      - type: bind\n        source: ./\n        target: /workspace\n```\n\n起動します。\n\n```sh\ndocker compose up -d\n```\n\nログを見ると GitHub へのログインを求められています。\n\n```sh\ndocker compose logs -f\n```\n\n```\nsimple-devenv-py-app-1  | To grant access to the server, please log into https://github.com/login/device and use code xxxx-xxxx\n```\n\n言われた通り https://github.com/login/device にアクセスして、コードを入力しましょう。\n\nログインが完了するとトンネルが作成され、ブラウザアクセス用の URL が払い出されることがわかります。\n\n```\nsimple-devenv-py-app-1  | [2022-12-17 09:06:03] info Creating tunnel with the name: dazzling-antshrike\nsimple-devenv-py-app-1  | \nsimple-devenv-py-app-1  | Open this link in your browser https://insiders.vscode.dev/+ms-vscode.remote-server/dazzling-antshrike/workspace\n```\n\n## 接続（ブラウザ）\n\n好きなブラウザで払い出されたリンクを開くだけです。簡単。\n\n## 接続（VS Code）\n\n[Remote - Tunnels](https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-server) 拡張機能がインストールし、GitHub にログインすると登録されているトンネルの一覧を確認できます。\n\n![Tunnels](/images/posts/2022/12/vsc_remote_tunnels.png)\n\nボタンをクリックしてリモートに接続します。\n\n## 遊んでみる\n\nあとはいつも通り VS Code の設定を行なっていけば OK です。\n\n![editor](/images/posts/2022/12/vsc_remote_editor.png)\n\nサーバーを起動してみます。\n\n![run](/images/posts/2022/12/vsc_remote_run.png)\n\nポートが使われていることを検知するとローカル実行時と同じように通知が出てきます。  \n「ブラウザーで開く」をクリックするとポートがクラウド経由でポートが転送されて、起動したサーバーにリクエストが届きます。\n\n![port forwarding](/images/posts/2022/12/vsc_port_forwarding.png)\n\nちなみにこの URL は GitHub 未認証の状態では見ることができない（ログインを求められる）のでセキュリティ的にも安心です。\n\n## 使い心地は？\n\n若干ラグがあるように感じます。\n\n今回検証に使った Raspberry Pi のスペックの問題なのか（MicroSD から SSD にしたら変わるかも？）、ネットワーク環境の問題なのか、原因はまだ切り分けできていません。\n\nまた、ちょいちょい接続が切れて `Connecting to hogehoge...` と出てくるのですが、これはおそらくうちのネットワーク環境のせいな気がします。。\n\n### 2022/12/18 追記\n\nMicro SD から SSD に変えてみたら体感が大きく改善され、ストレスを感じない程度に快適になりました。SSD しか勝たん。\n\n## まとめ\n\n今までこれと同様のことを実現する選択肢として [code-server](https://coder.com/docs/code-server/latest) がありましたが、Pylance などオープンソースでは利用できない拡張機能があったりして、ローカルの VSCode と同じ環境を整えることは困難でした。\n\nMicrosoft 謹製の VS Code Server がリリースされたことにより、よりローカルの VS Code に近い環境を作ることができるようになりました。  \nサーバー側のポートを開ける必要がないのもメリットです。企業のポリシー次第ですが、会社でこれを使えたら嬉しいというユーザーも多いのではないでしょうか。\n\nそれでは、ハッピーなエンジニアライフを！\n\n## 参考文献\n\n* [Visual Studio Code Server](https://code.visualstudio.com/docs/remote/vscode-server)\n","tags":[{"name":"VS Code","ref":"/tags/vs-code"},{"name":"開発環境","ref":"/tags/開発環境"}],"showTerminalAside":false},{"title":"よくあるSPA+API構成でのOpenID Connectクライアント実装","date":"2022-12-02T00:00:00.000Z","ref":"/posts/2022/12/openid-connect-fastapi","desc":" この記事はニフクラ等を提供している、富士通クラウドテクノロジーズ Advent Calendar 2022の2日目の記事です。\n\n昨日は [@nt","draft":false,"content":"\nこの記事は[ニフクラ](https://www.nifcloud.com/)等を提供している、[富士通クラウドテクノロジーズ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/fjct)の2日目の記事です。\n\n昨日は [@ntoofu](https://qiita.com/ntoofu) さんの [パケットキャプチャからKubernetes APIのTLS通信を解析する](https://ntoofu.github.io/blog/post/sniffing-kube-apiserver-tls/) でした。  \n私は TLS な時点でパケットキャプチャを諦めてしまいそうですが Linux の便利な仕組みと気合があれば TLS 1.3 のパケットキャプチャも可能だとわかり、とても有益でした。私もギークなエンジニア目指して頑張ります。\n\n今日は OpenID Connect のクライアントをどう実装するかについて検討してみたいと思います。\n\nFastAPI + SPA (Vue.js) でちょっとした社内ツールを開発した時に社内の認可基盤との OpenID Connect を用いたログイン連携機能を作りたかったのですが、実装のための情報が少なかったので記事に残しておきたいと思ったのがきっかけです。「これがベストプラクティスだ！」というわけではありませんが、1つの実践例としてどなたかの参考になれば幸いです。\n\n## 対象読者\n\n* OpenID Connect を使ってログインするアプリを作りたいけど実装方法がわからない人\n  * 色んなフローがあるっぽいけどどれを使うべき？\n  * アクセストークン？ ID トークン？\n  * サーバーで何してクライアントで何するの？\n* Python の FastAPI で作ったサーバーでのログイン〜リダイレクト〜トークン検証の実装例が知りたい人\n\n## OpenID Connect とは\n\n**OpenID Connect は OAuth 2.0 を拡張する形で策定された、認証・認可のための仕組み**です。OAuth 2.0 は認可を行うことを目的とした仕様です。すでに10年も前の話ですが、OAuth を認証にも使ってしまう「SNS ログイン」の手法は「[単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる](https://www.sakimura.org/2012/02/1487/)」と指摘されていました。OpenID Connect は OAuth 2.0 を拡張して認証の用途にも使えるようにした、ID トークンを発行するための仕組みとなっています。\n\n下図は認証・認可の流れの一例です（response_type=id_token の場合）。\n\n![overview](//www.plantuml.com/plantuml/png/NP6zIiDG5CVt-nINJkbGgBg9I0SNfrlo1g7DKD0q9EckzpW4KHfGS6aH9KWeIeMYK1FmOGv9u-GhUEvDH9lbSCBv_J_2xVc1vGMJqnDc3OAnnn6U43AKxpIvvVE9Rtjyx0rfxdIPI-neC78j9-0jb6yAXHkKQswO_NPB2Sn-ZUysSE7Qpl4HmXt22qA4CaOuuuQeTU9NjzTbEhHpgBpskSBbgyPN23EKdsgHIuG50j3222DOABXSN9T9HYS5o8IQ8OILtq67a8RVvZRzcZyYf7bqLLnCgy_o8Td47vMewPlIaa-NJEX8y__fMOVDTRcreVuqHCXqqLMRcN-2xLCHpqXUtrLces8HHldb_NTspdgsCwI7-W40)\n\nOP: OpenID Provider; ID トークンの発行者  \nRP: Relying Party; OP に認証機能を既存するクライアントアプリ\n\nユーザーがサービスにログインしようとすると、サービスはまず OpenID プロバイダー（OP）のエンドポイントに対してユーザーをリダイレクトします。OP は未認証であればログイン画面を出しユーザーを認証してから、サービスに対して認可を行うかどうか同意を取ります。ユーザーが同意すると、OP は ID トークンをリクエストに含めてサービスのコールバック URL にリダイレクトします。サービスは受け取った ID トークンが正規の OP からのものであることを OP の公開鍵を使用して検証します（そのほかにも複数の検証をする）。検証が正常に終了すればサービスへのログインの処理は完了です。\n\n## で、どうやってクライアントを実装するの？\n\n### まずは結論\n\n![code flow](//www.plantuml.com/plantuml/png/RPBFIW9H5CRtzoakhdGXJNzM4Q7GnfL3FS6aBeHI6KTewTmROQ4e94YWX28XKXdq1t8a7-OuEgvwXRwPKN2apULSlz_vpdUk4oiQccwKBY-ObZBoEYVvH792uWidrugyLCpeFA-dSUugx3n_nKCaFbr4tfFuvk5JDH9Y1NXaKzc2bZFucHfVDUmf0I6k9bR2li8okJI7Mm089GkPNEA4P8la2ya6YJx9CWydCSBDabHN_GSAyt95ZxrfXzpbnPl7lvDiavYwXHYH79AKA1Wuu6w6RTniaVb3vWE31WHJG3Z3cZEOkEqm4GDiIhBY3psA0jaoMJIjPQT7qh8RrVbrtRywtS6YF_QRjdqj57PznF2Zdsf3U_QcTM2B8ko39B0NjDj8C6PGN9RDsRGRC2NHyrQm_1N0uGhh7RppnjMPDktQX--zRWqIytuRwLpY_sUtNwkpyStwdRsbWy2yqh3l7dyd9elXpySNzmS0)\n\n* API サーバーで認証リクエストや ID トークン検証を行う\n  * 今回は採用するライブラリの都合で Authorization Code Flow を使います\n* ID トークンは Cookie で管理\n  * localStorage ではセキュリティ上問題がある\n  * インメモリでは利便性に欠ける\n  * Cookie の属性\n    * HttpOnly: true\n      * JavaScript からは触らせない\n    * SameSite: Lax\n      * 他サイトへの Cookie 送信を最低限にする\n      * Strict にすると OP にリダイレクトした際に破棄されてしまうため Lax\n    * Secure: true\n      * HTTPS でのみ Cookie を送信する\n\n### SPA なら全部 SPA にやらせればいいんじゃないの？\n\nはい、Implicit Flow を使うことで実現できます。\n\n冒頭の「車が通れるほどのどでかいセキュリティー・ホール」の話は OAuth 2.0 を Implicit Flow で使用した時の話ですが、OpenID Connect はそれを踏まえて策定された仕様なので、OpenID Connect において Implicit Flow を使うことに問題はありません。\n\nImplicit Flow を使う場合、下図のようになります（response_type=id_token）。\n\n![implicit flow](//www.plantuml.com/plantuml/png/TP9FIm916CRlyoa6JteGjZydYL3euicbFi6c7eHIMLVegFD6I1WA1LsKC2H4AWCfq5tmmxpkkfxw2hqpxWO3THbcz_dDypppxcORZcKxpSiBPXMTciqHNX0y55-qSgl1cusopMjsYTOzWvtNhdW2nQT4u1x5WYTFpLI2rScZKgpKhQh3pynST63Vq8IScO-40uELgoLERXgGADJBrVm9mYF26q8VnHYXnPC5Yf1T2cPq_j1WgbVwMALbkEJ5X-Bd20CKAxaHCuGf0j264KSuMH0TJk_2YKUQ9CI4he7GsJaUfIMY6suUtEtm6S7r-ztWkhTx34UJpNWPrz1zNThulHcZbxyDO-rLfGrLlKLINhQZvarLvwcufPnKXklYjjLUhqQCfF-8O3oW24dyFHZ_lRjUtiGPghaE19s-V_lqxRLPbZuF_HC_)\n\n上記のフローでは、SPA 側で Client Secret を管理する必要がありません。ClientSecret が必要になるのは主にトークンエンドポイント（認可コードやアクセストークンを使って、アクセストークンや ID トークンを取得するためのやつ）を使う時なので、response_type=id_token で OIDC クライアントを実装する場合には困りません。response_type=id_token で問題がないかという観点では、ログイン完了時にだけユーザー情報が手に入れば問題ない場合（ユーザー情報が最新である必要がない場合）には事足りると思われます。\n\nSPA でエンドユーザーに見せたくない機密情報を扱うのはほとんど不可能だと思いますので Client Secret を SPA に持たせる必要がないのは嬉しい仕様ですね。**Implicit Flow では CSRF 対策のために nonce の検証が必須**なので注意してください。\n\n### ID トークンどこ置く問題\n\nただ、Client Secret を SPA で管理する必要がないからといって SPA 上で ID トークンを扱えるようにすると、ID トークンをどこに保管するか、という問題が出てきます。これは OIDC のスコープ外の議論ですが、クライアント実装にあたって必ず検討するべき点だと思うので、今回はこれも考えていきたいと思います。\n\nID トークンを置く場所として考えられる候補を比較してみます。\n\n||Cookie (HttpOnly: true, Secure: true, SameSite: Lax)|インメモリ|localStorage|\n|---|---|---|---|\n|保持期間|**設定された有効期限まで**|ページがリロードされるまで|**なし**|\n|CSRF 対策|**更新系は防げる**|**他の JS ライブラリは基本的にアクセスできない**|どの JS ライブラリも取得可|\n|JS での ユーザー情報取得|できない [^1]|**できる**|**できる**|\n\n[^1]: サーバー側で Cookie の ID トークンを検証した上で、JSON レスポンスでユーザー情報を返却する API を作ったりすれば可能です。\n\nどれも一長一短な感がありますが、この中で一番安全性と利便性のバランスがいいのは Cookie (HttpOnly: true, Secure: true, SameSite: Lax) だと思ったので、今回は Cookie に ID トークンを置くようにしました。\n\nなお、Auth0 のクライアントライブラリではインメモリに ID トークンを保存しつつ、セッションを長く保たせることもできるようです。  \n[SPA認証トークンはlocalStorageでもCookieでもない、Auth0方式はいいねというお話](https://mizumotok.hatenablog.jp/entry/2021/08/04/114431)\n\n## FastAPI で OpenID Connect クライアントを実装する\n\n以上で、一通りクライアントの実装方針について議論ができたと思うので、ここからは具体的な Python (FastAPI) での実装に移りたいと思います。  \n今回使うライブラリ Authlib では FastAPI の他に Starlette, Flask や Django の Oauth Client とその実装例も公開されているので、それらを参考にすれば他のフレームワークでも割と簡単に実装できるのではないかなと思います。\n\n### ソースコード\n\nhttps://github.com/SogoKato/oidc-fastapi-authlib\n\n動かしてみたい方は README に従って起動してみてください。\n\n### 必要なもの\n\n前準備として OpenID プロバイダを用意する必要があります。どのプロバイダでも大丈夫ですが、まだ持っていない場合は [Auth0](https://auth0.com/jp) に登録してみるのがおすすめです。個人で使うようなリクエスト量であれば無料で使えます（2022年12月現在）。\n\n登録後、Application を作成したら、リダイレクト URI (Allowed Callback URLs) に `http://localhost:8080/api/auth` を入れておきます。また、下記の情報を探してメモっておきましょう。\n\n* Client ID\n* Client Secret\n* OpenID Configuration Endpoint\n  * アクセスすると OIDC クライアントで必要な情報を返してくれるエンドポイント\n  * 通常 `https://example.com/.well-known/openid-configuration`\n\n### アーキテクチャ\n\n![architecture](//www.plantuml.com/plantuml/png/SoWkIImgAStDuKfCBialKdZSlEnnyvx7JTk0f49YiK9fSMeHLs9HSaPcRc99ge9oIMfoHbv-JdvwfK9UUcPUXOAD3L15MMPogfqT3dME0Pv4g5Bo2F7rqNSE3jRt2bO2sGnqM4bcCefEa6CKTEsWDbi17RlgSTFwnqqh7ZVjVDpSmGKHrzMr0za9bDTFBCX4249D18bpEQJcfG0z3G00)\n\n今回は Cookie の SameSite 属性を使用しているので、SPA と API とで同じドメイン名を使い、パスでリクエストを振り分けます。\n\n### 解説\n\n#### ログイン時の処理\n\n```python\napp = FastAPI()\napp.add_middleware(SessionMiddleware, secret_key=\"MYSTRONGKEY\", https_only=True)\n```\n\nFastAPI の初期化と Cookie のための SessionMiddleware の追加をします。\n\n```python\noauth = OAuth()\noauth.register(\n    name=\"auth0\",\n    server_metadata_url=\"https://example.com/.well-known/openid-configuration\",\n    client_id=\"クライアントID\",\n    client_secret=\"クライアントシークレット\",\n    client_kwargs={\"scope\": \"openid profile\"},\n)\n```\n\nAuthlib のインスタンスを作ります。scope に `openid` と入れておくことで Authorization Code Flow の時にトークンエンドポイントで ID トークンが手に入ります。\n\n```python\n@app.get(\"/api/login\")\nasync def login(request: Request):\n    redirect_uri = request.url_for(\"auth\")\n    return await oauth.auth0.authorize_redirect(request, redirect_uri)\n```\n\n認証リクエストを開始するためのエンドポイントです。ユーザーがここにアクセスすることで `http://localhost:8080/api/auth` をリダイレクト URI とした認証リクエストを開始します（OpenID プロバイダにリダイレクトされる）。\n\nちなみにこんな URL でリダイレクトされます。state と nonce があることも確認できますね。\n\n```\nhttps://example.com/authorize\n  ?response_type=code\n  \u0026client_id=クライアントID\n  \u0026redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fapi%2Fauth\n  \u0026scope=openid+profile\n  \u0026state=PGO5TxTujESoXuLlfzYTWZsioK5Up5\n  \u0026nonce=HfyA3eugosoOuieiTGRZ\n```\n\n![OP login](/images/posts/2022/12/oidc_op_login.png)\n\nログインが完了するとリダイレクト URI にリダイレクトされ、次のエンドポイントが呼ばれます。\n\n```python\n@app.get(\"/api/auth\")\nasync def auth(request: Request):\n    try:\n        token = await oauth.auth0.authorize_access_token(request)\n    except OAuthError:\n        logger.exception(\"An error occurred while verifying authorization response.\")\n        raise UnauthenticatedError()\n    userinfo = token.get(\"userinfo\")\n    # userinfoのclaims(subやnameなど)を使ってDBにユーザーを登録する処理がここにきます.\n    request.session[\"id_token\"] = token.get(\"id_token\")\n    return RedirectResponse(url=\"/\")\n```\n\n`authorize_access_token` で認可コードと state を使って ID トークンを取得し、ID トークンと nonce を検証するところまでやってくれます（楽ちん）。  \nその後は自分の好きなように処理をして OK です。sub クレームをユーザー ID として、ユーザーがまだ DB に登録されていなければ insert するとか、ユーザーのプロフィール情報が変わってたら更新するとか、そういう処理が来るのかなと思います。\n\n最後に、Cookie に ID トークンをセットして `/` にリダイレクトして、ログイン処理は完了です。\n\n#### ログイン後の処理\n\nログイン後は JS 側で fetch や axios でリクエストをすると、Cookie も自動的に送信されます。なので、ログインしたユーザーにしか使わせたくないエンドポイントでは、Depends を使って ID トークンを検証します。\n\n```python\n@app.get(\"/api/items\")\nasync def list_items(user: User = Depends(verify_user)):\n    logger.info(f\"Successful log in: user_id={user.id} name={user.name}\")\n    return {\n        \"items\": [\n            {\"name\": \"Teddy bear\", \"icon\": \"🧸\", \"price\": 99},\n            {\"name\": \"Apple\", \"icon\": \"🍎\", \"price\": 2},\n            {\"name\": \"Sushi\", \"icon\": \"🍣\", \"price\": 200},\n            {\"name\": \"Bento\", \"icon\": \"🍱\", \"price\": 50},\n        ]\n    }\n```\n\n`verify_user` 関数で Cookie から ID トークンを取り出します。\n\n```python\nasync def verify_user(request: Request):\n    id_token = request.session.get(\"id_token\")\n    if id_token is None:\n        raise UnauthenticatedError()\n    decoded_jwt = await verify_token(id_token=id_token)\n    # DBにユーザーが登録されているか確認する処理がここにきます.\n    # user = user_repo.select_by_user_id(user_id=user_id)\n    return user\n```\n\n`verify_token` が ID トークンを検証する関数です。\n\n```python\nasync def verify_token(id_token: str):\n    jwks = await oauth.auth0.fetch_jwk_set()\n    try:\n        decoded_jwt = jwt.decode(s=id_token, key=jwks)\n    except Exception:\n        logger.exception(\"An error occurred while decoding jwt.\")\n        raise UnauthenticatedError()\n    metadata = await oauth.auth0.load_server_metadata()\n    if decoded_jwt[\"iss\"] != metadata[\"issuer\"]:\n        raise UnauthenticatedError()\n    if decoded_jwt[\"aud\"] != settings.oidc_client_id:\n        raise UnauthenticatedError()\n    exp = datetime.fromtimestamp(decoded_jwt[\"exp\"])\n    if exp \u003c datetime.now():\n        raise UnauthenticatedError()\n    return decoded_jwt\n```\n\nID トークンの検証として最低限必要なのは以下の通りです（Authorization Code Flow の場合）。\n\n1. JWK Set（OP の公開鍵）を使用して JWT をデコードする\n2. iss クレーム（Issuer Identifier; 発行者）を検証する\n3. aud クレーム（Audience(s); 誰に対して発行したか = Client ID）を検証する\n4. exp クレーム（Expiration time; 有効期限）を検証する\n\n以上が完了すれば基本的な OIDC クライアント実装は完了です🎉\n\n![log in](/images/posts/2022/12/oidc_log_in.gif)\n\n## 最後に\n\nいかがでしたか？？\n\n一見複雑そうな OpenID Connect ですが、一つずつ紐解いてみると意外と簡単に実装できるように仕様が設計されていることがわかりました。自分でパスワードを頑張って管理するよりもこういうところは信頼できる OpenID プロバイダに任せてしまった方が楽ですし、何よりも安全ですよね。\n\nぜひ皆さんも Web サービスを作る時には活用してみてください。\n\nこの記事は[富士通クラウドテクノロジーズ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/fjct)の2日目の記事でした。\n\n明日は [@Syuparn](https://qiita.com/Syuparn) さんが SQL のテストについて書いてくれるようです。  \nSQL のテストってあまりやってなかったりするので、他の人がどのように考えて実施しているのか気になります。それでは、明日の記事もお楽しみに！\n\n（👇この記事がよかったらいいねボタンを押してください！）\n\n## 参考文献\n\n* [OpenID Connect Basic Client Implementer's Guide 1.0 - draft 42](https://openid.net/specs/openid-connect-basic-1_0.html)\n* [OpenID Connect Implicit Client Implementer's Guide 1.0 - draft 25](https://openid.net/specs/openid-connect-implicit-1_0.html)\n* [Google login for FastAPI](https://blog.authlib.org/2020/fastapi-google-login)\n* [一番分かりやすい OpenID Connect の説明](https://qiita.com/TakahikoKawasaki/items/498ca08bbfcc341691fe)\n* [IDトークンが分かれば OpenID Connect が分かる](https://qiita.com/TakahikoKawasaki/items/8f0e422c7edd2d220e06)\n* [OpenID Connect 全フロー解説](https://qiita.com/TakahikoKawasaki/items/4ee9b55db9f7ef352b47)\n* [OAuth 2.0/OpenID Connectの2つのトークンの使いみち](https://qiita.com/wadahiro/items/ad36c7932c6627149873)\n* [単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる](https://www.sakimura.org/2012/02/1487/)\n* [OIDCのImplicit FlowでClientSecretを使わずにID連携する](https://zenn.dev/ritou/articles/a)\n* [SPA認証トークンはlocalStorageでもCookieでもない、Auth0方式はいいねというお話](https://mizumotok.hatenablog.jp/entry/2021/08/04/114431)\n* [GoでOpenID ConnectのClientを実装する（実装編）](https://times.hrbrain.co.jp/entry/go-openid-connect-implement)\n","tags":[{"name":"OpenID Connect","ref":"/tags/openid-connect"},{"name":"認証/認可","ref":"/tags/認証-認可"},{"name":"SPA","ref":"/tags/spa"},{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"}],"showTerminalAside":false},{"title":"GitLab CIのrulesとworkflowを理解する","date":"2022-11-17T00:00:00.000Z","ref":"/posts/2022/11/gitlab-rules-workflow","desc":" GitLab CI の rules を使って Dockerfile などの特定のファイルの変更時のみ Docker イメージを作成するパイプラインを回して、それ以外の時には既存の Docker イメージを使用して CI を実行する、という組み方をしたかったのですが、書き方に結構手間取ったのでメモ。","draft":false,"content":"\nGitLab CI の rules を使って Dockerfile などの特定のファイルの変更時のみ Docker イメージを作成するパイプラインを回して、それ以外の時には既存の Docker イメージを使用して CI を実行する、という組み方をしたかったのですが、書き方に結構手間取ったのでメモ。\n\n環境: GitLab.com 15.6.0-pre\n\n## rules とは\n\nhttps://docs.gitlab.com/ee/ci/yaml/#rules\n\nそれぞれのジョブについて、パイプラインに追加するかしないかの条件を記述するものです。\n\nrules では下記の条件が指定できます。\n\n* `if`\n* `changes`\n* `exists`\n* `allow_failure`\n* `variables`\n* `when`\n\nそれぞれの条件の詳細については公式ドキュメントを参照してください。\n\nrules は [only/except](https://docs.gitlab.com/ee/ci/yaml/#only--except) を置き換えるものなので、rules と only/except を同じジョブで同時に指定することはできません。\n\nrules の指定の一例を公式ドキュメントから引用します。\n\n```yaml\ndocker build:\n  script: docker build -t my-image:$CI_COMMIT_REF_SLUG .\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n      changes:\n        - Dockerfile\n      when: manual\n      allow_failure: true\n```\n\n上記の例では\n\n* パイプラインがマージリクエストのパイプラインの時に `Dockerfile` が変更されているか確認する\n* `Dockerfile` が変更されている時に、ジョブをパイプラインにマニュアルジョブとして追加する\n  * `allow_failure: true` によって、ジョブがトリガーされなかったとしても後続のジョブが実行される\n* `Dockerfile` が変更されていない時は、ジョブをパイプラインに追加しない\n  * `when: never` と同じ\n\nという挙動になります。\n\nrules はリストなので複数のルールを書くことができますが、 **短絡評価である** 点に注意が必要です。rules はパイプラインが作成されたタイミングで評価され、最初にマッチするまで評価が行われます。そのため、例えば `- when: manual` を最初に記述するとそこで評価が終わり（`manual` は常に真となりパイプラインに追加されます）、その後の条件については評価されません。言われてみたらそれはそうなのですが、筆者はそこでしばらく詰まってました。\n\n## workflow とは\n\nhttps://docs.gitlab.com/ee/ci/yaml/workflow.html\n\nパイプラインそのものを実行するかどうかを決定するものです。workflow で条件にマッチしなかった場合、そのパイプライン内のジョブが実行されることはありません。\n\nよくある使い方としては `$CI_PIPELINE_SOURCE` の種類（`merge_request_event`, `push`, `schedule`, etc.）に応じてパイプラインを実行するかしないかを決めると言った使い方があります。\n\n```yaml\nworkflow:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"schedule\"\n      when: never\n    - if: $CI_PIPELINE_SOURCE == \"push\"\n      when: never\n    - when: always\n```\n\n上記の例ではスケジュール実行時または push 時（ブランチとタグ）には `when: never` が指定されているためパイプラインは走りません。それ以外の時にはパイプラインが実行されます。\n\n## 重複したパイプラインを避ける\n\nhttps://docs.gitlab.com/ee/ci/jobs/job_control.html#avoid-duplicate-pipelines\n\nジョブに rules を使用していると、マージリクエスト作成後にブランチに対して push するといった1つのアクションが、push 時に発生したパイプラインとマージリクエストのパイプラインの2つが走らせることが起こりえます。\n\n重複したパイプライン（duplicate pipelines）を避けるためには\n\n* workflow を使ってどの種類のパイプラインは走って良いのかを指定する\n* ジョブが実行される条件をかなり限定的にして、最後のルールとして `when`（`when: never` 以外）を使うのを避ける\n\nことが対策になります。\n\n筆者の場合は、次項で示す例を書いている際に重複したパイプラインが発生し、片方のジョブは正しく機能しないという状況が起こりましたが、workflow を指定することで重複が解消され、正しく機能するようになりました。\n\n## 特定ファイルの変更時のみジョブを実行し、それ以外はスキップして後続のジョブを実行する\n\n`.gitlab-ci.yml` と同階層に `Dockerfile` がある想定です。\n\n```yaml\nstages:\n  - build\n  - test\n\nworkflow:\n  rules:\n    - if: $CI_PIPELINE_SOURCE == \"merge_request_event\"\n    - if: $CI_COMMIT_BRANCH \u0026\u0026 $CI_OPEN_MERGE_REQUESTS\n      when: never\n    - if: $CI_COMMIT_BRANCH\n\nbuild:\n  stage: build\n  image:\n    name: gcr.io/kaniko-project/executor:v1.9.0-debug\n    entrypoint: [\"\"]\n  script:\n    - /kaniko/executor\n      --context \"${CI_PROJECT_DIR}\"\n      --dockerfile \"${CI_PROJECT_DIR}/Dockerfile\"\n      --destination \"${CI_REGISTRY_IMAGE}:latest\"\n  rules:\n    - if: $CI_PIPELINE_SOURCE =~ /merge_request_event|push/\n      changes:\n        - Dockerfile\n    - when: manual\n      allow_failure: true\n\ntest:\n  stage: test\n  image: \"${CI_REGISTRY_IMAGE}:latest\"\n  script:\n    - echo \"DO SOME TESTS\"\n```\n\n上記の例は以下の挙動をします。\n\n* workflow\n  * マージリクエストでのパイプラインの場合は実行される\n  * マージリクエストがある時、ブランチへの push イベントでのパイプラインは実行されない\n  * それ以外のブランチへの push イベントでは実行される\n* rules\n  * パイプラインがマージリクエストのパイプラインの時または push された時に `Dockerfile` が変更されているか確認する\n    * changes は上記以外では常に真となってしまうため\n  * `Dockerfile` が変更されている時に、ジョブをパイプラインにジョブを追加する\n  * 上記の条件に当てはまらない時はマニュアルジョブとしてパイプラインに追加する\n    * `allow_failure: true` となっているので、後続のジョブはそのまま実行される\n\nこのように書くことで、実現したかった「特定ファイルの変更時のみジョブを実行し、それ以外はスキップして後続のジョブを実行する」が実現します。\n","tags":[{"name":"GitLab","ref":"/tags/gitlab"},{"name":"CI/CD","ref":"/tags/ci-cd"}],"showTerminalAside":false},{"title":"Next.jsとTailwind CSSでブログを作るときに考えたこと","date":"2022-11-13T00:00:00.000Z","ref":"/posts/2022/11/blog-with-nextjs-and-tailwindcss","desc":" このブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。","draft":false,"content":"\nこのブログは Next.js の SSG（Static Site Generation; 静的サイト生成）機能を使いながら、デザインの大半は Tailwind CSS を使用して整えています。そして生成された HTML, CSS, JS は GitHub Pages でホストさせてもらっています。\n\nそこそこの出来栄えになったので、今回はこのブログができるまでのお話をしたいなと思ったのですが、正直なところ、以下のリンク先のページを~~まるパク~~参考にさせてもらいながら作成したので、具体的な構築方法についてはそちらをご覧いただけると良いかと思います。1ステップずつ丁寧に解説されておりとても有用でした🙏\n\n* [Next.jsを利用した初めての本格的Markdownブログサイトの構築](https://reffect.co.jp/react/nextjs-markdown-blog)\n\nなので、今回は技術的な詳細というよりも、筆者が始める前に疑問だった点や技術選定、設計まわりについて書ければなと思います。\n\n## 対象読者\n\n* 自分のブログを作ってみたい人\n* React や Next.js に興味がある人\n\n## ブログをどこでホストするか\n\n技術に関する記事を書くのであれば Qiita や Zenn でいいじゃんと思いますし、実際その方がはるかに楽で、多くのリアクションをもらいやすいと思います。そんな中、自分のブログを作る理由としては「やってみたかったから」以上の理由は存在しません。つまりロマンです。\n\nしかしながら、いざ自分のブログを作ろうと思ったときに\n\n* 簡単に、かつ高度なカスタマイズができる\n* ランニングコストが安い\n\nといった美味しい環境は思ったよりも少ないです。\n\nブログを作ると言ったら WordPress が超定番ですが、テーマを作るとなると php や WordPress の知識が必要になります。WordPress テーマづくりに携わったことがあるので、やってみると思ったより簡単なのですが、筆者のお仕事の分野とはかすらないのであまりモチベーションが湧きません。  \nまた、最低月数百円のランニングコストもかかりますし、動的にページを生成するのでレスポンスも遅くなりがちです。\n\n次に SSG（Static Site Generation; 静的サイト生成）を検討します。Markdown で原稿を書き、静的な HTML などのファイルを出力すれば、GitHub Pages で無料で公開できるので結構良さそうです。\n\nSSG のツールとしては有名なものがいくつかあります。\n\n* Next.js\n* Gatsby\n* Hugo\n* NuxtJS\n* Jekyll\n\nこのうち、Next.js と Gatsby は React ベースのため当初は検討から外していました。筆者は Hugo を選び、配布テーマを適用してみたり、自作テーマを作り始めたりしましたが、想像より学習コストが高かったので挫折してしまいました。\n\n代わりに最近波に乗っていそうな Next.js を使ってみることにしました。React を使うのは初めてだったので（チュートリアルしかやったことがない）躊躇していましたが、[最初に紹介した記事](https://reffect.co.jp/react/nextjs-markdown-blog)のおかげもあって、すんなりと構築することができました。React の基本的な知識さえあれば問題なさそうです。\n\n## どうやってデザインするか\n\nまずは Adobe XD でデザインカンプを作成します。いきなりマークアップを始めても、作りたいものが定まっていないと無駄に時間がかかってしまうので、多少手間でも作りたいもののイメージを先に決めておくと良いです。\n\n![XD](/images/posts/2022/11/xd.png)\n\n上図のような感じで、ヘッダーやサイドバー、記事一覧、記事ページをざっくりと作りました。\n\n## React の CSS よくわからん問題\n\n筆者の経験不足のせいなのですが、React で CSS でスタイルを適用するベストな方法がよくわかりませんでした😇\n\nデザインカンプを作ってみて、そこまで複雑な CSS を記述する必要がなさそうだったので、Tailwind CSS を使ってみることにしました。\n\n[Tailwind CSS](https://tailwindcss.com/) とは、HTML のクラス属性に `flex`, `pt-4`, `text-center` のようなクラス名を記述することで、`display: flex` をかけたり `padding-top` や `text-align: center` を設定できるというヤツです。\n\n軽く個人的な感想をまとめてみると\n\nPros\n* コード量が減る\n* HTML 要素を消したけど CSS は消し忘れた、みたいなことはなくなる\n* カスタムの色を設定できるなど、一定の柔軟性がある\n\nCons\n* CSS の知識は必要（それはそう）\n* 都度リファレンスを見てクラス名を確認する必要がある\n* 複雑なことはできないので割り切るか、別の方法で書かなくてはいけない\n\nな感じです。良いところも悪いところもありますが、今回筆者はアリだと判断して採用しましたし、実際良かったです。\n\n## クライアント側で実行させたい処理どう書くの\n\nSSG で静的なページを書き出すと言っても、クライアント側で実行させたい処理はあります。このサイトでは、ライトモード↔︎ダークモード切り替えや「いいね」ボタンがそれに該当します。いずれもユーザーのアクションによって DOM を書き換える必要性があります。\n\n普通に React のコンポーネントとして書いてしまうと SSG でのビルド時に静的なページとして書き出されてしまうため、なんとかする必要があります。最初は public ディレクトリ内に js ファイルを置いて Next.js の [Script](https://nextjs.org/docs/basic-features/script) タグで読み込ませていたのですが、それよりも Next.js の [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) 機能を使った方がスマートに書けます。\n\n`{ ssr: false }` 引数を渡してあげることで、そのコンポーネントはブラウザ上でレンダリングされるようになります。\n\n## GitHub Pages で公開するときの罠\n\n晴れて準備完了！いざ公開！と意気揚々と GitHub Pages にデプロイしても、うまくいかないことがあります。\n\nビルド時には以下のコマンドを実行しましょう。\n\n```\nnext build\nnext export -o docs/\ntouch docs/.nojekyll\necho 'sogo.dev' \u003e docs/CNAME\n```\n\nポイントは公開ディレクトリ（上記の場合は `docs`）の直下に `.nojekyll` というファイルを作成していることです。これがないと `_next` ディレクトリは以下が公開されずリンク切れになります。  \n参考: [Next.js の SSG 機能で生成した静的サイトを GitHub Actions 経由で GitHub Pages に公開する](https://sidearrow.github.io/article/next-js-ssg-on-github-pages)\n\n最後のコマンドはカスタムドメイン名を使用しない場合は不要ですが、使用する場合は都度生成しておかないと消えてしまうため、カスタムドメイン名でアクセスできなくなります。\n\n## 今後やっていきたいこと\n\n以上がこのブログを作るにあたって考えたことなのですが、まだやり残したことはあります。\n\n* 記事をリッチにしたい\n  * シンタックスハイライト\n  * リンクカード\n  * 目次（ToC）\n* おすすめ記事をいい感じのアルゴリズムで出したい\n  * まずは記事を書きためなきゃ。。\n\n## 最後に\n\nつらつらと駄文を書き連ねてしまいました。勘の良い方は気づいていると思いますが、このブログは GitHub Pages でホストされている＝[ソースが見れる](https://github.com/SogoKato/sogokato.github.io)なので、もし興味のある方がいらっしゃいましたら覗いてみてください。\n","tags":[{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"},{"name":"Tailwind CSS","ref":"/tags/tailwind-css"}],"showTerminalAside":false},{"title":"Hello World!","date":"2022-10-11T00:00:00.000Z","ref":"/posts/2022/10/hello-world","desc":" はじめまして。  \nこれは初めての投稿です。\n\n今までブログが長く続いたことがないのですが、n度目の正直ということで今回こそは長く続くように頑張りたいと思います（とても固い決意）。\n\n@SogoKato といいます。どんな人か気になってくれた方は 自己紹介ページ をご覧いた","draft":false,"content":"\nはじめまして。  \nこれは初めての投稿です。\n\n今までブログが長く続いたことがないのですが、n度目の正直ということで今回こそは長く続くように頑張りたいと思います（とても固い決意）。\n\n@SogoKato といいます。どんな人か気になってくれた方は [自己紹介ページ](/profile) をご覧いただければと思います。\n\nこのブログの制作にあたっては、初めて React + Next.js + Tailwind CSS を触って作ってみましたが、結構いい開発者体験だったのでこれについてもまた記事に起こしていきたいな〜と思っています。。（少しゆるい決意）\n\n今まで書いてきた記事については、[私の Qiita](https://qiita.com/SogoK) を見てみてください。  \nおすすめは↓らへんです。\n\n* [Vue 3から始める人のための学習ロードマップ](https://qiita.com/SogoK/items/15ed0d9b2be4279b2f47)\n* [新卒エンジニアがCKA取得を目指してKubernetesを勉強したときの記録](https://qiita.com/SogoK/items/4ed2e118d0412c868169)\n* [GitLabのタブを開きすぎて見分けづらいのでfaviconを変える拡張機能を作った](https://qiita.com/SogoK/items/31f74b517dc3c6884c04)\n\nさて、初回から頑張りすぎると次回以降の心理的なハードルがあがっちゃうのでこれくらいにしておこうと思います。では、これからよろしくお願いします🙏\n","tags":[{"name":"Personal","ref":"/tags/personal"}],"showTerminalAside":false}],"slicedPosts":[{"title":"PyScriptを使ってブログのサンプルコードを実行させる","date":"2023-03-06T00:00:00.000Z","ref":"/posts/2023/03/pyscript-codeblock","desc":" 前回の記事を書くときに WebAssembly でブログのコードブロックのコードを実行させられたら面白いかも、ということで PyScript を使って実装してみました。React \u0026 Next.js で使う際の注意点について","draft":false,"content":"\n[前回の記事](/posts/2023/03/pyscript-codeblock)を書くときに WebAssembly でブログのコードブロックのコードを実行させられたら面白いかも、ということで PyScript を使って実装してみました。React \u0026 Next.js で使う際の注意点についても書こうと思います。\n\n以下については前提知識としてこの記事では解説しません。\n\n* [PyScript](https://pyscript.net/)\n* [Pyodide](https://pyodide.org/en/stable/)\n* [WebAssembly](https://webassembly.org/)\n* [react-markdown](https://github.com/remarkjs/react-markdown) のコードブロック（バッククォート3つ \\```）をカスタマイズする方法\n\n## やったこと\n\n* react-markdown のコードブロックでのオレオレ文法で PyScript を導入\n* PyScript のカスタム要素（以下）に対応する React コンポーネントを作成\n  * `\u003cpy-script\u003e`, `\u003cpy-repl\u003e`, `\u003cpy-terminal\u003e`, `\u003cpy-config\u003e`\n* React のハイドレーションのエラーを回避するために Next.js の [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) を使用\n* PyScript の初期化の仕様に合わせた最適化\n\n## まずは遊んでみよう\n\nこちらが成果物になります。コードブロック開始の \\`\\`\\` の横に書いた文字列が、コードブロックをカスタマイズする関数の引数に渡されるので、ここでオレオレ文法を制定します。\n\n### py-terminal タグ\n\nターミナルの出力を表示するためのタグです。後述の `\u003cpy-script\u003e` や `\u003cpy-repl\u003e` での標準出力や標準エラーはここに出てきます。ページに複数配置することができますが、表示される内容は同じになります。\n\nMarkdown では以下のように記述しています。\n\n\\`\\`\\`pyterminal  \n\\`\\`\\`\n\n```pyterminal\n```\n\n### py-script タグ\n\n最も基本的なタグです。\n\n\\`\\`\\`python:pyscript  \nprint(\"Hello world!\")  \n\\`\\`\\`\n\nそれを `\u003cpy-script\u003e` タグに変換することで、PyScript 初期化時にスクリプトが実行されます。\n\n```python:pyscript\nprint(\"Hello world!\")\n```\n\n### py-repl タグ\n\nJupyter Notebook のような感じで逐次実行ができます。\n\n```pyrepl\nprint(\"こんにちは世界!\")\nx = 1\nx\n```\n\n```pyrepl\nraise ValueError()\n```\n\n### py-config タグ\n\n[各種設定値](https://docs.pyscript.net/latest/reference/elements/py-config.html)を入れるためのタグです。\n\nページ内に配置できる `\u003cpy-config\u003e` は一つだけであることに注意が必要です。\n\n今回の実装時には PyScript の fetch 機能を使ってスクリプトファイルのロードを行うという要件があったので、`pyconfig` の markdown の記述は、記事ではファイル一覧として見せるようにしました。\n\n\\`\\`\\`pyconfig  \nterminal = false  \n\n\\[\\[fetch\\]\\]  \nfrom = \"../../../assets/posts/2023/03/dog.py\"  \nto_file = \"./dog.py\"  \n\\`\\`\\`\n\n```pyconfig\nterminal = false\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/dog.py\"\nto_file = \"./dog.py\"\n```\n\nアップロードしたファイルを PyScript に読み込むことで、自作スクリプトを使用できます。\n\n`dog.py` の中身はこうなっています。\n\n```python:dog.py\nclass Dog:\n    def bark(self):\n        print(\"Bow-wow!\")\n```\n\n`\u003cpy-script\u003e` で実行すると print したものがターミナルに出てきます。\n\n```python:pyscript\nfrom dog import Dog\n\nwanchan = Dog()\nwanchan.bark()\n```\n\n## react-markdown のコードブロックでのオレオレ文法で PyScript を導入\n\nすでに見ていただいたように、コードブロックの言語を記載する部分を拡張したオレオレ文法で実装しています。\n\nコードブロック開始の \\`\\`\\` の横に書いた文字列が [`CodeBlock`](https://github.com/SogoKato/sogokato.github.io/blob/8769da4e6bb4bdecf4a0c59d274d4a439b66535b/components/CodeBlock.tsx) コンポーネントの `className` 引数に渡されるので、それを `split` して条件分岐を作ります。\n\n関連するソースコード（執筆時点）\n* [components/CodeBlock.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/CodeBlock.tsx)\n\n## PyScript のカスタム要素に対応する React コンポーネントを作成\n\n上記の CodeBlock やその他の場所から呼び出される PyScript のカスタム要素を表すコンポーネントです。汎用的なライブラリを目指しているわけではないので、すべての引数を受け取れるようにはしていません。\n\n関連するソースコード（執筆時点）\n* `\u003cpy-script\u003e`\n  * [components/PyScript.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyScript.tsx)\n* `\u003cpy-repl\u003e`\n  * [components/PyRepl.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyRepl.tsx)\n* `\u003cpy-terminal\u003e`\n  * [components/PyTerminal.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyTerminal.tsx)\n* `\u003cpy-config\u003e`\n  * [components/PyConfig.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyConfig.tsx)\n\n## React のハイドレーションのエラーを回避するために Next.js の Dynamic Import を使用\n\nPyScript が DOM の書き換えを行うので、サーバー側で SSR した結果とクライアントの DOM との不整合が発生し、ハイドレーションのエラーが発生してしまいます。\n\n[Next.jsとTailwind CSSでブログを作るときに考えたこと](/posts/2022/11/blog-with-nextjs-and-tailwindcss)の記事でも紹介したことがありますが Next.js には [Dynamic Import](https://nextjs.org/docs/advanced-features/dynamic-import) という機能があり、これを使うことでクライアント側のみで実行したい処理を書くことができます。\n\n上で作成した PyScript のカスタム要素に対応するコンポーネント（`PyConfig` 以外）を使う際は Dynamic Import を使用するようにしています。`PyConfig` については DOM が変更されることがないので Dynamic Import にする必要がないです（また、これを Dynamic Import にしたらうまく動作しませんでした）。\n\n関連するソースコード（執筆時点）\n* [components/CodeBlock.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/CodeBlock.tsx)\n\n## PyScript の初期化の仕様に合わせた最適化\n\nPyScript では script タグで読み込みが完了したタイミングで、初期化の処理が行われ、現状では初期化後に設定の変更等は行えません。つまり、script タグの読み込みが完了する時には `\u003cpy-config\u003e` をはじめとする各要素が宣言されている必要があります（詳しくは要検証ですが）。\n\nこの仕様は、動的に要素を管理する React と相性が良くないです。とりあえず、`\u003cReactMarkdown\u003e` の呼び出し側で、PyScript の各要素よりも後ろに配置し `lazyOnload` strategy で読み込むようにしています。\n\nまた、SPA のようなクライアント側でのルーティングを行なっているので、別の記事に移動しても前のページの実行結果がターミナルに残ってしまいます。現状では PyScript 側に destroy 系のメソッドが用意されていないので、こちらもとりあえずの対応として閲覧者にページをリロードするように促す仕組みを入れています・・・。🙇\n\n関連するソースコード（執筆時点）\n* [components/PostCard.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PostCard.tsx)\n* [components/PyTerminal.tsx](https://github.com/SogoKato/sogokato.github.io/blob/3471507cfa722c763bdda0781e2d97ea17934a8d/components/PyTerminal.tsx)\n\n## おわりに\n\nPyScript はまだまだ発展途上感があり、周辺のエコシステムも整備されていませんが、今回は気合でブログのコードブロックに WASM を導入しました。サードパーティのライブラリも読み込めたりするので、ちょっとしたコードを載せて動かすには十分だと思います。\n\nこの記事が良ければ RSS 登録と「いいね」「役に立った」ボタンをポチッとお願いします！（YouTuber 風）  \nそして、同じようなことを思いついた誰かの助けになれば幸いです！\n\n## 参考文献\n\n* [PyScript](https://pyscript.net/)\n* [Pyodide](https://pyodide.org/en/stable/)\n* [pyscript-react](https://github.com/Py4Js/pyscript-react)\n* [オレオレ記法のMarkdownを任意のReactElementとして変換する](https://qiita.com/bigmon/items/de62335fbf8388192499)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"WebAssembly","ref":"/tags/webassembly"},{"name":"PyScript","ref":"/tags/pyscript"},{"name":"JavaScript","ref":"/tags/javascript"},{"name":"React","ref":"/tags/react"},{"name":"Next.js","ref":"/tags/next.js"}],"showTerminalAside":true},{"title":"Pythonのunittest.mock.patchではどこにパッチするかが重要","date":"2023-03-04T00:00:00.000Z","ref":"/posts/2023/03/python-unittest-mock-where-to-patch","desc":" Python 公式ドキュメントの unittest.mock のページにドンピシャの内容が書いてありますが、なかなか気づけずにハマってしまっていたので","draft":false,"content":"\n[Python 公式ドキュメントの unittest.mock のページ](https://docs.python.org/ja/3/library/unittest.mock.html#where-to-patch)にドンピシャの内容が書いてありますが、なかなか気づけずにハマってしまっていたのでメモです。\n\n`unittest.mock.patch` でパッチしたけど当たってない気がする人は参考にしてみてください。\n\n下記の引用に要点が凝縮されています。\n\n\u003e ### どこにパッチするか\n\u003e\n\u003e `patch()` は (一時的に) ある 名前 が参照しているオブジェクトを別のものに変更することで適用されます。任意のオブジェクトには、それを参照するたくさんの名前が存在しえます。なので、必ずテスト対象のシステムが使っている名前に対して patch しなければなりません。\n\u003e\n\u003e 基本的な原則は、オブジェクトが _ルックアップ_ されるところにパッチすることです。その場所はオブジェクトが定義されたところとは限りません。\n\nつまり、宣言した場所ではなく import している側から見たオブジェクトの位置を指定しなさい、ということです。ただ、`from a import SomeClass` とするか、`import a` して `a.SomeClass` とするかでパッチの当て方が変わってくるので注意が必要です。\n\n以下のファイルがある想定で実験してみます。\n\n```pyconfig\nterminal = false\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/a.py\"\nto_file = \"./a.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/b.py\"\nto_file = \"./b.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/c.py\"\nto_file = \"./c.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/test_b.py\"\nto_file = \"./test_b.py\"\n\n[[fetch]]\nfrom = \"../../../assets/posts/2023/03/test_c.py\"\nto_file = \"./test_c.py\"\n```\n\n`a.py` の `SomeClass` はテスト対象システムが依存しているクラスです。これがモックの対象となるクラスです。\n\n```python:a.py\nclass SomeClass:\n    def some_method(self):\n        raise NotImplementedError()\n```\n\n`b.py` の `SystemUnderTest` はその名の通りテスト対象システムです。`b.py` では `from a import SomeClass` で import してから `SomeClass()` でインスタンス化しています。\n\n\u003e この状態で `a.SomeClass` を patch() を使って mock out してもテストには影響しません。モジュール b はすでに 本物の `SomeClass` への参照を持っていて、パッチの影響を受けないからです。\n\u003e\n\u003e 重要なのは、 SomeClass が使われている (もしくはルックアップされている) 場所にパッチすることです。この場合、 `some_function` はモジュール b の中にインポートされた `SomeClass` をルックアップしています。\n\nなのでパッチする時は `@patch(\"b.SomeClass\")` とします。\n\n```python:b.py\nfrom a import SomeClass\n\n\nclass SystemUnderTest:\n    def some_function(self):\n        sc = SomeClass()\n        return sc.some_method()\n```\n\n`c.py` の `SystemUnderTest` もその名の通りテスト対象システムです。`ｃ.py` では `import a` で import してから `a.SomeClass()` でインスタンス化しています。\n\n\u003e この場合、パッチしたいクラスはそのモジュールからルックアップされているので、 `a.SomeClass` をパッチする必要があります\n\nなので `@patch(\"a.SomeClass\")` と書いてパッチを当てます。\n\n```python:c.py\nimport a\n\n\nclass SystemUnderTest:\n    def some_function(self):\n        sc = a.SomeClass()\n        return sc.some_method()\n```\n\nそれぞれに対するテストを書いて確かめてみます。`TestB` の `test_patching_a` はパッチが当たらないので失敗するはずです。\n\n```python:test_b.py\nimport unittest\nfrom unittest.mock import patch\n\nfrom b import SystemUnderTest\n\n\nclass TestB(unittest.TestCase):\n    @patch(\"a.SomeClass\")\n    def test_patching_a(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        # Call below will raise NotImplementedError since it is not patched\n        actual = sut.some_function()\n        assert actual == \"mock\"\n\n    @patch(\"b.SomeClass\")\n    def test_patching_b(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        actual = sut.some_function()\n        assert actual == \"mock\"\n```\n\n`TestC` の `test_patching_c` ではパッチを当てることに失敗します。\n\n```python:test_c.py\nimport unittest\nfrom unittest.mock import patch\n\nfrom c import SystemUnderTest\n\n\nclass TestC(unittest.TestCase):\n    @patch(\"a.SomeClass\")\n    def test_patching_a(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        actual = sut.some_function()\n        assert actual == \"mock\"\n\n    @patch(\"c.SomeClass\")  # will raise AttributeError\n    def test_patching_c(self, some_class_mock):\n        some_class_mock_instance = some_class_mock.return_value\n        some_class_mock_instance.some_method.return_value = \"mock\"\n        sut = SystemUnderTest()\n        actual = sut.some_function()\n        assert actual == \"mock\"\n```\n\n実行します。\n\n```python:main.py:pyscript\nfrom unittest import TestLoader\nfrom unittest import TextTestRunner\n\n\nloader = TestLoader()\ntest = loader.discover(\".\")\nrunner = TextTestRunner()\nrunner.run(test)\n```\n\n```pyterminal\n```\n\n期待通りの結果が得られていますね。Python の import まわりはやっぱりなんか面倒くさい・・・。\n\n## 参考文献\n\n* [unittest.mock --- モックオブジェクトライブラリ](https://docs.python.org/ja/3/library/unittest.mock.html)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"単体テスト","ref":"/tags/単体テスト"}],"showTerminalAside":true},{"title":"FastAPIとSQLAlchemy2.0ならもう型ヒントを諦めなくていい","date":"2023-02-08T00:00:00.000Z","ref":"/posts/2023/02/fastapi-orm-sqlalchemy","desc":" サチコ（Google Search Console）を眺めていたら `FastAPI MySQL` がそれなりに需要ありそうと思ったので、FastAPI と SQLAlchemy を組み合わせて ORM を使う方法を紹介したいと思います。最近の SQLAlchemy（1.4以降）ではマッピングされ","draft":false,"content":"\nサチコ（Google Search Console）を眺めていたら `FastAPI MySQL` がそれなりに需要ありそうと思ったので、FastAPI と SQLAlchemy を組み合わせて ORM を使う方法を紹介したいと思います。最近の SQLAlchemy（1.4以降）ではマッピングされたオブジェクトに型を適用することもできるので、型ヒントを活かして型安全なコードを書くことも難しくなくなっています。\n\n## 環境\n\n* Python 3.10.6\n* FastAPI 0.89.1\n* SQLAlchemy 2.0.1\n* Docker 20.10.13\n* Docker Compose v2.3.3\n\n## 前提\n\nFastAPI 公式ドキュメントの [SQL (Relational) Databases](https://fastapi.tiangolo.com/ja/tutorial/sql-databases/) のページを熟読しておいてください。\n\n2023年1月にリリースされた SQLAlchemy 2.0を使用します。1系を使用している既存プロジェクトの場合は [SQLAlchemy 2.0 - Major Migration Guide](https://docs.sqlalchemy.org/en/20/changelog/migration_20.html) を参考に2.0へ移行してください。1.4から2.0の移行はスムーズだと思います。\n\nSQLAlchemy で利用できる ORM のモデルの書き方はいくつかあります。個人的には [dataclass と統合した書き方](https://docs.sqlalchemy.org/en/20/orm/dataclasses.html)も好きですが、今回はシンプルにベーシックな実装を行います。\n\n## 成果物\n\nhttps://github.com/SogoKato/fastapi-sqlalchemy2\n\n```py\nfrom fastapi import Depends, FastAPI, HTTPException\nfrom pydantic import BaseModel\nfrom sqlalchemy import ForeignKey, String, create_engine, select\nfrom sqlalchemy.orm import (\n    DeclarativeBase,\n    Mapped,\n    Session,\n    mapped_column,\n    relationship,\n    sessionmaker,\n)\n\n\"\"\"\nSQLAlchemyのモデル.\n\nBased on:\n* https://docs.sqlalchemy.org/en/20/orm/quickstart.html#declare-models\n* https://fastapi.tiangolo.com/ja/tutorial/sql-databases/#create-the-database-models\n\"\"\"\n\n\nclass Base(DeclarativeBase):\n    \"\"\"各DBモデルの基底クラス.\"\"\"\n\n    pass\n\n\nclass User(Base):\n    \"\"\"usersテーブルのDBモデル.\"\"\"\n\n    __tablename__ = \"users\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    email: Mapped[str] = mapped_column(String(100), unique=True, index=True)\n    hashed_password: Mapped[str] = mapped_column(String(100))\n    is_active: Mapped[bool]\n\n    items: Mapped[list[\"Item\"]] = relationship(back_populates=\"owner\")\n\n\nclass Item(Base):\n    \"\"\"itemsテーブルのDBモデル.\"\"\"\n\n    __tablename__ = \"items\"\n\n    id: Mapped[int] = mapped_column(primary_key=True, index=True)\n    title: Mapped[str] = mapped_column(String(30), index=True)\n    description: Mapped[str] = mapped_column(String(30), index=True)\n    owner_id: Mapped[int] = mapped_column(ForeignKey(\"users.id\"))\n\n    owner: Mapped[\"User\"] = relationship(back_populates=\"items\")\n\n\n\"\"\"\nPydanticのモデル.\n\nBased on:\n* https://fastapi.tiangolo.com/ja/tutorial/sql-databases/#create-the-pydantic-models\n\"\"\"\n\n\nclass ItemBase(BaseModel):\n    \"\"\"Itemの基底クラス.\"\"\"\n\n    title: str\n    description: str | None = None\n\n\nclass ItemCreateRequest(ItemBase):\n    \"\"\"Item作成のリクエストを表現するクラス.\"\"\"\n\n    pass\n\n\nclass ItemResponse(ItemBase):\n    \"\"\"Itemのレスポンスを表現するクラス.\"\"\"\n\n    id: int\n    owner_id: int\n\n    class Config:\n        orm_mode = True\n\n\nclass UserBase(BaseModel):\n    \"\"\"Userの基底クラス.\"\"\"\n\n    email: str\n\n\nclass UserCreateRequest(UserBase):\n    \"\"\"User作成のリクエストを表現するクラス.\"\"\"\n\n    password: str\n\n\nclass UserResponse(UserBase):\n    \"\"\"Userのレスポンスを表現するクラス.\"\"\"\n\n    id: int\n    is_active: bool\n    items: list[ItemResponse] = []\n\n    class Config:\n        orm_mode = True\n\n\n\"\"\"\nDBのCRUD操作を行う関数.\n\nBased on:\n* https://docs.sqlalchemy.org/en/20/changelog/migration_20.html#migration-orm-usage\n* https://fastapi.tiangolo.com/ja/tutorial/sql-databases/#crud-utils\n\"\"\"\n\n\ndef get_db_user(db: Session, user_id: int):\n    \"\"\"usersテーブルからuser_idに一致するUserを取得します.\"\"\"\n    return db.execute(select(User).where(User.id == user_id)).scalars().first()\n\n\ndef get_db_user_by_email(db: Session, email: str):\n    \"\"\"usersテーブルからemailに一致するUserを取得します.\"\"\"\n    return db.execute(select(User).where(User.email == email)).scalars().first()\n\n\ndef get_db_users(db: Session, skip: int = 0, limit: int = 100):\n    \"\"\"usersテーブルからUserをすべて取得します.\"\"\"\n    return db.execute(select(User).offset(skip).limit(limit)).scalars().all()\n\n\ndef create_db_user(db: Session, user: UserCreateRequest):\n    \"\"\"usersテーブルにUserを追加します.\"\"\"\n    fake_hashed_password = user.password + \"notreallyhashed\"\n    db_user = User(\n        email=user.email, hashed_password=fake_hashed_password, is_active=True\n    )\n    db.add(db_user)\n    db.commit()\n    db.refresh(db_user)\n    return db_user\n\n\ndef get_db_items(db: Session, skip: int = 0, limit: int = 100):\n    \"\"\"itemsテーブルからItemをすべて取得します.\"\"\"\n    return db.execute(select(Item).offset(skip).limit(limit)).scalars().all()\n\n\ndef create_db_user_item(db: Session, item: ItemCreateRequest, user_id: int):\n    \"\"\"itemsテーブルにItemを追加します.\"\"\"\n    db_item = Item(**item.dict(), owner_id=user_id)\n    db.add(db_item)\n    db.commit()\n    db.refresh(db_item)\n    return db_item\n\n\n\"\"\"\nFastAPIでSQLAlchemyを使うためのセットアップ.\n\"\"\"\n# DBセッションを作成するクラスを作る.\nSQLALCHEMY_DATABASE_URL = \"mysql+mysqldb://user:password@db/test\"\n\n# デバッグ用にecho=Trueに設定.\nengine = create_engine(SQLALCHEMY_DATABASE_URL, echo=True)\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n\n# DBマイグレーションを行う.\nBase.metadata.create_all(bind=engine)\n\n# FastAPIをインスタンス化.\napp = FastAPI()\n\n\ndef get_db():\n    \"\"\"リクエストが来たらセッションを作成し、処理が完了したら閉じるためのDependency.\"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n\n\"\"\"\nFastAPIのルーティング.\n\"\"\"\n\n\n@app.post(\"/users/\", response_model=UserResponse)\ndef create_user(user: UserCreateRequest, db: Session = Depends(get_db)):\n    \"\"\"ユーザーを作成します.\"\"\"\n    db_user = get_db_user_by_email(db, email=user.email)\n    if db_user:\n        raise HTTPException(status_code=400, detail=\"Email already registered\")\n    return create_db_user(db=db, user=user)\n\n\n@app.get(\"/users/\", response_model=list[UserResponse])\ndef read_users(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n    \"\"\"ユーザーを一覧します.\"\"\"\n    users = get_db_users(db, skip=skip, limit=limit)\n    return users\n\n\n@app.get(\"/users/{user_id}\", response_model=UserResponse)\ndef read_user(user_id: int, db: Session = Depends(get_db)):\n    \"\"\"ユーザーを取得します.\"\"\"\n    db_user = get_db_user(db, user_id=user_id)\n    if db_user is None:\n        raise HTTPException(status_code=404, detail=\"User not found\")\n    return db_user\n\n\n@app.post(\"/users/{user_id}/items/\", response_model=ItemResponse)\ndef create_item_for_user(\n    user_id: int, item: ItemCreateRequest, db: Session = Depends(get_db)\n):\n    \"\"\"ユーザーのアイテムを作成します.\"\"\"\n    return create_db_user_item(db=db, item=item, user_id=user_id)\n\n\n@app.get(\"/items/\", response_model=list[ItemResponse])\ndef read_items(skip: int = 0, limit: int = 100, db: Session = Depends(get_db)):\n    \"\"\"アイテムを一覧します.\"\"\"\n    items = get_db_items(db, skip=skip, limit=limit)\n    return items\n```\n\n以上を `main.py` として保存して、下記の `Dockerfile` `docker-compose.yml` で `docker compose up --build` すれば動きます。\n\n```dockerfile\nFROM python:3.10\n\nWORKDIR /app\n\nENV PATH=$PATH:/root/.local/bin\nCOPY pyproject.toml poetry.lock ./\n\nRUN curl -sSL https://install.python-poetry.org | python3 - \\\n    \u0026\u0026 poetry install\n\nCMD [\"poetry\", \"run\", \"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--reload\"]\n```\n\n```yaml\nversion: '3'\nservices:\n  app:\n    build:\n      context: ./\n      dockerfile: Dockerfile\n    ports:\n      - '8000:8000'\n    volumes:\n      - type: bind\n        source: ./\n        target: /app\n  db:\n    image: mysql:8.0\n    environment:\n      MYSQL_ROOT_PASSWORD: password\n      MYSQL_DATABASE: test\n      MYSQL_USER: user\n      MYSQL_PASSWORD: password\n```\n\n## ちょこっと解説\n\n### SQL Alchemy 2.0 に対応させる\n\nコードを見ればそれがすべてなのであまり解説することはないのですが、FastAPI 公式ドキュメントの [SQL (Relational) Databases](https://fastapi.tiangolo.com/ja/tutorial/sql-databases/) のページとの大きな違いは、SQLAlchemy 2.0風な書き方になっているかどうかです。\n\nSQLAlchemy を使ったことのある方なら `session.query(User).filter(User.id == user_id).first()` のような書き方に慣れているかと思いますが、SQLAlchemy 2.0 ではこの書き方は[レガシーとされています](https://docs.sqlalchemy.org/en/20/orm/queryguide/query.html#legacy-query-api)。\n\nSQLAlchemy Core に統一された書き方が推奨されており、上記の例は以下のように書き換えられます。\n\n```py\nsession.execute(select(User).where(User.id == user_id)).scalars().first()\n```\n\n特徴は\n\n* ステートメント（SELECT ... WHERE ...）とその実行が明確に分離された\n* `Query` クラスではなく `Result` クラスや `ScalarResult` で `.all()` や `.first()` を使う\n\nことです。今までの API よりも分かりやすくなっていますし、型推論も効いているので使いやすいと思います。\n\nモデルクラスの書き方も変わっています。\n\n今までは以下のように定義していた部分が\n\n```py\nid = Column(Integer, primary_key=True, index=True)\n```\n\nこのようになります。\n\n```py\nid: Mapped[int] = mapped_column(primary_key=True, index=True)\n```\n\nそれっぽく移植していけば迷うことは少ないと思います。\n\n### DB セッションの取得には dependency を使う\n\nFastAPI の主要な機能の一つともいえる dependency を使って、DB セッションの生成を行うのが定番となっています。ちなみに、`SessionLocal` の命名は、`sqlalchemy.orm.Session` と区別するためだそうです。\n\n```py\ndef get_db():\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n```\n\nこの `get_db` dependency を使うことで、リクエストの開始時に DB セッションを生成し（`yield` の段階で渡される）、リクエストの処理が完了したら（finally 節で）DB セッションが閉じられるようになります。Dependency での `yield` の使い方については [Dependencies with yield](https://fastapi.tiangolo.com/ja/tutorial/dependencies/dependencies-with-yield/) をご参照ください。\n\nDependency は、別の dependency の中でも使うことができるので、リクエストの前処理（バリデーションなど）で引数に `db = Depends(get_db)` と指定することで、その中でも DB セッションを使うことができます。便利ですね。\n\n### Pydantic の ORM mode\n\n私のユースケースでは普段使っていないのですが、マッチすれば便利だなと思うのが Pydantic の `orm_mode = True` です。\n\nこれが有効になっていると、Pydantic が値を取得するときに `data[\"id\"]` のように辞書のキーだけでなく、`data.id` のように属性でも値を取得しようと試みるようになるそうです。これだけ聞いてもあまりピンときませんが、この違いがあることによって ORM が張っている relationship（通常は lazy loading なので求められるまでは存在していない）の値をとってくることが可能になるようです（`@property` で呼び出して値をとってこられるというようなことかなと予想しています）。\n\n## まとめ\n\n[Prisma Client Python](https://prisma-client-py.readthedocs.io/en/stable/) の型付けの開発者体験も結構好きでしたが、SQLAlchemy もまだまだ勢いがありますね。ぜひ活用してみてください。\n\n関連記事もどうぞ。  \n[SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ](/posts/2023/01/sqlalchemy-dealing-with-disconnects)\n\n## おまけ：API をたたいてみる\n\n```\n$ curl -s localhost:8000/users/ -XPOST \\\n  -H 'content-type: application/json' \\\n  -d '{\"email\": \"me@example.com\", \"password\": \"mystrongpassword\"}' \\\n  | jq\n```\n\n```json\n{\n  \"email\": \"me@example.com\",\n  \"id\": 1,\n  \"is_active\": true,\n  \"items\": []\n}\n```\n\n```\n$ curl -s localhost:8000/users/ | jq\n```\n\n```json\n[\n  {\n    \"email\": \"me@example.com\",\n    \"id\": 1,\n    \"is_active\": true,\n    \"items\": []\n  }\n]\n```\n\n```\n$ curl -s localhost:8000/users/?limit=0 | jq\n```\n\n```json\n[]\n```\n\n```\n$ curl -s localhost:8000/users/1 | jq\n```\n\n```json\n{\n  \"email\": \"me@example.com\",\n  \"id\": 1,\n  \"is_active\": true,\n  \"items\": []\n}\n```\n\n```\n$ curl -s localhost:8000/users/1/items/ -XPOST \\\n  -H 'content-type: application/json' \\\n  -d '{\"title\": \"LEVEL3\", \"description\": \"My favourite album\"}' \\\n  | jq\n```\n\n```json\n{\n  \"title\": \"LEVEL3\",\n  \"description\": \"My favourite album\",\n  \"id\": 1,\n  \"owner_id\": 1\n}\n```\n\n```\n$ curl -s localhost:8000/users/1 | jq\n```\n\n```json\n{\n  \"email\": \"me@example.com\",\n  \"id\": 1,\n  \"is_active\": true,\n  \"items\": [\n    {\n      \"title\": \"LEVEL3\",\n      \"description\": \"My favourite album\",\n      \"id\": 1,\n      \"owner_id\": 1\n    }\n  ]\n}\n```\n\n```\n$ curl -s localhost:8000/items/ | jq\n```\n\n```json\n[\n  {\n    \"title\": \"LEVEL3\",\n    \"description\": \"My favourite album\",\n    \"id\": 1,\n    \"owner_id\": 1\n  }\n]\n```\n\n## 参考文献\n\n* [SQL (Relational) Databases](https://fastapi.tiangolo.com/ja/tutorial/sql-databases/)\n* [ORM Quick Start](https://docs.sqlalchemy.org/en/20/orm/quickstart.html)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"},{"name":"ORM","ref":"/tags/orm"}],"showTerminalAside":false},{"title":"TypedDictはdictのsubtypeではないので関数の引数にはMappingを使う","date":"2023-02-06T00:00:00.000Z","ref":"/posts/2023/02/typeddict-is-not-subtype-of-dict","desc":" Python の dict（辞書）を TypeScript の interface のように扱えて便利な TypedDict ですが、**dict のサブクラスではない**というのが少し落とし穴だなと思ったのでメモ。\n\n##","draft":false,"content":"\nPython の dict（辞書）を TypeScript の interface のように扱えて便利な [TypedDict](https://peps.python.org/pep-0589/) ですが、**dict のサブクラスではない**というのが少し落とし穴だなと思ったのでメモ。\n\n## まずは PEP を見よう\n\n大抵のことは公式ドキュメントを見れば書いてあります。今回も例外なくそうでした。\n\n\u003e First, any TypedDict type is consistent with `Mapping[str, object]`.\n\nhttps://peps.python.org/pep-0589/#type-consistency\n\n言いたいことは以上です。関数の引数として、その TypedDict 以外の辞書も受け取りたいときは Mapping を使いましょう。\n\n```py\nfrom typing import Mapping, TypedDict\n\nclass Movie(TypedDict):\n    name: str\n    year: int\n\ndef from_mapping(map: Mapping[str, object]):\n    \"\"\"TypedDictを含む任意のマップを受け取る関数.\"\"\"\n\ndef from_dict(dict: dict[str, object]):\n    \"\"\"任意のdictを受け取る関数.\"\"\"\n\nmovie: Movie = {\n  \"name\": \"Harry Potter and the Philosopher's Stone\",\n  \"year\": 1999,\n}\n\n# OK\nfrom_mapping(movie)\n\n# NG\nfrom_dict(movie)\n```\n\n## どんなエラーが出る？\n\n型ヒントなので実行時にエラーになることはありませんが、静的型検査で怒られます。\n\n```\n$ poetry run pyright main.py\n...\npyright 1.1.292\n/path/to/main.py\n  /path/to/main.py:22:11 - error: Argument of type \"Movie\" cannot be assigned to parameter \"dict\" of type \"dict[str, object]\" in function \"from_dict\"\n    \"Movie\" is incompatible with \"dict[str, object]\" (reportGeneralTypeIssues)\n1 error, 0 warnings, 0 informations\nCompleted in 0.512sec\n```\n\nちなみに上記の例では `Mapping[str, object]` を使っていますが `Mapping[str, Any]` でも問題ないです。\n\n## まとめ\n\nとりあえず `dict[str, Any]` でいけるかな～と思っていたら引っかかったので勉強になりました。\n\n少し話はそれますが[ロバストネス原則](https://ja.wikipedia.org/wiki/%E3%83%AD%E3%83%90%E3%82%B9%E3%83%88%E3%83%8D%E3%82%B9%E5%8E%9F%E5%89%87)というのを最近知りました。\n\n\u003e 貴方が自分ですることに関しては厳密に、貴方が他人から受けることに関しては寛容に  \n\u003e (be conservative in what you do, be liberal in what you accept from others)\n\n今回の例では `dict[str, Any]` を引数として指定するよりも `Mapping[str, Any]` と書くほうが、よりソフトウェアを堅牢な作りにできるのかもと思いました。ちょっと影が薄い（？）Mapping くん、有効に活用していきたい所存です。\n\n## 参考文献\n\n* https://peps.python.org/pep-0589/\n* https://stackoverflow.com/questions/73242556/typeddict-class-is-an-incompatible-type-for-function-expecting-dict\n\nRobustness Principle 的にも Mapping を使うようにした方がいいかも\n","tags":[{"name":"Python","ref":"/tags/python"}],"showTerminalAside":false},{"title":"SQLAlchemyで'MySQL server has gone away'が発生した時の対処法2つ","date":"2023-01-12T00:00:00.000Z","ref":"/posts/2023/01/sqlalchemy-dealing-with-disconnects","desc":" FastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2","draft":false,"content":"\nFastAPI で SQLAlchemy を使っている時に、コンテナを立てた直後は問題ないけど一定時間経過後に DB 接続が切れてしまう問題に遭遇したのでその時に調べたことのメモ。\n\n## 環境\n\n* mysql 5.7.15\n* SQLAlchemy 1.4.45\n* mysqlclient 2.1.1\n\n## 問題\n\n```\nMySQLdb.OperationalError: (2006, 'MySQL server has gone away')\n```\n\n最後に MySQL サーバーに接続してから一定時間（デフォルトで8時間）が経過すると上記のエラーにより DB へのアクセスに失敗します。\n\n## 原因\n\nSQLAlchemy には Connection Pooling という、DB サーバーとのコネクションを内部的に保持する機能が存在します。また、MySQL には一定時間（デフォルトで8時間）が経過するとコネクションを破棄する機能が存在します。\n\nその結果、SQLAlchemy 側で保持しているコネクションを使ってクエリを投げたりしても、MySQL 側でコネクションが破棄されている場合には `MySQL server has gone away` のエラーが出てしまうことになります。\n\n`show global variables like 'wait_timeout';` によって、現在設定されている `wait_timeout` の秒数を知ることができます。\n\n```\nmysql\u003e show global variables like 'wait_timeout';\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| wait_timeout  | 28800 |\n+---------------+-------+\n1 row in set (0.00 sec)\n```\n\n生きているコネクションは `show processlist` で知ることができます。`Time` が経過時間（秒）です。\n\n```\nmysql\u003e show processlist;\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n| Id      | User  | Host            | db   | Command | Time  | State    | Info             |\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n| 1200000 | scott | localhost:47000 | test | Query   |     0 | starting | show processlist |\n| 1200001 | scott | localhost:47001 | test | Sleep   |  3600 |          | NULL             |\n+---------+-------+-----------------+------+---------+-------+----------+------------------+\n2 rows in set (0.00 sec)\n```\n\n## 解決方法\n\n[SQLAlchemy の公式ドキュメント](https://docs.sqlalchemy.org/en/20/core/pooling.html#dealing-with-disconnects)に書かれているように、大きく「悲観的」「楽観的」2つのアプローチがあります。\n\nどちらを採用するかは要件や好みによると思います。どちらの方法にしても、コネクションプールからチェックアウトした後に MySQL 側で破棄されてしまうようなケースでは無効なのでご注意ください（一度の処理でそんなに長く扱うことは少ないとは思いますが）。\n\n### 悲観的アプローチ\n\nコネクションプールから取り出すときに、そのコネクションがまだ生きているかどうかをテストする方法です。私は今回こちらを採用しました。\n\nコネクションのチェックアウト時に若干のオーバーヘッドができてしまいますが、最もシンプルで信頼できるアプローチとされています。\n\n```py\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+mysqldb://scott:tiger@localhost/test\", pool_pre_ping=True)\n```\n\n### 楽観的アプローチ\n\n一定時間ごとにコネクションを張り直す方法です。例えば、DB サーバー側で28800秒に設定されているのならば、それよりも短く設定すればよいです。\n\n使っていても使っていなくても一定時間おきに DB へのリクエストが飛んでしまいますが、コネクションのチェックアウト時にオーバーヘッドが発生しないのが利点です。\n\n```py\nfrom sqlalchemy import create_engine\n\nengine = create_engine(\"mysql+mysqldb://scott:tiger@localhost/test\", pool_recycle=3600)\n```\n\n## 参考文献\n\n* [Connection Pooling](https://docs.sqlalchemy.org/en/20/core/pooling.html)\n* [Python: SQLAlchemy で 'MySQL server has gone away' になる問題を解決する](https://blog.amedama.jp/entry/2015/08/15/133322)\n* [full-stack-fastapi-postgresql/session.py at master · tiangolo/full-stack-fastapi-postgresql](https://github.com/tiangolo/full-stack-fastapi-postgresql/blob/master/%7B%7Bcookiecutter.project_slug%7D%7D/backend/app/app/db/session.py)\n","tags":[{"name":"Python","ref":"/tags/python"},{"name":"SQLAlchemy","ref":"/tags/sqlalchemy"}],"showTerminalAside":false},{"title":"よくあるSPA+API構成でのOpenID Connectクライアント実装","date":"2022-12-02T00:00:00.000Z","ref":"/posts/2022/12/openid-connect-fastapi","desc":" この記事はニフクラ等を提供している、富士通クラウドテクノロジーズ Advent Calendar 2022の2日目の記事です。\n\n昨日は [@nt","draft":false,"content":"\nこの記事は[ニフクラ](https://www.nifcloud.com/)等を提供している、[富士通クラウドテクノロジーズ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/fjct)の2日目の記事です。\n\n昨日は [@ntoofu](https://qiita.com/ntoofu) さんの [パケットキャプチャからKubernetes APIのTLS通信を解析する](https://ntoofu.github.io/blog/post/sniffing-kube-apiserver-tls/) でした。  \n私は TLS な時点でパケットキャプチャを諦めてしまいそうですが Linux の便利な仕組みと気合があれば TLS 1.3 のパケットキャプチャも可能だとわかり、とても有益でした。私もギークなエンジニア目指して頑張ります。\n\n今日は OpenID Connect のクライアントをどう実装するかについて検討してみたいと思います。\n\nFastAPI + SPA (Vue.js) でちょっとした社内ツールを開発した時に社内の認可基盤との OpenID Connect を用いたログイン連携機能を作りたかったのですが、実装のための情報が少なかったので記事に残しておきたいと思ったのがきっかけです。「これがベストプラクティスだ！」というわけではありませんが、1つの実践例としてどなたかの参考になれば幸いです。\n\n## 対象読者\n\n* OpenID Connect を使ってログインするアプリを作りたいけど実装方法がわからない人\n  * 色んなフローがあるっぽいけどどれを使うべき？\n  * アクセストークン？ ID トークン？\n  * サーバーで何してクライアントで何するの？\n* Python の FastAPI で作ったサーバーでのログイン〜リダイレクト〜トークン検証の実装例が知りたい人\n\n## OpenID Connect とは\n\n**OpenID Connect は OAuth 2.0 を拡張する形で策定された、認証・認可のための仕組み**です。OAuth 2.0 は認可を行うことを目的とした仕様です。すでに10年も前の話ですが、OAuth を認証にも使ってしまう「SNS ログイン」の手法は「[単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる](https://www.sakimura.org/2012/02/1487/)」と指摘されていました。OpenID Connect は OAuth 2.0 を拡張して認証の用途にも使えるようにした、ID トークンを発行するための仕組みとなっています。\n\n下図は認証・認可の流れの一例です（response_type=id_token の場合）。\n\n![overview](//www.plantuml.com/plantuml/png/NP6zIiDG5CVt-nINJkbGgBg9I0SNfrlo1g7DKD0q9EckzpW4KHfGS6aH9KWeIeMYK1FmOGv9u-GhUEvDH9lbSCBv_J_2xVc1vGMJqnDc3OAnnn6U43AKxpIvvVE9Rtjyx0rfxdIPI-neC78j9-0jb6yAXHkKQswO_NPB2Sn-ZUysSE7Qpl4HmXt22qA4CaOuuuQeTU9NjzTbEhHpgBpskSBbgyPN23EKdsgHIuG50j3222DOABXSN9T9HYS5o8IQ8OILtq67a8RVvZRzcZyYf7bqLLnCgy_o8Td47vMewPlIaa-NJEX8y__fMOVDTRcreVuqHCXqqLMRcN-2xLCHpqXUtrLces8HHldb_NTspdgsCwI7-W40)\n\nOP: OpenID Provider; ID トークンの発行者  \nRP: Relying Party; OP に認証機能を既存するクライアントアプリ\n\nユーザーがサービスにログインしようとすると、サービスはまず OpenID プロバイダー（OP）のエンドポイントに対してユーザーをリダイレクトします。OP は未認証であればログイン画面を出しユーザーを認証してから、サービスに対して認可を行うかどうか同意を取ります。ユーザーが同意すると、OP は ID トークンをリクエストに含めてサービスのコールバック URL にリダイレクトします。サービスは受け取った ID トークンが正規の OP からのものであることを OP の公開鍵を使用して検証します（そのほかにも複数の検証をする）。検証が正常に終了すればサービスへのログインの処理は完了です。\n\n## で、どうやってクライアントを実装するの？\n\n### まずは結論\n\n![code flow](//www.plantuml.com/plantuml/png/RPBFIW9H5CRtzoakhdGXJNzM4Q7GnfL3FS6aBeHI6KTewTmROQ4e94YWX28XKXdq1t8a7-OuEgvwXRwPKN2apULSlz_vpdUk4oiQccwKBY-ObZBoEYVvH792uWidrugyLCpeFA-dSUugx3n_nKCaFbr4tfFuvk5JDH9Y1NXaKzc2bZFucHfVDUmf0I6k9bR2li8okJI7Mm089GkPNEA4P8la2ya6YJx9CWydCSBDabHN_GSAyt95ZxrfXzpbnPl7lvDiavYwXHYH79AKA1Wuu6w6RTniaVb3vWE31WHJG3Z3cZEOkEqm4GDiIhBY3psA0jaoMJIjPQT7qh8RrVbrtRywtS6YF_QRjdqj57PznF2Zdsf3U_QcTM2B8ko39B0NjDj8C6PGN9RDsRGRC2NHyrQm_1N0uGhh7RppnjMPDktQX--zRWqIytuRwLpY_sUtNwkpyStwdRsbWy2yqh3l7dyd9elXpySNzmS0)\n\n* API サーバーで認証リクエストや ID トークン検証を行う\n  * 今回は採用するライブラリの都合で Authorization Code Flow を使います\n* ID トークンは Cookie で管理\n  * localStorage ではセキュリティ上問題がある\n  * インメモリでは利便性に欠ける\n  * Cookie の属性\n    * HttpOnly: true\n      * JavaScript からは触らせない\n    * SameSite: Lax\n      * 他サイトへの Cookie 送信を最低限にする\n      * Strict にすると OP にリダイレクトした際に破棄されてしまうため Lax\n    * Secure: true\n      * HTTPS でのみ Cookie を送信する\n\n### SPA なら全部 SPA にやらせればいいんじゃないの？\n\nはい、Implicit Flow を使うことで実現できます。\n\n冒頭の「車が通れるほどのどでかいセキュリティー・ホール」の話は OAuth 2.0 を Implicit Flow で使用した時の話ですが、OpenID Connect はそれを踏まえて策定された仕様なので、OpenID Connect において Implicit Flow を使うことに問題はありません。\n\nImplicit Flow を使う場合、下図のようになります（response_type=id_token）。\n\n![implicit flow](//www.plantuml.com/plantuml/png/TP9FIm916CRlyoa6JteGjZydYL3euicbFi6c7eHIMLVegFD6I1WA1LsKC2H4AWCfq5tmmxpkkfxw2hqpxWO3THbcz_dDypppxcORZcKxpSiBPXMTciqHNX0y55-qSgl1cusopMjsYTOzWvtNhdW2nQT4u1x5WYTFpLI2rScZKgpKhQh3pynST63Vq8IScO-40uELgoLERXgGADJBrVm9mYF26q8VnHYXnPC5Yf1T2cPq_j1WgbVwMALbkEJ5X-Bd20CKAxaHCuGf0j264KSuMH0TJk_2YKUQ9CI4he7GsJaUfIMY6suUtEtm6S7r-ztWkhTx34UJpNWPrz1zNThulHcZbxyDO-rLfGrLlKLINhQZvarLvwcufPnKXklYjjLUhqQCfF-8O3oW24dyFHZ_lRjUtiGPghaE19s-V_lqxRLPbZuF_HC_)\n\n上記のフローでは、SPA 側で Client Secret を管理する必要がありません。ClientSecret が必要になるのは主にトークンエンドポイント（認可コードやアクセストークンを使って、アクセストークンや ID トークンを取得するためのやつ）を使う時なので、response_type=id_token で OIDC クライアントを実装する場合には困りません。response_type=id_token で問題がないかという観点では、ログイン完了時にだけユーザー情報が手に入れば問題ない場合（ユーザー情報が最新である必要がない場合）には事足りると思われます。\n\nSPA でエンドユーザーに見せたくない機密情報を扱うのはほとんど不可能だと思いますので Client Secret を SPA に持たせる必要がないのは嬉しい仕様ですね。**Implicit Flow では CSRF 対策のために nonce の検証が必須**なので注意してください。\n\n### ID トークンどこ置く問題\n\nただ、Client Secret を SPA で管理する必要がないからといって SPA 上で ID トークンを扱えるようにすると、ID トークンをどこに保管するか、という問題が出てきます。これは OIDC のスコープ外の議論ですが、クライアント実装にあたって必ず検討するべき点だと思うので、今回はこれも考えていきたいと思います。\n\nID トークンを置く場所として考えられる候補を比較してみます。\n\n||Cookie (HttpOnly: true, Secure: true, SameSite: Lax)|インメモリ|localStorage|\n|---|---|---|---|\n|保持期間|**設定された有効期限まで**|ページがリロードされるまで|**なし**|\n|CSRF 対策|**更新系は防げる**|**他の JS ライブラリは基本的にアクセスできない**|どの JS ライブラリも取得可|\n|JS での ユーザー情報取得|できない [^1]|**できる**|**できる**|\n\n[^1]: サーバー側で Cookie の ID トークンを検証した上で、JSON レスポンスでユーザー情報を返却する API を作ったりすれば可能です。\n\nどれも一長一短な感がありますが、この中で一番安全性と利便性のバランスがいいのは Cookie (HttpOnly: true, Secure: true, SameSite: Lax) だと思ったので、今回は Cookie に ID トークンを置くようにしました。\n\nなお、Auth0 のクライアントライブラリではインメモリに ID トークンを保存しつつ、セッションを長く保たせることもできるようです。  \n[SPA認証トークンはlocalStorageでもCookieでもない、Auth0方式はいいねというお話](https://mizumotok.hatenablog.jp/entry/2021/08/04/114431)\n\n## FastAPI で OpenID Connect クライアントを実装する\n\n以上で、一通りクライアントの実装方針について議論ができたと思うので、ここからは具体的な Python (FastAPI) での実装に移りたいと思います。  \n今回使うライブラリ Authlib では FastAPI の他に Starlette, Flask や Django の Oauth Client とその実装例も公開されているので、それらを参考にすれば他のフレームワークでも割と簡単に実装できるのではないかなと思います。\n\n### ソースコード\n\nhttps://github.com/SogoKato/oidc-fastapi-authlib\n\n動かしてみたい方は README に従って起動してみてください。\n\n### 必要なもの\n\n前準備として OpenID プロバイダを用意する必要があります。どのプロバイダでも大丈夫ですが、まだ持っていない場合は [Auth0](https://auth0.com/jp) に登録してみるのがおすすめです。個人で使うようなリクエスト量であれば無料で使えます（2022年12月現在）。\n\n登録後、Application を作成したら、リダイレクト URI (Allowed Callback URLs) に `http://localhost:8080/api/auth` を入れておきます。また、下記の情報を探してメモっておきましょう。\n\n* Client ID\n* Client Secret\n* OpenID Configuration Endpoint\n  * アクセスすると OIDC クライアントで必要な情報を返してくれるエンドポイント\n  * 通常 `https://example.com/.well-known/openid-configuration`\n\n### アーキテクチャ\n\n![architecture](//www.plantuml.com/plantuml/png/SoWkIImgAStDuKfCBialKdZSlEnnyvx7JTk0f49YiK9fSMeHLs9HSaPcRc99ge9oIMfoHbv-JdvwfK9UUcPUXOAD3L15MMPogfqT3dME0Pv4g5Bo2F7rqNSE3jRt2bO2sGnqM4bcCefEa6CKTEsWDbi17RlgSTFwnqqh7ZVjVDpSmGKHrzMr0za9bDTFBCX4249D18bpEQJcfG0z3G00)\n\n今回は Cookie の SameSite 属性を使用しているので、SPA と API とで同じドメイン名を使い、パスでリクエストを振り分けます。\n\n### 解説\n\n#### ログイン時の処理\n\n```python\napp = FastAPI()\napp.add_middleware(SessionMiddleware, secret_key=\"MYSTRONGKEY\", https_only=True)\n```\n\nFastAPI の初期化と Cookie のための SessionMiddleware の追加をします。\n\n```python\noauth = OAuth()\noauth.register(\n    name=\"auth0\",\n    server_metadata_url=\"https://example.com/.well-known/openid-configuration\",\n    client_id=\"クライアントID\",\n    client_secret=\"クライアントシークレット\",\n    client_kwargs={\"scope\": \"openid profile\"},\n)\n```\n\nAuthlib のインスタンスを作ります。scope に `openid` と入れておくことで Authorization Code Flow の時にトークンエンドポイントで ID トークンが手に入ります。\n\n```python\n@app.get(\"/api/login\")\nasync def login(request: Request):\n    redirect_uri = request.url_for(\"auth\")\n    return await oauth.auth0.authorize_redirect(request, redirect_uri)\n```\n\n認証リクエストを開始するためのエンドポイントです。ユーザーがここにアクセスすることで `http://localhost:8080/api/auth` をリダイレクト URI とした認証リクエストを開始します（OpenID プロバイダにリダイレクトされる）。\n\nちなみにこんな URL でリダイレクトされます。state と nonce があることも確認できますね。\n\n```\nhttps://example.com/authorize\n  ?response_type=code\n  \u0026client_id=クライアントID\n  \u0026redirect_uri=http%3A%2F%2Flocalhost%3A8080%2Fapi%2Fauth\n  \u0026scope=openid+profile\n  \u0026state=PGO5TxTujESoXuLlfzYTWZsioK5Up5\n  \u0026nonce=HfyA3eugosoOuieiTGRZ\n```\n\n![OP login](/images/posts/2022/12/oidc_op_login.png)\n\nログインが完了するとリダイレクト URI にリダイレクトされ、次のエンドポイントが呼ばれます。\n\n```python\n@app.get(\"/api/auth\")\nasync def auth(request: Request):\n    try:\n        token = await oauth.auth0.authorize_access_token(request)\n    except OAuthError:\n        logger.exception(\"An error occurred while verifying authorization response.\")\n        raise UnauthenticatedError()\n    userinfo = token.get(\"userinfo\")\n    # userinfoのclaims(subやnameなど)を使ってDBにユーザーを登録する処理がここにきます.\n    request.session[\"id_token\"] = token.get(\"id_token\")\n    return RedirectResponse(url=\"/\")\n```\n\n`authorize_access_token` で認可コードと state を使って ID トークンを取得し、ID トークンと nonce を検証するところまでやってくれます（楽ちん）。  \nその後は自分の好きなように処理をして OK です。sub クレームをユーザー ID として、ユーザーがまだ DB に登録されていなければ insert するとか、ユーザーのプロフィール情報が変わってたら更新するとか、そういう処理が来るのかなと思います。\n\n最後に、Cookie に ID トークンをセットして `/` にリダイレクトして、ログイン処理は完了です。\n\n#### ログイン後の処理\n\nログイン後は JS 側で fetch や axios でリクエストをすると、Cookie も自動的に送信されます。なので、ログインしたユーザーにしか使わせたくないエンドポイントでは、Depends を使って ID トークンを検証します。\n\n```python\n@app.get(\"/api/items\")\nasync def list_items(user: User = Depends(verify_user)):\n    logger.info(f\"Successful log in: user_id={user.id} name={user.name}\")\n    return {\n        \"items\": [\n            {\"name\": \"Teddy bear\", \"icon\": \"🧸\", \"price\": 99},\n            {\"name\": \"Apple\", \"icon\": \"🍎\", \"price\": 2},\n            {\"name\": \"Sushi\", \"icon\": \"🍣\", \"price\": 200},\n            {\"name\": \"Bento\", \"icon\": \"🍱\", \"price\": 50},\n        ]\n    }\n```\n\n`verify_user` 関数で Cookie から ID トークンを取り出します。\n\n```python\nasync def verify_user(request: Request):\n    id_token = request.session.get(\"id_token\")\n    if id_token is None:\n        raise UnauthenticatedError()\n    decoded_jwt = await verify_token(id_token=id_token)\n    # DBにユーザーが登録されているか確認する処理がここにきます.\n    # user = user_repo.select_by_user_id(user_id=user_id)\n    return user\n```\n\n`verify_token` が ID トークンを検証する関数です。\n\n```python\nasync def verify_token(id_token: str):\n    jwks = await oauth.auth0.fetch_jwk_set()\n    try:\n        decoded_jwt = jwt.decode(s=id_token, key=jwks)\n    except Exception:\n        logger.exception(\"An error occurred while decoding jwt.\")\n        raise UnauthenticatedError()\n    metadata = await oauth.auth0.load_server_metadata()\n    if decoded_jwt[\"iss\"] != metadata[\"issuer\"]:\n        raise UnauthenticatedError()\n    if decoded_jwt[\"aud\"] != settings.oidc_client_id:\n        raise UnauthenticatedError()\n    exp = datetime.fromtimestamp(decoded_jwt[\"exp\"])\n    if exp \u003c datetime.now():\n        raise UnauthenticatedError()\n    return decoded_jwt\n```\n\nID トークンの検証として最低限必要なのは以下の通りです（Authorization Code Flow の場合）。\n\n1. JWK Set（OP の公開鍵）を使用して JWT をデコードする\n2. iss クレーム（Issuer Identifier; 発行者）を検証する\n3. aud クレーム（Audience(s); 誰に対して発行したか = Client ID）を検証する\n4. exp クレーム（Expiration time; 有効期限）を検証する\n\n以上が完了すれば基本的な OIDC クライアント実装は完了です🎉\n\n![log in](/images/posts/2022/12/oidc_log_in.gif)\n\n## 最後に\n\nいかがでしたか？？\n\n一見複雑そうな OpenID Connect ですが、一つずつ紐解いてみると意外と簡単に実装できるように仕様が設計されていることがわかりました。自分でパスワードを頑張って管理するよりもこういうところは信頼できる OpenID プロバイダに任せてしまった方が楽ですし、何よりも安全ですよね。\n\nぜひ皆さんも Web サービスを作る時には活用してみてください。\n\nこの記事は[富士通クラウドテクノロジーズ Advent Calendar 2022](https://qiita.com/advent-calendar/2022/fjct)の2日目の記事でした。\n\n明日は [@Syuparn](https://qiita.com/Syuparn) さんが SQL のテストについて書いてくれるようです。  \nSQL のテストってあまりやってなかったりするので、他の人がどのように考えて実施しているのか気になります。それでは、明日の記事もお楽しみに！\n\n（👇この記事がよかったらいいねボタンを押してください！）\n\n## 参考文献\n\n* [OpenID Connect Basic Client Implementer's Guide 1.0 - draft 42](https://openid.net/specs/openid-connect-basic-1_0.html)\n* [OpenID Connect Implicit Client Implementer's Guide 1.0 - draft 25](https://openid.net/specs/openid-connect-implicit-1_0.html)\n* [Google login for FastAPI](https://blog.authlib.org/2020/fastapi-google-login)\n* [一番分かりやすい OpenID Connect の説明](https://qiita.com/TakahikoKawasaki/items/498ca08bbfcc341691fe)\n* [IDトークンが分かれば OpenID Connect が分かる](https://qiita.com/TakahikoKawasaki/items/8f0e422c7edd2d220e06)\n* [OpenID Connect 全フロー解説](https://qiita.com/TakahikoKawasaki/items/4ee9b55db9f7ef352b47)\n* [OAuth 2.0/OpenID Connectの2つのトークンの使いみち](https://qiita.com/wadahiro/items/ad36c7932c6627149873)\n* [単なる OAuth 2.0 を認証に使うと、車が通れるほどのどでかいセキュリティー・ホールができる](https://www.sakimura.org/2012/02/1487/)\n* [OIDCのImplicit FlowでClientSecretを使わずにID連携する](https://zenn.dev/ritou/articles/a)\n* [SPA認証トークンはlocalStorageでもCookieでもない、Auth0方式はいいねというお話](https://mizumotok.hatenablog.jp/entry/2021/08/04/114431)\n* [GoでOpenID ConnectのClientを実装する（実装編）](https://times.hrbrain.co.jp/entry/go-openid-connect-implement)\n","tags":[{"name":"OpenID Connect","ref":"/tags/openid-connect"},{"name":"認証/認可","ref":"/tags/認証-認可"},{"name":"SPA","ref":"/tags/spa"},{"name":"Python","ref":"/tags/python"},{"name":"FastAPI","ref":"/tags/fastapi"}],"showTerminalAside":false}],"pages":[1],"currentPage":1,"tag":{"name":"Python","ref":"/tags/python"}},"__N_SSG":true},"page":"/tags/[tag]/page/[page]","query":{"tag":"python","page":"1"},"buildId":"p-ZcBjky8xbDNJC8ns1xV","isFallback":false,"gsp":true,"scriptLoader":[{"async":true,"src":"https://www.googletagmanager.com/gtag/js?id=G-RE7Q7WBFDJ","strategy":"afterInteractive"},{"id":"_gtag","defer":true,"dangerouslySetInnerHTML":{"__html":"\n              if (window.location.hostname === \"sogo.dev\") {\n                window.dataLayer = window.dataLayer || [];\n                function gtag(){dataLayer.push(arguments);}\n                gtag(\"js\", new Date());\n                gtag(\"config\", \"G-RE7Q7WBFDJ\");\n              }"},"strategy":"afterInteractive"}]}</script></body></html>