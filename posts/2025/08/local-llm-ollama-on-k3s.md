---
title: "è‡ªå®…PCã‚’ãƒ­ãƒ¼ã‚«ãƒ«LLMã‚µãƒ¼ãƒã«ã™ã‚‹ã€Nvidia/K3s/Ollama/Gemma3ã€‘"
date: "2025-08-14"
tags: ["LLM", "GPU", "K3s", "Kubernetes", "è‡ªå®…ã‚µãƒ¼ãƒãƒ¼"]
---

[å€‹äººçš„Ubuntu24.04 Serverã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ¡ãƒ¢](/posts/2025/08/setup-ubuntu-server) ã®ç¶šãã§ã™ã€‚VRAM 8 GB ã—ã‹ãªã„ GPU ã§ã€ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«å…¥åŠ›å¯èƒ½ãªãƒ­ãƒ¼ã‚«ãƒ« LLM ã‚µãƒ¼ãƒãƒ¼ã‚’æ§‹ç¯‰ã—ã¦ã„ãã¾ã™ã€‚çµè«–ã€ã“ã‚Œã‹ã‚‰ãƒ­ãƒ¼ã‚«ãƒ« LLM ã®ãŸã‚ã« GPU ã‚’ç”¨æ„ã™ã‚‹ãªã‚‰ RTX 40xx ä¸–ä»£ä»¥é™ãŒãŠã™ã™ã‚ã€‚

## ç’°å¢ƒ

* Ubuntu 24.04 Server
* Ryzen 7 3700X
* ãƒ¡ãƒ¢ãƒª 32GB
* NVIDIA GeForce RTX 2070
  * VRAM 8 GB
* nvidia-driver-575 575.64.03-0ubuntu0.24.04.1
* NVIDIA Container Toolkit 1.17.8-1
* K3s v1.32.6+k3s1
* Helm v3.15.3
* NVIDIA GPU Operator 25.3.2
* ~~vLLM v0.10.0~~
* Ollama v0.11.2

## å‰ææ¡ä»¶

* Nvidia ãƒ‰ãƒ©ã‚¤ãƒã‚’å°å…¥æ¸ˆã¿
* Nvidia Container Toolkit ã‚’å°å…¥æ¸ˆã¿
* K3s ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ¸ˆã¿

å„æ‰‹é †ã¯ [å‰å›ã®è¨˜äº‹](/posts/2025/08/setup-ubuntu-server) ã‚’å‚ç…§

## NVIDIA GPU Operator å°å…¥

K3s ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«ã¯ãƒ‰ãƒ©ã‚¤ãƒã¨ container toolkit ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ãŸçŠ¶æ…‹ã§ K3s ã‚’ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã™ã‚Œã°ã€ãã®ã¾ã¾ pod ã§ GPU ã‚’è¦æ±‚ã™ã‚Œã°å‹•ããµã†ã«æ›¸ã‹ã‚Œã¦ã„ã¾ã™ãŒã€ç­†è€…ã®ç’°å¢ƒã§ã¯ãƒ€ãƒ¡ã ã£ãŸã®ã§ã€ãƒãƒƒãƒˆã®æƒ…å ±ã‚’é ¼ã‚Šã« [^1] NVIDIA GPU Operator ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã—ãŸã€‚

[^1]: [k3sã§Nvidia GPUã‚’ä½¿ç”¨ã™ã‚‹](https://cloudandbuild.jp/blog/article-20240914) ã®è¨˜äº‹ã§ã‚‚ k3s æ§‹ç¯‰ç›´å¾Œã®çŠ¶æ…‹ã§ã¯ GPU ãŒä½¿ãˆãªã„ã¨æ›¸ã‹ã‚Œã¦ã„ã‚‹ã€‚

(ä»¥ä¸‹ã€å®Ÿéš›ã«ã¯ [Helmfile](https://helmfile.readthedocs.io/en/latest/) ã‚’ä½¿ã£ã¦ã„ã‚‹ã®ã§ã‚³ãƒãƒ³ãƒ‰ã¯é–“é•ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹)

```sh
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update
```

```sh
helm install --wait --generate-name \
  -n gpu-operator --create-namespace \
  nvidia/gpu-operator \
  --version=v25.3.2 \
  --values=values.yaml
```

`values.yaml`

```yaml
operator:
  runtimeClass: nvidia
  # upgrade CRD on chart upgrade, requires --disable-openapi-validation flag
  # to be passed during helm upgrade.
  upgradeCRD: true
driver:
  enabled: false
toolkit:
  enabled: false
dcgmExporter:
  enabled: false
  config:
    name: ""
```

[NVIDIA GPU Operator ã®ãƒšãƒ¼ã‚¸](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html) ã«æ›¸ã‹ã‚Œã¦ã„ã‚‹ã‚ˆã†ã«ã€ãƒãƒ¼ãƒ‰ä¸Šã«ãƒ‰ãƒ©ã‚¤ãƒã¨ container toolkit ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ `driver.enabled=false` `toolkit.enabled=false` ã‚’è¨­å®šã—ã¦ OK ã§ã™ã€‚

`dcgmExporter` ã®é …ç›®ã¯ helm install æ™‚ã«ã‚³ã‚±ãŸã®ã§å…¥ã‚Œã¦ã„ã‚‹ã ã‘ã§ã€ãªã—ã§ã„ã‘ã‚‹ãªã‚‰ãªã—ã§ã„ã„ã§ã™ã€‚

## Ollama ãƒ‡ãƒ—ãƒ­ã‚¤

[otwld/ollama-helm](https://github.com/otwld/ollama-helm) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

```sh
helm repo add otwld https://helm.otwld.com/
helm repo update
helm install --wait ollama \
  -n ollama --create-namespace \
  otwld/ollama \
  --version=v1.26.0 \
  --values values.yaml
```

`values.yaml`

```yaml
ollama:
  gpu:
    enabled: true
    type: 'nvidia'
    number: 1
  models:
    pull:
      - gemma3:4b

runtimeClassName: nvidia

persistentVolume:
  enabled: true
```

å‹•ä½œç¢ºèªã—ã¾ã™ã€‚

```sh
kubectl run curl-test \
  --rm -it \
  --image=curlimages/curl:8.7.1 \
  --restart=Never \
  -- curl -s http://ollama.ollama:11434/api/generate \
       -H "Content-Type: application/json" \
       -d '{"model": "gemma3:4b", "prompt": "Hello from Kubernetes!", "stream": false}'
```

(ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¦‹ã‚„ã™ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã—ã¦ã„ã¾ã™)

```json
{
  "model": "gemma3:4b",
  "created_at": "2025-08-13T01:12:45.465213503Z",
  "response": "Hello to you too from my digital world! ğŸ‘‹ \n\nItâ€™s great to hear from someone running in Kubernetes. It's a powerful platform for deploying and managing applications. \n\nWhat's happening in your cluster? Are you running anything interesting?  Do you want to chat about Kubernetes, or perhaps you have a question you'd like to ask?",
  "done": true,
  "done_reason": "stop",
  "context": [
    ...
  ],
  "total_duration": 1185074966,
  "load_duration": 118207640,
  "prompt_eval_count": 13,
  "prompt_eval_duration": 32136908,
  "eval_count": 75,
  "eval_duration": 1034268789
}
```

ç”»åƒã‚‚é€ã£ã¦ã¿ã¾ã™ã€‚

```sh
kubectl run curl-test \
  --rm -it \
  --image=curlimages/curl:8.7.1 \
  --restart=Never \
  -- sh -c 'wget https://sogo.dev/images/icon.png \
    && base64 -w 0 icon.png  > image.txt \
    && curl -s http://ollama.ollama:11434/api/generate \
       -H "Content-Type: application/json" \
       -d "{\"model\": \"gemma3:4b\", \"prompt\": \"ä½•ãŒå†™ã£ã¦ã„ã¾ã™ã‹\", \"images\":[\"$(cat image.txt)\"], \"stream\": false}"'
```

```json
{
  "model": "gemma3:4b",
  "created_at": "2025-08-13T01:48:30.629190309Z",
  "response": "ç”»åƒã«ã¯ã€æ©™è‰²ã®ãƒ‰ãƒƒã‚°ï¼ˆé•·æ¯›ã®ãƒ‰ãƒƒã‚°ï¼‰ã®æ¨ªé¡”ãŒå†™ã£ã¦ã„ã¾ã™ã€‚",
  "done": true,
  "done_reason": "stop",
  "context": [
    ...
  ],
  "total_duration": 3821486516,
  "load_duration": 2237497834,
  "prompt_eval_count": 275,
  "prompt_eval_duration": 1299865248,
  "eval_count": 22,
  "eval_duration": 283175986
}
```

ã„ã„ã‹ã‚“ã˜ã§ã™ã­ï¼

## ãŠã¾ã‘: vLLM ç·¨

æœ€åˆã¯ã€æœ¬ç•ªç”¨é€”ã«å¼·ã„ã¨ã•ã‚Œã‚‹ [vLLM](https://docs.vllm.ai/en/v0.7.3/index.html) ã§æ§‹ç¯‰ã‚’é€²ã‚ã¦ã„ãŸã®ã§ã™ãŒã€ç§ã® GPU ã§ã¯ [Gemma 3](https://ai.google.dev/gemma/docs/core?hl=ja) 4B ã‚’å‹•ã‹ã›ãªã‹ã£ãŸã®ã§æ–­å¿µã—ã¾ã—ãŸã€‚

* ãƒ¡ãƒ¢ãƒª 8 GB ã§ã¯é€šå¸¸ã® 32 ãƒ“ãƒƒãƒˆã‚’å‹•ã‹ã™ã«ã¯è¶³ã‚Šãªã„
* BF16, SFP8, INT4 ã«ã¤ã„ã¦ã¯ã€RTX 20xx ãŒå¯¾å¿œã—ã¦ã„ãªã„ã€ã¾ãŸã¯ vLLM ãŒè¦æ±‚ã™ã‚‹ãƒãƒ¼ã‚¸ãƒ§ãƒ³æœªæº€ã®ä¸–ä»£ã® GPU ãªã®ã§ä¸å¯

Gemma 3 1B ãªã‚‰ GPU ã§å‹•ãã¾ã—ãŸãŒã€1B ã¯ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã§ãƒãƒ«ãƒãƒ¢ãƒ¼ãƒ€ãƒ«éå¯¾å¿œãªã®ã§ã€ç”¨é€”ã«åˆã‚ãšå´ä¸‹ã€‚vLLM ã¯ [CPU ã§ã‚‚å‹•ã](https://docs.vllm.ai/en/latest/getting_started/installation/cpu.html) ã¿ãŸã„ã§ã™ãŒã€pre-built ãªã‚³ãƒ³ãƒ†ãƒŠã‚¤ãƒ¡ãƒ¼ã‚¸ãŒ amd64 ç”¨ã«ç”¨æ„ã•ã‚Œã¦ãªã‹ã£ãŸã®ã§è©¦ã—ã¦ã„ã¾ã›ã‚“ã€‚

## å‚è€ƒæ–‡çŒ®

* [é«˜åº¦ãªã‚ªãƒ—ã‚·ãƒ§ãƒ³ / è¨­å®š | K3s](https://docs.k3s.io/ja/advanced#nvidia%E3%82%B3%E3%83%B3%E3%83%86%E3%83%8A%E3%83%A9%E3%83%B3%E3%82%BF%E3%82%A4%E3%83%A0%E3%81%AE%E3%82%B5%E3%83%9D%E3%83%BC%E3%83%88)
* [Installing the NVIDIA Container Toolkit â€” NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#with-apt-ubuntu-debian)
* [k3sã§Nvidia GPUã‚’ä½¿ç”¨ã™ã‚‹](https://cloudandbuild.jp/blog/article-20240914)
* [Installing the NVIDIA GPU Operator â€” NVIDIA GPU Operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/getting-started.html)
* [k8s ã‚¯ãƒ©ã‚¹ã‚¿ã‹ã‚‰GPUã‚’ä½¿ç”¨ã™ã‚‹æ–¹æ³•ã«ã¤ã„ã¦( gpu-operator)](https://zenn.dev/srkr/articles/4afe42d3d2183e)
* [Gemma 3 ãƒ¢ãƒ‡ãƒ«ã®æ¦‚è¦ Â |Â  Google AI for Developers](https://ai.google.dev/gemma/docs/core?hl=ja)
